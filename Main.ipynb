{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"Final.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sbcNNOwas0t2","outputId":"e390de54-9c45-4747-dd1a-300060cb95bc","executionInfo":{"status":"ok","timestamp":1648202774191,"user_tz":-330,"elapsed":2937,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"XZFE-Yyss5RW","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b5caa341-5afd-418b-d6a6-52d35ef544b7","executionInfo":{"status":"ok","timestamp":1648202776228,"user_tz":-330,"elapsed":346,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["cd /content/gdrive/MyDrive/Thesis/ASD"],"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Thesis/ASD\n"]}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-18T20:06:36.027823Z","iopub.execute_input":"2021-06-18T20:06:36.028151Z","iopub.status.idle":"2021-06-18T20:06:38.856661Z","shell.execute_reply.started":"2021-06-18T20:06:36.028106Z","shell.execute_reply":"2021-06-18T20:06:38.855715Z"},"trusted":true,"id":"5IcOJBWphkn3","executionInfo":{"status":"ok","timestamp":1648202778663,"user_tz":-330,"elapsed":349,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from functools import reduce\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import train_test_split\n","import time\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","import torch\n","import sys\n","import pickle\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.model_selection import KFold, StratifiedKFold\n","import torch.optim as optim\n","from sklearn.metrics import confusion_matrix\n","import functools\n","import numpy.ma as ma # for masked arrays\n","import glob\n","import random\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from tqdm.notebook import tqdm\n","from itertools import groupby\n","import sklearn"],"execution_count":40,"outputs":[]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"id":"J91JWayxDhD_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from captum.attr import IntegratedGradients\n","from captum.attr import Saliency\n","from captum.attr import DeepLift\n","from captum.attr import NoiseTunnel\n","from captum.attr import visualization as viz\n","from captum.attr import Saliency\n","import torchvision"],"metadata":{"id":"tl53yTciEI-K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O7DgqnL6hkn4"},"source":["### Helper functions for computing correlations"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-18T20:06:38.925344Z","iopub.execute_input":"2021-06-18T20:06:38.925672Z","iopub.status.idle":"2021-06-18T20:06:38.942734Z","shell.execute_reply.started":"2021-06-18T20:06:38.925638Z","shell.execute_reply":"2021-06-18T20:06:38.941792Z"},"trusted":true,"id":"CrCnO-6yhkn5","executionInfo":{"status":"ok","timestamp":1648202780456,"user_tz":-330,"elapsed":574,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["def get_corr_data(df):\n","              \n","    with np.errstate(invalid=\"ignore\"):\n","        corr = np.nan_to_num(np.corrcoef(df.T))\n","        mask = np.invert(np.tri(corr.shape[0], k=-1, dtype=bool))\n","        m = ma.masked_where(mask == 1, mask)\n","        return ma.masked_where(m, corr).compressed()\n","        \n","def get_corr_matrix(filename,data_path):\n","    # returns correlation matrix\n","    for file in os.listdir(data_path):\n","        if file.startswith(filename):\n","            df = pd.read_csv(os.path.join(data_path, file), sep='\\t')\n","    with np.errstate(invalid=\"ignore\"):\n","        corr = np.nan_to_num(np.corrcoef(df.T))\n","        return corr\n","\n","def confusion(g_turth,predictions):\n","    tn, fp, fn, tp = confusion_matrix(g_turth,predictions).ravel()\n","    accuracy = (tp+tn)/(tp+fp+tn+fn)\n","    sensitivity = (tp)/(tp+fn)\n","    specificty = (tn)/(tn+fp)\n","    return accuracy,sensitivity,specificty"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oz3YnOOchkn3"},"source":["## Loading the data "]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-18T20:06:38.861206Z","iopub.execute_input":"2021-06-18T20:06:38.861461Z","iopub.status.idle":"2021-06-18T20:06:38.868954Z","shell.execute_reply.started":"2021-06-18T20:06:38.861434Z","shell.execute_reply":"2021-06-18T20:06:38.868167Z"},"trusted":true,"id":"PmnCD4dphkn4","executionInfo":{"status":"ok","timestamp":1648202783763,"user_tz":-330,"elapsed":11,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["def get_key(filename):\n","    f_split = filename.split('_')\n","    if f_split[3] == 'rois':\n","        key = '_'.join(f_split[0:3]) \n","    else:\n","        key = '_'.join(f_split[0:2])\n","    return key"],"execution_count":42,"outputs":[]},{"cell_type":"code","source":["data_df = pd.read_csv('./Phenotypes/Phenotypic_V1_0b_preprocessed949.csv', encoding= 'unicode_escape')\n","data_df.DX_GROUP = data_df.DX_GROUP.map({1: 1, 2:0})\n","print('Length of data frame : ', len(data_df))\n","print(data_df.head())"],"metadata":{"id":"oNOgREKYD8xm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648202784315,"user_tz":-330,"elapsed":560,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"c6e0e155-0e18-4b86-ca92-22305acee330"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of data frame :  949\n","   Unnamed: 0  SUB_ID  X  subject SITE_ID       FILE_ID  DX_GROUP  DSM_IV_TR  \\\n","0           0   50003  2    50003    PITT  Pitt_0050003         1          1   \n","1           1   50004  3    50004    PITT  Pitt_0050004         1          1   \n","2           2   50006  5    50006    PITT  Pitt_0050006         1          1   \n","3           3   50007  6    50007    PITT  Pitt_0050007         1          1   \n","4           4   50009  8    50009    PITT  Pitt_0050009         1          1   \n","\n","   AGE_AT_SCAN  SEX  ... qc_notes_rater_1  qc_anat_rater_2  \\\n","0        24.45    1  ...              NaN               OK   \n","1        19.09    1  ...              NaN               OK   \n","2        13.37    1  ...              NaN               OK   \n","3        17.78    1  ...              NaN               OK   \n","4        33.86    1  ...              NaN               OK   \n","\n","   qc_anat_notes_rater_2  qc_func_rater_2       qc_func_notes_rater_2  \\\n","0                    NaN               OK                         NaN   \n","1                    NaN               OK                         NaN   \n","2                    NaN            maybe          ic-parietal slight   \n","3                    NaN            maybe  ic-cerebellum_temporal_lob   \n","4                    NaN             fail      ic-parietal-cerebellum   \n","\n","   qc_anat_rater_3 qc_anat_notes_rater_3 qc_func_rater_3  \\\n","0               OK                   NaN              OK   \n","1               OK                   NaN              OK   \n","2               OK                   NaN              OK   \n","3               OK                   NaN              OK   \n","4               OK                   NaN              OK   \n","\n","  qc_func_notes_rater_3  SUB_IN_SMP  \n","0                   NaN           1  \n","1                   NaN           1  \n","2                   NaN           1  \n","3                   NaN           1  \n","4                   NaN           1  \n","\n","[5 rows x 106 columns]\n"]}]},{"cell_type":"code","source":["data_path = './Datasets/CPAC/rois_cc200/*.1D'\n","fpaths = glob.glob(data_path)\n","print('Number of Subjects available: ', len(fpaths))"],"metadata":{"id":"K4iW2KkSSgVq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648201149599,"user_tz":-330,"elapsed":313,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"f885a15d-44ac-4f57-bbb1-14b3037f475b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Subjects available:  1035\n"]}]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-18T20:06:38.945281Z","iopub.execute_input":"2021-06-18T20:06:38.94597Z","iopub.status.idle":"2021-06-18T20:07:07.764978Z","shell.execute_reply.started":"2021-06-18T20:06:38.945932Z","shell.execute_reply":"2021-06-18T20:07:07.763126Z"},"trusted":true,"id":"mfjFNCivhkn6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648124379191,"user_tz":-330,"elapsed":60327,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"507f3c6a-a288-44a9-923e-caa2e5c085bb"},"source":["all_corr = {}\n","\n","for i,path in enumerate(fpaths):\n","\n","    # Extracting SFC\n","    fname = path.split('/')[-1]\n","    key = fname.split('_')[0]\n","    x = np.loadtxt(path)\n","    x = np.array(x, dtype = 'float32')\n","    corr = get_corr_data(x)\n","\n","    # Extracting corresponding labels\n","    y = data_df[data_df['SUB_ID'] == int(key)]['DX_GROUP']\n","\n","    all_corr[key] = (corr,y)\n","\n","print('Length of correlations vector : ', len(all_corr))\n","pickle.dump(all_corr, open('./data/SFC_CC200.pkl', 'wb'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of correlations vector :  866\n"]}]},{"cell_type":"code","metadata":{"id":"n3zlWZzR1qm6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648202791866,"user_tz":-330,"elapsed":705,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"842eb67b-6c7d-44d7-de60-2d5aecc18682"},"source":["all_corr = pickle.load(open('./data/SFC_CC200.pkl', 'rb'))\n","flist = np.array(list(all_corr.keys()))\n","labels = np.array([all_corr[f][1] for f in flist], dtype = 'uint8')\n","print('Length of Input subjects : ', len(flist))\n","print('Length of Output subjects : ', len(labels))"],"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of Input subjects :  949\n","Length of Output subjects :  949\n"]}]},{"cell_type":"markdown","source":["# DataLoader"],"metadata":{"id":"Hkp7JHCba4ok"}},{"cell_type":"code","metadata":{"id":"5daHy9cVnrKp","executionInfo":{"status":"ok","timestamp":1648202805444,"user_tz":-330,"elapsed":370,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["class ASDDataset(Dataset):\n","    def __init__(self, all_corr, subjects):\n","        self.corr = all_corr\n","        self.subjects = subjects\n","        pass\n","    def __getitem__(self,idx):\n","        return torch.tensor(self.corr[self.subjects[idx]][0],dtype=torch.float),torch.tensor(self.corr[self.subjects[idx]][1],dtype=torch.float)\n","        pass\n","    def __len__(self):\n","        return len(self.subjects)\n","        pass"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CWyj8pQihkn7"},"source":["# Network "]},{"cell_type":"code","source":["# Auto Encoder and Classifier\n","class Network(nn.Module):\n","    def __init__(self, num_inputs = 19900, num_latent = 200):\n","        super(Network, self).__init__()\n","        \n","        self.num_latent = num_latent\n","        self.num_inputs = num_inputs\n","        \n","        self.fc_encoder = nn.Sequential (\n","                nn.Linear(self.num_inputs,4096),\n","                nn.Tanh(),\n","                nn.Linear(4096,1024),\n","                nn.Tanh())\n","        \n","        self.fc_decoder = nn.Sequential (\n","                nn.Linear(1024,4096),\n","                nn.Tanh(),\n","                nn.Linear(4096,self.num_inputs),\n","                nn.Tanh())\n","         \n","        self.classifier = nn.Sequential (\n","            nn.Dropout(p=0.25),\n","            nn.Linear(1024, 1),\n","        )\n","\n","        self.sigmoid = nn.Sigmoid()           \n","         \n","    def forward(self, x, eval_classifier = True):\n","\n","        x = self.fc_encoder(x)\n","        if eval_classifier:\n","            x_logit = self.classifier(x)   #   .squeeze(1)\n","            x_logit = self.sigmoid(x_logit)\n","            return x_logit \n","\n","        x = self.fc_decoder(x)        \n","        return x"],"metadata":{"id":"moCFjEdlR8h9","executionInfo":{"status":"ok","timestamp":1648202823286,"user_tz":-330,"elapsed":329,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pw6wxQ7uhkn8"},"source":["# Defining training and testing functions"]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-18T20:29:54.242475Z","iopub.execute_input":"2021-06-18T20:29:54.242797Z","iopub.status.idle":"2021-06-18T20:29:54.272092Z","shell.execute_reply.started":"2021-06-18T20:29:54.242766Z","shell.execute_reply":"2021-06-18T20:29:54.271229Z"},"trusted":true,"id":"XJGFx-CFhkn8","executionInfo":{"status":"ok","timestamp":1648202924409,"user_tz":-330,"elapsed":368,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["def train(model, criterion, data_loader, mode='clf'):\n","    model.train()\n","    clf_loss = []\n","    ae_loss = []\n","    \n","    if mode == 'clf':\n","        final_targets = []\n","        final_predictions = []\n","    else:\n","        final_targets = None\n","        final_predictions = None    \n","    \n","    for (inputs, targets) in data_loader :\n","        # if len(batch_x) != batch_size:           # Check 1\n","        #     continue\n","\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","\n","        if mode == 'ae':        \n","            reconstructed = model(inputs, False)\n","            loss_ae = criterion(reconstructed, inputs) / len(inputs)              \n","            loss_total = loss_ae\n","            loss_ae_np = loss_ae.detach().cpu().numpy()\n","            ae_loss.append(loss_ae_np)           \n","\n","        elif mode == 'clf':\n","            logits = model(inputs, True)\n","            logits = np.squeeze(logits, 1)\n","            loss_clf = criterion(logits, targets)\n","            proba = logits.detach().cpu().numpy()\n","            # proba = torch.sigmoid(logits).detach().cpu().numpy().    # Make sure sigmoid or softmax is present in the architecture function, otherwise uncomment this.\n","            predictions = np.round(proba)           \n","            final_targets.append(targets.detach().cpu().numpy())\n","            final_predictions.append(predictions)\n","            \n","            loss_total = loss_clf\n","            loss_clf_np = loss_clf.detach().cpu().numpy()           \n","            clf_loss.append(loss_clf_np)\n","            \n","        loss_total.backward()\n","        optimizer.step()\n","    \n","    if (final_targets is not None) and (final_predictions is not None):\n","        final_targets = np.concatenate(final_targets)\n","        final_predictions = np.concatenate(final_predictions)\n","        train_accuracy = np.mean(final_targets == final_predictions)\n","\n","        return np.mean(clf_loss), train_accuracy\n","    else:\n","        return np.mean(ae_loss), None\n","\n","\n","def test(model, criterion, data_loader, mode = 'clf'):\n","\n","    clf_loss = []\n","    ae_loss = []\n","    \n","    if mode == 'clf':\n","        final_targets = []\n","        final_predictions = []\n","    else:\n","        final_targets = None\n","        final_predictions = None    \n","    \n","    with torch.no_grad():\n","        model.eval()\n","        for (inputs, targets) in data_loader :\n","            # if len(batch_x) != batch_size:           # Check 1\n","            #     continue\n","\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            if mode == 'ae':        \n","                reconstructed = model(inputs, False)\n","                loss_ae = criterion_ae(reconstructed, inputs) / len(inputs)           \n","                loss_total = loss_ae\n","                loss_ae_np = loss_ae.detach().cpu().numpy()\n","                ae_loss.append(loss_ae_np)           \n","\n","            if mode == 'clf':\n","                logits = model(inputs, True)\n","                logits = np.squeeze(logits, 1)\n","                loss_clf = criterion_clf(logits, targets)\n","                proba = logits.detach().cpu().numpy()\n","                # proba = torch.sigmoid(logits).detach().cpu().numpy().    # Make sure sigmoid or softmax is present in the architecture function, otherwise uncomment this.\n","                predictions = np.round(proba)           \n","                final_targets.append(targets.detach().cpu().numpy())\n","                final_predictions.append(predictions)\n","                \n","                loss_total = loss_clf\n","                loss_clf_np = loss_clf.detach().cpu().numpy()           \n","                clf_loss.append(loss_clf_np)\n","              \n","    \n","    if (final_targets is  None) and (final_predictions is None):\n","        return np.mean(ae_loss), None\n","    \n","    final_targets = np.concatenate(final_targets)\n","    final_predictions = np.concatenate(final_predictions)\n","    mlp_acc, mlp_sens, mlp_spef = confusion(final_targets, final_predictions)\n","    metrics_dict = {'accuracy': np.round(mlp_acc, 4), \n","                    'senstivity' : np.round(mlp_sens,4), \n","                    'specificity' : np.round(mlp_spef,4), \n","                    'loss' : np.round(np.mean(clf_loss),4)}               \n","    return  metrics_dict  "],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"execution":{"iopub.status.busy":"2021-06-18T20:29:55.7098Z","iopub.execute_input":"2021-06-18T20:29:55.710152Z","iopub.status.idle":"2021-06-18T20:29:55.718895Z","shell.execute_reply.started":"2021-06-18T20:29:55.710095Z","shell.execute_reply":"2021-06-18T20:29:55.718161Z"},"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"uTlD8687hkn9","outputId":"0ec951cf-7907-4f3d-8bb6-d6a688fe6661","executionInfo":{"status":"ok","timestamp":1648202863119,"user_tz":-330,"elapsed":344,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","metadata":{"id":"FEYrLdqSCM7D"},"source":["def attribute_image_features(algorithm, inputs):\n","    model.zero_grad()\n","    model.eval()\n","    tensor_attributions = algorithm.attribute(inputs = inputs, target = 0, return_convergence_delta=True)  \n","    return tensor_attributions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YEsTbR4mxh5A"},"source":["# ASD 2 Layer Model Training"]},{"cell_type":"code","source":["# Define Parameters\n","p_fold = 10\n","batch_size = 16\n","lr_ae, lr_clf = 0.0001, 0.0001\n","ae_epochs, clf_epochs = 50, 50     # 50, 50\n","weight_decay_ae, weight_decay_clf = 0.05, 0.05\n","n_inputs, n_latent = 19900, 512  # Automate this according to the atlas "],"metadata":{"id":"cC9O0SN5H-zA","executionInfo":{"status":"ok","timestamp":1648202868197,"user_tz":-330,"elapsed":2,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9532M-9sEBY","outputId":"6e3e44fc-42e8-4177-aae9-f673a226a987","executionInfo":{"status":"ok","timestamp":1648206925416,"user_tz":-330,"elapsed":2421039,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["crossval_acc, crossval_sen, crossval_spec, crossval_loss, attributions = [], [], [], [], [] \n","all_folds_splits = {}\n","kf = StratifiedKFold(n_splits = p_fold, random_state = 1, shuffle = True)\n","\n","start = time.time()\n","for fold,(train_index, test_index) in enumerate(kf.split(flist, labels)):\n","\n","    train_subjects, test_subjects = flist[train_index],flist[test_index]\n","    train_labels = labels[train_index]   \n","    train_subjects, val_subjects, train_labels, val_labels = train_test_split(train_subjects, train_labels, \n","                                                      test_size = 0.25, random_state = 42, stratify = train_labels)\n","    \n","    print('Number of train subjects : ', len(train_subjects))\n","    print('Number of val subjects : ', len(val_subjects))\n","    print('Number of test subjects : ', len(test_subjects))\n","\n","    fold_splits_dict = {} \n","    fold_splits_dict['train'] = train_subjects\n","    fold_splits_dict['val'] = val_subjects\n","    fold_splits_dict['test'] = test_subjects\n","\n","    all_folds_splits[fold] = fold_splits_dict\n","    verbose = (True if (fold == 0) else False)\n","   \n","    train_dataset = ASDDataset(all_corr, train_subjects)\n","    val_dataset = ASDDataset(all_corr, val_subjects)\n","    test_dataset = ASDDataset(all_corr, test_subjects)\n","    \n","    train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","    val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n","    test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)                           \n","\n","    model = Network(num_inputs = n_inputs, num_latent = n_latent)\n","    model = model.to(device)\n","\n","    criterion_ae = nn.MSELoss(reduction='sum')         \n","    optimizer = optim.Adam(model.parameters(), lr = lr_ae, weight_decay = weight_decay_ae)          \n","    best_ae_model, count = None, 1\n","    best_ae_loss = sys.float_info.max\n","    \n","    print(\"Auto Encoder training Started-----------\")\n","    for epoch in range(1, ae_epochs+1):\n","\n","        print(f'Epoch {epoch}/{ae_epochs}')\n","        ae_train_loss, _ = train(model, criterion_ae, train_dataloader, mode = 'ae')\n","        print(f'AE Train loss: {(ae_train_loss):.4f}')\n","\n","        ae_val_loss, _ = test(model, criterion_ae, val_dataloader, mode = 'ae')\n","        print(f'AE Val loss: {(ae_val_loss):.4f}')\n","\n","        if(ae_val_loss < best_ae_loss):     # Early Stopping \n","            best_ae_model = model\n","            best_ae_loss = ae_val_loss\n","            count = 1\n","        else:\n","            count += 1     \n","        if(count == 10):  # Criteria\n","            break\n","              \n","    best_clf_model, best_clf_acc, count = None, 0.0, 1\n","    model = best_ae_model\n","    criterion_clf = nn.BCELoss()      \n","    optimizer = optim.Adam(model.parameters(), lr = lr_clf, weight_decay = weight_decay_clf)\n","\n","    print(\"Classifier training Started-----------\")\n","    for epoch in range(1, clf_epochs+1):\n","\n","        print(f'Epoch {epoch}/{clf_epochs}')\n","        clf_train_loss, train_acc = train(model, criterion_clf, train_dataloader, mode='clf')\n","        print(f'CLF Train loss: {(clf_train_loss):.4f}, Train Accuracy: {(train_acc):.4f}')\n","\n","        val_metrics = test(model, criterion_clf, val_dataloader, mode='clf')\n","        print(f'CLF Val loss: {(val_metrics[\"loss\"]):.4f}, Validation Accuracy: {(val_metrics[\"accuracy\"]):.4f}')\n","\n","        if(val_metrics['accuracy'] > best_clf_acc):    # Early Stopping Criteria\n","            best_clf_model = model\n","            best_clf_acc = val_metrics['accuracy']\n","            count = 1\n","        else:\n","            count += 1\n","        if(count == 10):\n","            break        \n","\n","    metrics_dict = test(best_clf_model, criterion_clf, test_dataloader, mode = 'clf')\n","\n","    print(f'Fold {fold+1}/{p_fold}')\n","    print(f'{metrics_dict}')\n","    print(\"--------------------------------------------\")\n","    \n","    # torch.save(best_clf_model.state_dict(), f'./data/Weights/Fold_{kk+1}.pth').    # To save the weights\n","    # print(f'Fold {kk+1} weights are saved')\n","\n","    crossval_acc.append(metrics_dict['accuracy'])\n","    crossval_sen.append(metrics_dict['senstivity'])\n","    crossval_spec.append(metrics_dict['specificity'])\n","    crossval_loss.append(metrics_dict['loss'])\n","\n","print(f'Average Value after 10 Folds')\n","print(f'Accuracy: {np.round(np.mean(crossval_acc),4)}, Senstivity: {np.round(np.mean(crossval_sen),4)}, Specificity: {np.round(np.mean(crossval_spec),4)}, Loss: {np.round(np.mean(crossval_loss),4)}')\n","# pickle.dump(df, open('./data/AllFoldssubjects.pkl', 'wb'))\n","print(f'Total time taken : {time.time()-start}')"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 774.6885\n","AE Val loss: 698.0565\n","Epoch 2/50\n","AE Train loss: 632.6107\n","AE Val loss: 639.1536\n","Epoch 3/50\n","AE Train loss: 556.9248\n","AE Val loss: 605.7745\n","Epoch 4/50\n","AE Train loss: 500.7336\n","AE Val loss: 586.5453\n","Epoch 5/50\n","AE Train loss: 454.2633\n","AE Val loss: 575.3898\n","Epoch 6/50\n","AE Train loss: 413.2725\n","AE Val loss: 562.2501\n","Epoch 7/50\n","AE Train loss: 377.2842\n","AE Val loss: 546.5216\n","Epoch 8/50\n","AE Train loss: 341.6988\n","AE Val loss: 539.1572\n","Epoch 9/50\n","AE Train loss: 312.0334\n","AE Val loss: 532.9943\n","Epoch 10/50\n","AE Train loss: 286.8349\n","AE Val loss: 528.0292\n","Epoch 11/50\n","AE Train loss: 262.6194\n","AE Val loss: 521.5522\n","Epoch 12/50\n","AE Train loss: 244.6883\n","AE Val loss: 522.6520\n","Epoch 13/50\n","AE Train loss: 227.4125\n","AE Val loss: 514.4360\n","Epoch 14/50\n","AE Train loss: 209.9804\n","AE Val loss: 511.0320\n","Epoch 15/50\n","AE Train loss: 194.7498\n","AE Val loss: 517.5863\n","Epoch 16/50\n","AE Train loss: 182.3103\n","AE Val loss: 506.8158\n","Epoch 17/50\n","AE Train loss: 168.0216\n","AE Val loss: 500.7198\n","Epoch 18/50\n","AE Train loss: 156.2044\n","AE Val loss: 498.6882\n","Epoch 19/50\n","AE Train loss: 146.2020\n","AE Val loss: 498.5742\n","Epoch 20/50\n","AE Train loss: 136.2603\n","AE Val loss: 497.4731\n","Epoch 21/50\n","AE Train loss: 127.4689\n","AE Val loss: 493.1801\n","Epoch 22/50\n","AE Train loss: 119.7226\n","AE Val loss: 501.5870\n","Epoch 23/50\n","AE Train loss: 112.3551\n","AE Val loss: 490.5433\n","Epoch 24/50\n","AE Train loss: 104.9602\n","AE Val loss: 496.7354\n","Epoch 25/50\n","AE Train loss: 99.4385\n","AE Val loss: 489.0110\n","Epoch 26/50\n","AE Train loss: 93.1015\n","AE Val loss: 488.8557\n","Epoch 27/50\n","AE Train loss: 88.5928\n","AE Val loss: 486.3488\n","Epoch 28/50\n","AE Train loss: 84.0518\n","AE Val loss: 491.7249\n","Epoch 29/50\n","AE Train loss: 79.4739\n","AE Val loss: 486.6586\n","Epoch 30/50\n","AE Train loss: 75.7137\n","AE Val loss: 484.6304\n","Epoch 31/50\n","AE Train loss: 72.0853\n","AE Val loss: 484.6083\n","Epoch 32/50\n","AE Train loss: 68.1830\n","AE Val loss: 483.1078\n","Epoch 33/50\n","AE Train loss: 64.8784\n","AE Val loss: 482.8484\n","Epoch 34/50\n","AE Train loss: 61.3110\n","AE Val loss: 483.1175\n","Epoch 35/50\n","AE Train loss: 58.3710\n","AE Val loss: 481.5805\n","Epoch 36/50\n","AE Train loss: 55.4692\n","AE Val loss: 485.0802\n","Epoch 37/50\n","AE Train loss: 53.0943\n","AE Val loss: 481.4512\n","Epoch 38/50\n","AE Train loss: 50.9730\n","AE Val loss: 481.9972\n","Epoch 39/50\n","AE Train loss: 48.6643\n","AE Val loss: 479.2835\n","Epoch 40/50\n","AE Train loss: 46.6215\n","AE Val loss: 481.0863\n","Epoch 41/50\n","AE Train loss: 45.7873\n","AE Val loss: 479.5439\n","Epoch 42/50\n","AE Train loss: 44.8354\n","AE Val loss: 482.4541\n","Epoch 43/50\n","AE Train loss: 42.7789\n","AE Val loss: 479.1265\n","Epoch 44/50\n","AE Train loss: 40.3146\n","AE Val loss: 476.9261\n","Epoch 45/50\n","AE Train loss: 39.2617\n","AE Val loss: 479.8907\n","Epoch 46/50\n","AE Train loss: 38.4489\n","AE Val loss: 478.2349\n","Epoch 47/50\n","AE Train loss: 38.1277\n","AE Val loss: 478.5608\n","Epoch 48/50\n","AE Train loss: 37.7604\n","AE Val loss: 479.8582\n","Epoch 49/50\n","AE Train loss: 37.3728\n","AE Val loss: 479.0269\n","Epoch 50/50\n","AE Train loss: 36.0252\n","AE Val loss: 478.0643\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6664, Train Accuracy: 0.6078\n","CLF Val loss: 0.6203, Validation Accuracy: 0.6776\n","Epoch 2/50\n","CLF Train loss: 0.4452, Train Accuracy: 0.8000\n","CLF Val loss: 0.5533, Validation Accuracy: 0.7103\n","Epoch 3/50\n","CLF Train loss: 0.3105, Train Accuracy: 0.8906\n","CLF Val loss: 0.5999, Validation Accuracy: 0.6822\n","Epoch 4/50\n","CLF Train loss: 0.2254, Train Accuracy: 0.9406\n","CLF Val loss: 0.5903, Validation Accuracy: 0.7056\n","Epoch 5/50\n","CLF Train loss: 0.1966, Train Accuracy: 0.9391\n","CLF Val loss: 0.6948, Validation Accuracy: 0.6542\n","Epoch 6/50\n","CLF Train loss: 0.2345, Train Accuracy: 0.9141\n","CLF Val loss: 0.6500, Validation Accuracy: 0.7009\n","Epoch 7/50\n","CLF Train loss: 0.1800, Train Accuracy: 0.9500\n","CLF Val loss: 0.6221, Validation Accuracy: 0.6963\n","Epoch 8/50\n","CLF Train loss: 0.1225, Train Accuracy: 0.9797\n","CLF Val loss: 0.6687, Validation Accuracy: 0.7103\n","Epoch 9/50\n","CLF Train loss: 0.0955, Train Accuracy: 0.9875\n","CLF Val loss: 0.6627, Validation Accuracy: 0.6916\n","Epoch 10/50\n","CLF Train loss: 0.1195, Train Accuracy: 0.9828\n","CLF Val loss: 0.6328, Validation Accuracy: 0.7150\n","Epoch 11/50\n","CLF Train loss: 0.1045, Train Accuracy: 0.9828\n","CLF Val loss: 0.6123, Validation Accuracy: 0.7009\n","Epoch 12/50\n","CLF Train loss: 0.0935, Train Accuracy: 0.9875\n","CLF Val loss: 0.6165, Validation Accuracy: 0.6869\n","Epoch 13/50\n","CLF Train loss: 0.0786, Train Accuracy: 0.9953\n","CLF Val loss: 0.6985, Validation Accuracy: 0.6963\n","Epoch 14/50\n","CLF Train loss: 0.1024, Train Accuracy: 0.9875\n","CLF Val loss: 0.6237, Validation Accuracy: 0.7243\n","Epoch 15/50\n","CLF Train loss: 0.0791, Train Accuracy: 0.9922\n","CLF Val loss: 0.6115, Validation Accuracy: 0.6822\n","Epoch 16/50\n","CLF Train loss: 0.1050, Train Accuracy: 0.9859\n","CLF Val loss: 0.8888, Validation Accuracy: 0.6449\n","Epoch 17/50\n","CLF Train loss: 0.1062, Train Accuracy: 0.9781\n","CLF Val loss: 0.6260, Validation Accuracy: 0.6916\n","Epoch 18/50\n","CLF Train loss: 0.1071, Train Accuracy: 0.9766\n","CLF Val loss: 0.7505, Validation Accuracy: 0.6822\n","Epoch 19/50\n","CLF Train loss: 0.0800, Train Accuracy: 0.9891\n","CLF Val loss: 0.6757, Validation Accuracy: 0.7009\n","Epoch 20/50\n","CLF Train loss: 0.0646, Train Accuracy: 0.9984\n","CLF Val loss: 0.6167, Validation Accuracy: 0.7336\n","Epoch 21/50\n","CLF Train loss: 0.0567, Train Accuracy: 1.0000\n","CLF Val loss: 0.6319, Validation Accuracy: 0.7009\n","Epoch 22/50\n","CLF Train loss: 0.0577, Train Accuracy: 0.9984\n","CLF Val loss: 0.7225, Validation Accuracy: 0.6776\n","Epoch 23/50\n","CLF Train loss: 0.0633, Train Accuracy: 0.9984\n","CLF Val loss: 0.6306, Validation Accuracy: 0.6916\n","Epoch 24/50\n","CLF Train loss: 0.0624, Train Accuracy: 0.9969\n","CLF Val loss: 0.6138, Validation Accuracy: 0.7150\n","Epoch 25/50\n","CLF Train loss: 0.0549, Train Accuracy: 1.0000\n","CLF Val loss: 0.6770, Validation Accuracy: 0.6822\n","Epoch 26/50\n","CLF Train loss: 0.0559, Train Accuracy: 0.9984\n","CLF Val loss: 0.5961, Validation Accuracy: 0.7103\n","Epoch 27/50\n","CLF Train loss: 0.0541, Train Accuracy: 0.9969\n","CLF Val loss: 0.6190, Validation Accuracy: 0.7290\n","Epoch 28/50\n","CLF Train loss: 0.0686, Train Accuracy: 0.9938\n","CLF Val loss: 0.8035, Validation Accuracy: 0.6729\n","Epoch 29/50\n","CLF Train loss: 0.0699, Train Accuracy: 0.9938\n","CLF Val loss: 0.6211, Validation Accuracy: 0.7009\n","Fold 1/10\n","{'accuracy': 0.6947, 'senstivity': 0.6429, 'specificity': 0.7358, 'loss': 0.6723}\n","--------------------------------------------\n","Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 772.6222\n","AE Val loss: 704.0395\n","Epoch 2/50\n","AE Train loss: 631.1675\n","AE Val loss: 646.2939\n","Epoch 3/50\n","AE Train loss: 556.2863\n","AE Val loss: 611.2987\n","Epoch 4/50\n","AE Train loss: 498.7659\n","AE Val loss: 587.2192\n","Epoch 5/50\n","AE Train loss: 450.9363\n","AE Val loss: 571.5001\n","Epoch 6/50\n","AE Train loss: 410.4919\n","AE Val loss: 561.4927\n","Epoch 7/50\n","AE Train loss: 373.8029\n","AE Val loss: 556.9850\n","Epoch 8/50\n","AE Train loss: 341.6973\n","AE Val loss: 541.3129\n","Epoch 9/50\n","AE Train loss: 312.7760\n","AE Val loss: 534.4512\n","Epoch 10/50\n","AE Train loss: 286.3183\n","AE Val loss: 527.9777\n","Epoch 11/50\n","AE Train loss: 262.5279\n","AE Val loss: 525.5463\n","Epoch 12/50\n","AE Train loss: 240.5706\n","AE Val loss: 517.0311\n","Epoch 13/50\n","AE Train loss: 222.0611\n","AE Val loss: 522.2570\n","Epoch 14/50\n","AE Train loss: 205.7021\n","AE Val loss: 516.2625\n","Epoch 15/50\n","AE Train loss: 192.1417\n","AE Val loss: 510.8046\n","Epoch 16/50\n","AE Train loss: 179.1289\n","AE Val loss: 511.6826\n","Epoch 17/50\n","AE Train loss: 166.5036\n","AE Val loss: 505.3510\n","Epoch 18/50\n","AE Train loss: 153.2725\n","AE Val loss: 499.7790\n","Epoch 19/50\n","AE Train loss: 142.5690\n","AE Val loss: 497.8735\n","Epoch 20/50\n","AE Train loss: 133.1387\n","AE Val loss: 496.2645\n","Epoch 21/50\n","AE Train loss: 124.4942\n","AE Val loss: 494.6663\n","Epoch 22/50\n","AE Train loss: 117.3461\n","AE Val loss: 497.7480\n","Epoch 23/50\n","AE Train loss: 110.6455\n","AE Val loss: 491.6326\n","Epoch 24/50\n","AE Train loss: 103.7067\n","AE Val loss: 494.7577\n","Epoch 25/50\n","AE Train loss: 97.6777\n","AE Val loss: 492.8223\n","Epoch 26/50\n","AE Train loss: 91.4974\n","AE Val loss: 490.2535\n","Epoch 27/50\n","AE Train loss: 86.8646\n","AE Val loss: 494.0593\n","Epoch 28/50\n","AE Train loss: 81.8581\n","AE Val loss: 487.5955\n","Epoch 29/50\n","AE Train loss: 77.5698\n","AE Val loss: 486.0052\n","Epoch 30/50\n","AE Train loss: 73.3770\n","AE Val loss: 486.8992\n","Epoch 31/50\n","AE Train loss: 69.7234\n","AE Val loss: 486.0974\n","Epoch 32/50\n","AE Train loss: 65.9592\n","AE Val loss: 486.0124\n","Epoch 33/50\n","AE Train loss: 63.0574\n","AE Val loss: 484.2448\n","Epoch 34/50\n","AE Train loss: 60.4010\n","AE Val loss: 483.6736\n","Epoch 35/50\n","AE Train loss: 57.2817\n","AE Val loss: 483.0713\n","Epoch 36/50\n","AE Train loss: 54.6643\n","AE Val loss: 483.6269\n","Epoch 37/50\n","AE Train loss: 52.3480\n","AE Val loss: 482.4395\n","Epoch 38/50\n","AE Train loss: 50.2611\n","AE Val loss: 482.4680\n","Epoch 39/50\n","AE Train loss: 48.4394\n","AE Val loss: 481.0985\n","Epoch 40/50\n","AE Train loss: 47.3898\n","AE Val loss: 481.8093\n","Epoch 41/50\n","AE Train loss: 45.1735\n","AE Val loss: 482.6645\n","Epoch 42/50\n","AE Train loss: 44.3246\n","AE Val loss: 483.0988\n","Epoch 43/50\n","AE Train loss: 42.6182\n","AE Val loss: 480.9121\n","Epoch 44/50\n","AE Train loss: 41.3014\n","AE Val loss: 481.8042\n","Epoch 45/50\n","AE Train loss: 40.6662\n","AE Val loss: 481.3400\n","Epoch 46/50\n","AE Train loss: 40.2295\n","AE Val loss: 488.4885\n","Epoch 47/50\n","AE Train loss: 38.9060\n","AE Val loss: 481.7862\n","Epoch 48/50\n","AE Train loss: 38.6086\n","AE Val loss: 480.0013\n","Epoch 49/50\n","AE Train loss: 38.0215\n","AE Val loss: 482.1803\n","Epoch 50/50\n","AE Train loss: 37.6420\n","AE Val loss: 481.9118\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.5796, Train Accuracy: 0.6828\n","CLF Val loss: 0.6395, Validation Accuracy: 0.6776\n","Epoch 2/50\n","CLF Train loss: 0.4423, Train Accuracy: 0.7828\n","CLF Val loss: 0.7078, Validation Accuracy: 0.6355\n","Epoch 3/50\n","CLF Train loss: 0.3513, Train Accuracy: 0.8562\n","CLF Val loss: 0.7222, Validation Accuracy: 0.6355\n","Epoch 4/50\n","CLF Train loss: 0.3235, Train Accuracy: 0.8531\n","CLF Val loss: 0.7090, Validation Accuracy: 0.6729\n","Epoch 5/50\n","CLF Train loss: 0.2540, Train Accuracy: 0.9172\n","CLF Val loss: 0.5209, Validation Accuracy: 0.7383\n","Epoch 6/50\n","CLF Train loss: 0.1935, Train Accuracy: 0.9422\n","CLF Val loss: 0.5335, Validation Accuracy: 0.7523\n","Epoch 7/50\n","CLF Train loss: 0.1623, Train Accuracy: 0.9609\n","CLF Val loss: 0.5846, Validation Accuracy: 0.7196\n","Epoch 8/50\n","CLF Train loss: 0.1331, Train Accuracy: 0.9672\n","CLF Val loss: 0.6624, Validation Accuracy: 0.7196\n","Epoch 9/50\n","CLF Train loss: 0.1721, Train Accuracy: 0.9359\n","CLF Val loss: 0.5896, Validation Accuracy: 0.7056\n","Epoch 10/50\n","CLF Train loss: 0.1169, Train Accuracy: 0.9797\n","CLF Val loss: 0.5792, Validation Accuracy: 0.7290\n","Epoch 11/50\n","CLF Train loss: 0.0903, Train Accuracy: 0.9922\n","CLF Val loss: 0.5687, Validation Accuracy: 0.7009\n","Epoch 12/50\n","CLF Train loss: 0.0904, Train Accuracy: 0.9906\n","CLF Val loss: 0.6095, Validation Accuracy: 0.7336\n","Epoch 13/50\n","CLF Train loss: 0.0877, Train Accuracy: 0.9906\n","CLF Val loss: 0.6967, Validation Accuracy: 0.7383\n","Epoch 14/50\n","CLF Train loss: 0.1241, Train Accuracy: 0.9797\n","CLF Val loss: 0.6185, Validation Accuracy: 0.7523\n","Epoch 15/50\n","CLF Train loss: 0.0814, Train Accuracy: 0.9938\n","CLF Val loss: 0.6702, Validation Accuracy: 0.7009\n","Fold 2/10\n","{'accuracy': 0.6316, 'senstivity': 0.7381, 'specificity': 0.5472, 'loss': 0.9285}\n","--------------------------------------------\n","Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 778.6284\n","AE Val loss: 709.7322\n","Epoch 2/50\n","AE Train loss: 635.0834\n","AE Val loss: 648.9687\n","Epoch 3/50\n","AE Train loss: 559.6877\n","AE Val loss: 612.8033\n","Epoch 4/50\n","AE Train loss: 501.6553\n","AE Val loss: 591.7443\n","Epoch 5/50\n","AE Train loss: 456.5119\n","AE Val loss: 576.3303\n","Epoch 6/50\n","AE Train loss: 415.6529\n","AE Val loss: 564.4938\n","Epoch 7/50\n","AE Train loss: 377.6396\n","AE Val loss: 553.8173\n","Epoch 8/50\n","AE Train loss: 344.2254\n","AE Val loss: 546.8211\n","Epoch 9/50\n","AE Train loss: 316.2870\n","AE Val loss: 540.6835\n","Epoch 10/50\n","AE Train loss: 290.0658\n","AE Val loss: 537.3045\n","Epoch 11/50\n","AE Train loss: 265.3060\n","AE Val loss: 526.1183\n","Epoch 12/50\n","AE Train loss: 242.0285\n","AE Val loss: 523.0209\n","Epoch 13/50\n","AE Train loss: 224.6739\n","AE Val loss: 522.5132\n","Epoch 14/50\n","AE Train loss: 209.0728\n","AE Val loss: 514.9710\n","Epoch 15/50\n","AE Train loss: 192.9349\n","AE Val loss: 511.7719\n","Epoch 16/50\n","AE Train loss: 179.7518\n","AE Val loss: 508.2380\n","Epoch 17/50\n","AE Train loss: 167.0860\n","AE Val loss: 504.6830\n","Epoch 18/50\n","AE Train loss: 155.7497\n","AE Val loss: 506.3123\n","Epoch 19/50\n","AE Train loss: 144.1170\n","AE Val loss: 501.1833\n","Epoch 20/50\n","AE Train loss: 134.5929\n","AE Val loss: 502.7007\n","Epoch 21/50\n","AE Train loss: 125.0901\n","AE Val loss: 499.4941\n","Epoch 22/50\n","AE Train loss: 117.7763\n","AE Val loss: 495.4491\n","Epoch 23/50\n","AE Train loss: 111.1523\n","AE Val loss: 499.7476\n","Epoch 24/50\n","AE Train loss: 104.8893\n","AE Val loss: 494.7793\n","Epoch 25/50\n","AE Train loss: 99.6801\n","AE Val loss: 493.9192\n","Epoch 26/50\n","AE Train loss: 94.1266\n","AE Val loss: 491.6714\n","Epoch 27/50\n","AE Train loss: 89.1662\n","AE Val loss: 491.8047\n","Epoch 28/50\n","AE Train loss: 83.9574\n","AE Val loss: 489.0825\n","Epoch 29/50\n","AE Train loss: 77.7519\n","AE Val loss: 488.4319\n","Epoch 30/50\n","AE Train loss: 73.6413\n","AE Val loss: 486.9692\n","Epoch 31/50\n","AE Train loss: 69.7147\n","AE Val loss: 487.2809\n","Epoch 32/50\n","AE Train loss: 66.0806\n","AE Val loss: 487.7693\n","Epoch 33/50\n","AE Train loss: 63.1610\n","AE Val loss: 488.5675\n","Epoch 34/50\n","AE Train loss: 60.4507\n","AE Val loss: 485.4743\n","Epoch 35/50\n","AE Train loss: 57.8283\n","AE Val loss: 487.5499\n","Epoch 36/50\n","AE Train loss: 55.8237\n","AE Val loss: 487.2189\n","Epoch 37/50\n","AE Train loss: 53.7566\n","AE Val loss: 484.8779\n","Epoch 38/50\n","AE Train loss: 51.4599\n","AE Val loss: 485.6717\n","Epoch 39/50\n","AE Train loss: 49.6944\n","AE Val loss: 485.7485\n","Epoch 40/50\n","AE Train loss: 47.9798\n","AE Val loss: 484.9538\n","Epoch 41/50\n","AE Train loss: 45.7218\n","AE Val loss: 483.4873\n","Epoch 42/50\n","AE Train loss: 43.3955\n","AE Val loss: 486.8894\n","Epoch 43/50\n","AE Train loss: 41.9390\n","AE Val loss: 483.0191\n","Epoch 44/50\n","AE Train loss: 41.2800\n","AE Val loss: 484.4358\n","Epoch 45/50\n","AE Train loss: 40.6365\n","AE Val loss: 484.3545\n","Epoch 46/50\n","AE Train loss: 40.6512\n","AE Val loss: 485.4109\n","Epoch 47/50\n","AE Train loss: 39.7228\n","AE Val loss: 483.2879\n","Epoch 48/50\n","AE Train loss: 38.6638\n","AE Val loss: 488.3099\n","Epoch 49/50\n","AE Train loss: 38.2383\n","AE Val loss: 484.2686\n","Epoch 50/50\n","AE Train loss: 37.1436\n","AE Val loss: 483.3433\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6061, Train Accuracy: 0.6719\n","CLF Val loss: 0.5467, Validation Accuracy: 0.7103\n","Epoch 2/50\n","CLF Train loss: 0.4462, Train Accuracy: 0.7953\n","CLF Val loss: 0.5395, Validation Accuracy: 0.6916\n","Epoch 3/50\n","CLF Train loss: 0.3281, Train Accuracy: 0.8719\n","CLF Val loss: 0.5909, Validation Accuracy: 0.7196\n","Epoch 4/50\n","CLF Train loss: 0.3603, Train Accuracy: 0.8516\n","CLF Val loss: 0.5596, Validation Accuracy: 0.6869\n","Epoch 5/50\n","CLF Train loss: 0.3153, Train Accuracy: 0.8797\n","CLF Val loss: 0.5329, Validation Accuracy: 0.7243\n","Epoch 6/50\n","CLF Train loss: 0.1836, Train Accuracy: 0.9500\n","CLF Val loss: 0.5852, Validation Accuracy: 0.7243\n","Epoch 7/50\n","CLF Train loss: 0.1720, Train Accuracy: 0.9578\n","CLF Val loss: 0.5175, Validation Accuracy: 0.6963\n","Epoch 8/50\n","CLF Train loss: 0.1371, Train Accuracy: 0.9734\n","CLF Val loss: 0.5723, Validation Accuracy: 0.6963\n","Epoch 9/50\n","CLF Train loss: 0.1117, Train Accuracy: 0.9859\n","CLF Val loss: 0.5464, Validation Accuracy: 0.7150\n","Epoch 10/50\n","CLF Train loss: 0.1110, Train Accuracy: 0.9844\n","CLF Val loss: 0.5694, Validation Accuracy: 0.6822\n","Epoch 11/50\n","CLF Train loss: 0.1004, Train Accuracy: 0.9922\n","CLF Val loss: 0.5334, Validation Accuracy: 0.7196\n","Epoch 12/50\n","CLF Train loss: 0.1021, Train Accuracy: 0.9859\n","CLF Val loss: 0.5846, Validation Accuracy: 0.7009\n","Epoch 13/50\n","CLF Train loss: 0.1176, Train Accuracy: 0.9844\n","CLF Val loss: 0.6019, Validation Accuracy: 0.7009\n","Epoch 14/50\n","CLF Train loss: 0.0880, Train Accuracy: 0.9891\n","CLF Val loss: 0.7023, Validation Accuracy: 0.6869\n","Fold 3/10\n","{'accuracy': 0.7053, 'senstivity': 0.381, 'specificity': 0.9623, 'loss': 0.6752}\n","--------------------------------------------\n","Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 771.0414\n","AE Val loss: 697.2612\n","Epoch 2/50\n","AE Train loss: 628.2855\n","AE Val loss: 636.3954\n","Epoch 3/50\n","AE Train loss: 556.8401\n","AE Val loss: 603.9059\n","Epoch 4/50\n","AE Train loss: 498.5224\n","AE Val loss: 582.8543\n","Epoch 5/50\n","AE Train loss: 451.0625\n","AE Val loss: 570.9599\n","Epoch 6/50\n","AE Train loss: 412.6468\n","AE Val loss: 553.9323\n","Epoch 7/50\n","AE Train loss: 373.4583\n","AE Val loss: 545.1965\n","Epoch 8/50\n","AE Train loss: 341.8673\n","AE Val loss: 535.0615\n","Epoch 9/50\n","AE Train loss: 311.0723\n","AE Val loss: 527.6479\n","Epoch 10/50\n","AE Train loss: 283.7621\n","AE Val loss: 522.5379\n","Epoch 11/50\n","AE Train loss: 261.5107\n","AE Val loss: 522.1839\n","Epoch 12/50\n","AE Train loss: 242.4607\n","AE Val loss: 512.1826\n","Epoch 13/50\n","AE Train loss: 224.2487\n","AE Val loss: 510.0201\n","Epoch 14/50\n","AE Train loss: 209.8081\n","AE Val loss: 512.7165\n","Epoch 15/50\n","AE Train loss: 192.8415\n","AE Val loss: 502.8234\n","Epoch 16/50\n","AE Train loss: 177.4090\n","AE Val loss: 503.8018\n","Epoch 17/50\n","AE Train loss: 163.9054\n","AE Val loss: 498.1769\n","Epoch 18/50\n","AE Train loss: 153.0868\n","AE Val loss: 505.8304\n","Epoch 19/50\n","AE Train loss: 141.7141\n","AE Val loss: 491.5864\n","Epoch 20/50\n","AE Train loss: 131.8631\n","AE Val loss: 492.3498\n","Epoch 21/50\n","AE Train loss: 123.8557\n","AE Val loss: 490.2847\n","Epoch 22/50\n","AE Train loss: 116.6556\n","AE Val loss: 487.8354\n","Epoch 23/50\n","AE Train loss: 110.5183\n","AE Val loss: 487.2003\n","Epoch 24/50\n","AE Train loss: 104.1872\n","AE Val loss: 490.4055\n","Epoch 25/50\n","AE Train loss: 98.6577\n","AE Val loss: 484.8023\n","Epoch 26/50\n","AE Train loss: 93.2807\n","AE Val loss: 484.4716\n","Epoch 27/50\n","AE Train loss: 87.5943\n","AE Val loss: 486.9538\n","Epoch 28/50\n","AE Train loss: 82.7371\n","AE Val loss: 486.6809\n","Epoch 29/50\n","AE Train loss: 78.5658\n","AE Val loss: 481.4827\n","Epoch 30/50\n","AE Train loss: 74.5649\n","AE Val loss: 481.8000\n","Epoch 31/50\n","AE Train loss: 70.5064\n","AE Val loss: 480.4552\n","Epoch 32/50\n","AE Train loss: 67.2690\n","AE Val loss: 479.3542\n","Epoch 33/50\n","AE Train loss: 63.9174\n","AE Val loss: 483.0036\n","Epoch 34/50\n","AE Train loss: 61.1373\n","AE Val loss: 480.4763\n","Epoch 35/50\n","AE Train loss: 57.7507\n","AE Val loss: 477.7855\n","Epoch 36/50\n","AE Train loss: 54.7825\n","AE Val loss: 481.1344\n","Epoch 37/50\n","AE Train loss: 53.2167\n","AE Val loss: 478.4653\n","Epoch 38/50\n","AE Train loss: 51.5585\n","AE Val loss: 477.4323\n","Epoch 39/50\n","AE Train loss: 49.7238\n","AE Val loss: 478.7092\n","Epoch 40/50\n","AE Train loss: 48.1653\n","AE Val loss: 476.8555\n","Epoch 41/50\n","AE Train loss: 47.0578\n","AE Val loss: 476.4548\n","Epoch 42/50\n","AE Train loss: 44.6952\n","AE Val loss: 479.8442\n","Epoch 43/50\n","AE Train loss: 41.9931\n","AE Val loss: 475.8439\n","Epoch 44/50\n","AE Train loss: 40.8256\n","AE Val loss: 475.5049\n","Epoch 45/50\n","AE Train loss: 40.0063\n","AE Val loss: 477.7051\n","Epoch 46/50\n","AE Train loss: 39.4374\n","AE Val loss: 474.6346\n","Epoch 47/50\n","AE Train loss: 37.6214\n","AE Val loss: 475.9237\n","Epoch 48/50\n","AE Train loss: 36.1261\n","AE Val loss: 474.5804\n","Epoch 49/50\n","AE Train loss: 34.4975\n","AE Val loss: 476.2357\n","Epoch 50/50\n","AE Train loss: 34.0447\n","AE Val loss: 474.0989\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6439, Train Accuracy: 0.6406\n","CLF Val loss: 0.6760, Validation Accuracy: 0.6308\n","Epoch 2/50\n","CLF Train loss: 0.4451, Train Accuracy: 0.7953\n","CLF Val loss: 0.5770, Validation Accuracy: 0.6822\n","Epoch 3/50\n","CLF Train loss: 0.3483, Train Accuracy: 0.8625\n","CLF Val loss: 0.5830, Validation Accuracy: 0.7150\n","Epoch 4/50\n","CLF Train loss: 0.2793, Train Accuracy: 0.9078\n","CLF Val loss: 0.7613, Validation Accuracy: 0.6495\n","Epoch 5/50\n","CLF Train loss: 0.3009, Train Accuracy: 0.8750\n","CLF Val loss: 0.6379, Validation Accuracy: 0.7150\n","Epoch 6/50\n","CLF Train loss: 0.2035, Train Accuracy: 0.9375\n","CLF Val loss: 0.9969, Validation Accuracy: 0.5514\n","Epoch 7/50\n","CLF Train loss: 0.2594, Train Accuracy: 0.8953\n","CLF Val loss: 0.6554, Validation Accuracy: 0.6963\n","Epoch 8/50\n","CLF Train loss: 0.1592, Train Accuracy: 0.9563\n","CLF Val loss: 0.8143, Validation Accuracy: 0.6449\n","Epoch 9/50\n","CLF Train loss: 0.1318, Train Accuracy: 0.9719\n","CLF Val loss: 0.6183, Validation Accuracy: 0.7009\n","Epoch 10/50\n","CLF Train loss: 0.0973, Train Accuracy: 0.9906\n","CLF Val loss: 0.6050, Validation Accuracy: 0.7196\n","Epoch 11/50\n","CLF Train loss: 0.0842, Train Accuracy: 0.9953\n","CLF Val loss: 0.6973, Validation Accuracy: 0.6822\n","Epoch 12/50\n","CLF Train loss: 0.0944, Train Accuracy: 0.9875\n","CLF Val loss: 0.6235, Validation Accuracy: 0.7056\n","Epoch 13/50\n","CLF Train loss: 0.0983, Train Accuracy: 0.9938\n","CLF Val loss: 0.7460, Validation Accuracy: 0.6916\n","Epoch 14/50\n","CLF Train loss: 0.1020, Train Accuracy: 0.9812\n","CLF Val loss: 0.6264, Validation Accuracy: 0.7290\n","Epoch 15/50\n","CLF Train loss: 0.0790, Train Accuracy: 0.9953\n","CLF Val loss: 0.6593, Validation Accuracy: 0.7056\n","Epoch 16/50\n","CLF Train loss: 0.0752, Train Accuracy: 0.9984\n","CLF Val loss: 0.6517, Validation Accuracy: 0.7290\n","Epoch 17/50\n","CLF Train loss: 0.0790, Train Accuracy: 0.9891\n","CLF Val loss: 0.6667, Validation Accuracy: 0.6822\n","Epoch 18/50\n","CLF Train loss: 0.0922, Train Accuracy: 0.9906\n","CLF Val loss: 0.6687, Validation Accuracy: 0.6916\n","Epoch 19/50\n","CLF Train loss: 0.0851, Train Accuracy: 0.9875\n","CLF Val loss: 0.6839, Validation Accuracy: 0.6963\n","Epoch 20/50\n","CLF Train loss: 0.1021, Train Accuracy: 0.9781\n","CLF Val loss: 0.8359, Validation Accuracy: 0.6682\n","Epoch 21/50\n","CLF Train loss: 0.0841, Train Accuracy: 0.9922\n","CLF Val loss: 0.6547, Validation Accuracy: 0.7196\n","Epoch 22/50\n","CLF Train loss: 0.0637, Train Accuracy: 0.9938\n","CLF Val loss: 0.6749, Validation Accuracy: 0.7150\n","Epoch 23/50\n","CLF Train loss: 0.0580, Train Accuracy: 1.0000\n","CLF Val loss: 0.7296, Validation Accuracy: 0.6636\n","Fold 4/10\n","{'accuracy': 0.6526, 'senstivity': 0.7857, 'specificity': 0.5472, 'loss': 0.7684}\n","--------------------------------------------\n","Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 777.5764\n","AE Val loss: 711.3439\n","Epoch 2/50\n","AE Train loss: 633.4976\n","AE Val loss: 656.1334\n","Epoch 3/50\n","AE Train loss: 558.8643\n","AE Val loss: 619.5024\n","Epoch 4/50\n","AE Train loss: 499.9973\n","AE Val loss: 600.0967\n","Epoch 5/50\n","AE Train loss: 454.5352\n","AE Val loss: 582.4124\n","Epoch 6/50\n","AE Train loss: 414.9163\n","AE Val loss: 574.3734\n","Epoch 7/50\n","AE Train loss: 376.6568\n","AE Val loss: 561.3574\n","Epoch 8/50\n","AE Train loss: 342.2934\n","AE Val loss: 552.1042\n","Epoch 9/50\n","AE Train loss: 312.5290\n","AE Val loss: 546.6374\n","Epoch 10/50\n","AE Train loss: 285.4992\n","AE Val loss: 535.4916\n","Epoch 11/50\n","AE Train loss: 262.1251\n","AE Val loss: 531.5449\n","Epoch 12/50\n","AE Train loss: 242.4611\n","AE Val loss: 535.8706\n","Epoch 13/50\n","AE Train loss: 226.8138\n","AE Val loss: 530.5333\n","Epoch 14/50\n","AE Train loss: 210.2194\n","AE Val loss: 532.5402\n","Epoch 15/50\n","AE Train loss: 194.6337\n","AE Val loss: 519.6555\n","Epoch 16/50\n","AE Train loss: 180.3297\n","AE Val loss: 513.8888\n","Epoch 17/50\n","AE Train loss: 166.7251\n","AE Val loss: 511.1495\n","Epoch 18/50\n","AE Train loss: 154.5952\n","AE Val loss: 510.1095\n","Epoch 19/50\n","AE Train loss: 144.8627\n","AE Val loss: 506.3401\n","Epoch 20/50\n","AE Train loss: 137.3796\n","AE Val loss: 506.2991\n","Epoch 21/50\n","AE Train loss: 128.8232\n","AE Val loss: 506.5589\n","Epoch 22/50\n","AE Train loss: 119.9124\n","AE Val loss: 500.3788\n","Epoch 23/50\n","AE Train loss: 113.2557\n","AE Val loss: 503.6562\n","Epoch 24/50\n","AE Train loss: 106.2400\n","AE Val loss: 501.0804\n","Epoch 25/50\n","AE Train loss: 100.0595\n","AE Val loss: 500.1461\n","Epoch 26/50\n","AE Train loss: 94.3587\n","AE Val loss: 508.2200\n","Epoch 27/50\n","AE Train loss: 90.6988\n","AE Val loss: 499.0939\n","Epoch 28/50\n","AE Train loss: 85.7584\n","AE Val loss: 498.0948\n","Epoch 29/50\n","AE Train loss: 80.1618\n","AE Val loss: 500.9134\n","Epoch 30/50\n","AE Train loss: 75.5288\n","AE Val loss: 494.5200\n","Epoch 31/50\n","AE Train loss: 72.2005\n","AE Val loss: 494.5708\n","Epoch 32/50\n","AE Train loss: 69.0387\n","AE Val loss: 494.1964\n","Epoch 33/50\n","AE Train loss: 66.1574\n","AE Val loss: 493.6104\n","Epoch 34/50\n","AE Train loss: 62.7493\n","AE Val loss: 492.6804\n","Epoch 35/50\n","AE Train loss: 59.5365\n","AE Val loss: 492.4297\n","Epoch 36/50\n","AE Train loss: 57.2765\n","AE Val loss: 492.5330\n","Epoch 37/50\n","AE Train loss: 54.3517\n","AE Val loss: 490.2754\n","Epoch 38/50\n","AE Train loss: 51.3696\n","AE Val loss: 490.7259\n","Epoch 39/50\n","AE Train loss: 48.7694\n","AE Val loss: 488.6092\n","Epoch 40/50\n","AE Train loss: 46.3385\n","AE Val loss: 488.6563\n","Epoch 41/50\n","AE Train loss: 44.3327\n","AE Val loss: 489.0153\n","Epoch 42/50\n","AE Train loss: 42.4636\n","AE Val loss: 486.8968\n","Epoch 43/50\n","AE Train loss: 41.5536\n","AE Val loss: 487.5568\n","Epoch 44/50\n","AE Train loss: 40.4536\n","AE Val loss: 488.8274\n","Epoch 45/50\n","AE Train loss: 40.0506\n","AE Val loss: 490.9908\n","Epoch 46/50\n","AE Train loss: 39.4433\n","AE Val loss: 487.7405\n","Epoch 47/50\n","AE Train loss: 38.0722\n","AE Val loss: 490.0594\n","Epoch 48/50\n","AE Train loss: 37.4610\n","AE Val loss: 493.0464\n","Epoch 49/50\n","AE Train loss: 37.0584\n","AE Val loss: 487.5769\n","Epoch 50/50\n","AE Train loss: 36.2169\n","AE Val loss: 489.2949\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6095, Train Accuracy: 0.6703\n","CLF Val loss: 0.6229, Validation Accuracy: 0.6589\n","Epoch 2/50\n","CLF Train loss: 0.4958, Train Accuracy: 0.7562\n","CLF Val loss: 0.5879, Validation Accuracy: 0.6636\n","Epoch 3/50\n","CLF Train loss: 0.3950, Train Accuracy: 0.8469\n","CLF Val loss: 0.5621, Validation Accuracy: 0.7150\n","Epoch 4/50\n","CLF Train loss: 0.2738, Train Accuracy: 0.9125\n","CLF Val loss: 0.5507, Validation Accuracy: 0.7150\n","Epoch 5/50\n","CLF Train loss: 0.2068, Train Accuracy: 0.9437\n","CLF Val loss: 0.5683, Validation Accuracy: 0.7383\n","Epoch 6/50\n","CLF Train loss: 0.2378, Train Accuracy: 0.8984\n","CLF Val loss: 0.5419, Validation Accuracy: 0.6869\n","Epoch 7/50\n","CLF Train loss: 0.1544, Train Accuracy: 0.9734\n","CLF Val loss: 0.5624, Validation Accuracy: 0.7336\n","Epoch 8/50\n","CLF Train loss: 0.1251, Train Accuracy: 0.9766\n","CLF Val loss: 0.5571, Validation Accuracy: 0.7150\n","Epoch 9/50\n","CLF Train loss: 0.1147, Train Accuracy: 0.9875\n","CLF Val loss: 0.5699, Validation Accuracy: 0.7150\n","Epoch 10/50\n","CLF Train loss: 0.1033, Train Accuracy: 0.9938\n","CLF Val loss: 0.5526, Validation Accuracy: 0.7523\n","Epoch 11/50\n","CLF Train loss: 0.1225, Train Accuracy: 0.9688\n","CLF Val loss: 0.6195, Validation Accuracy: 0.7103\n","Epoch 12/50\n","CLF Train loss: 0.1331, Train Accuracy: 0.9688\n","CLF Val loss: 0.7649, Validation Accuracy: 0.6495\n","Epoch 13/50\n","CLF Train loss: 0.1465, Train Accuracy: 0.9594\n","CLF Val loss: 0.8218, Validation Accuracy: 0.6215\n","Epoch 14/50\n","CLF Train loss: 0.1217, Train Accuracy: 0.9656\n","CLF Val loss: 0.5627, Validation Accuracy: 0.7243\n","Epoch 15/50\n","CLF Train loss: 0.0684, Train Accuracy: 0.9984\n","CLF Val loss: 0.5471, Validation Accuracy: 0.6963\n","Epoch 16/50\n","CLF Train loss: 0.0766, Train Accuracy: 0.9969\n","CLF Val loss: 0.5711, Validation Accuracy: 0.7009\n","Epoch 17/50\n","CLF Train loss: 0.0685, Train Accuracy: 1.0000\n","CLF Val loss: 0.5726, Validation Accuracy: 0.7477\n","Epoch 18/50\n","CLF Train loss: 0.0752, Train Accuracy: 0.9953\n","CLF Val loss: 0.5539, Validation Accuracy: 0.7196\n","Epoch 19/50\n","CLF Train loss: 0.0662, Train Accuracy: 0.9984\n","CLF Val loss: 0.5720, Validation Accuracy: 0.7196\n","Fold 5/10\n","{'accuracy': 0.7684, 'senstivity': 0.619, 'specificity': 0.8868, 'loss': 0.5798}\n","--------------------------------------------\n","Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 769.9509\n","AE Val loss: 709.1245\n","Epoch 2/50\n","AE Train loss: 630.6284\n","AE Val loss: 650.4703\n","Epoch 3/50\n","AE Train loss: 558.2589\n","AE Val loss: 615.9398\n","Epoch 4/50\n","AE Train loss: 501.8830\n","AE Val loss: 598.1865\n","Epoch 5/50\n","AE Train loss: 456.2451\n","AE Val loss: 577.5876\n","Epoch 6/50\n","AE Train loss: 411.7526\n","AE Val loss: 563.8622\n","Epoch 7/50\n","AE Train loss: 373.3583\n","AE Val loss: 550.2026\n","Epoch 8/50\n","AE Train loss: 340.2115\n","AE Val loss: 540.0250\n","Epoch 9/50\n","AE Train loss: 310.7162\n","AE Val loss: 535.8237\n","Epoch 10/50\n","AE Train loss: 285.9016\n","AE Val loss: 536.6817\n","Epoch 11/50\n","AE Train loss: 262.1501\n","AE Val loss: 528.6107\n","Epoch 12/50\n","AE Train loss: 241.1745\n","AE Val loss: 518.4803\n","Epoch 13/50\n","AE Train loss: 223.3054\n","AE Val loss: 513.9784\n","Epoch 14/50\n","AE Train loss: 206.5586\n","AE Val loss: 510.5430\n","Epoch 15/50\n","AE Train loss: 192.3331\n","AE Val loss: 510.6078\n","Epoch 16/50\n","AE Train loss: 178.0965\n","AE Val loss: 505.3183\n","Epoch 17/50\n","AE Train loss: 165.5930\n","AE Val loss: 501.8055\n","Epoch 18/50\n","AE Train loss: 158.7336\n","AE Val loss: 508.7460\n","Epoch 19/50\n","AE Train loss: 149.4756\n","AE Val loss: 501.9336\n","Epoch 20/50\n","AE Train loss: 137.9747\n","AE Val loss: 498.0904\n","Epoch 21/50\n","AE Train loss: 127.7202\n","AE Val loss: 495.0678\n","Epoch 22/50\n","AE Train loss: 119.8251\n","AE Val loss: 493.8544\n","Epoch 23/50\n","AE Train loss: 112.2985\n","AE Val loss: 493.3774\n","Epoch 24/50\n","AE Train loss: 106.6580\n","AE Val loss: 492.9472\n","Epoch 25/50\n","AE Train loss: 99.1067\n","AE Val loss: 490.4380\n","Epoch 26/50\n","AE Train loss: 92.8541\n","AE Val loss: 488.7856\n","Epoch 27/50\n","AE Train loss: 86.8089\n","AE Val loss: 487.0618\n","Epoch 28/50\n","AE Train loss: 82.6010\n","AE Val loss: 485.5260\n","Epoch 29/50\n","AE Train loss: 78.2854\n","AE Val loss: 485.9346\n","Epoch 30/50\n","AE Train loss: 74.1642\n","AE Val loss: 485.1470\n","Epoch 31/50\n","AE Train loss: 71.2956\n","AE Val loss: 486.0062\n","Epoch 32/50\n","AE Train loss: 67.3002\n","AE Val loss: 483.3157\n","Epoch 33/50\n","AE Train loss: 64.0632\n","AE Val loss: 483.9150\n","Epoch 34/50\n","AE Train loss: 61.4135\n","AE Val loss: 485.1813\n","Epoch 35/50\n","AE Train loss: 58.4791\n","AE Val loss: 482.7029\n","Epoch 36/50\n","AE Train loss: 56.0039\n","AE Val loss: 489.0376\n","Epoch 37/50\n","AE Train loss: 54.5601\n","AE Val loss: 481.4638\n","Epoch 38/50\n","AE Train loss: 51.8939\n","AE Val loss: 482.6324\n","Epoch 39/50\n","AE Train loss: 49.4606\n","AE Val loss: 482.4822\n","Epoch 40/50\n","AE Train loss: 47.7664\n","AE Val loss: 482.6112\n","Epoch 41/50\n","AE Train loss: 46.2978\n","AE Val loss: 479.9163\n","Epoch 42/50\n","AE Train loss: 45.0960\n","AE Val loss: 480.8087\n","Epoch 43/50\n","AE Train loss: 43.9327\n","AE Val loss: 482.2136\n","Epoch 44/50\n","AE Train loss: 41.6152\n","AE Val loss: 478.7923\n","Epoch 45/50\n","AE Train loss: 40.1061\n","AE Val loss: 480.1666\n","Epoch 46/50\n","AE Train loss: 39.2256\n","AE Val loss: 479.4352\n","Epoch 47/50\n","AE Train loss: 37.7783\n","AE Val loss: 479.0506\n","Epoch 48/50\n","AE Train loss: 36.8632\n","AE Val loss: 479.5509\n","Epoch 49/50\n","AE Train loss: 34.9845\n","AE Val loss: 477.5855\n","Epoch 50/50\n","AE Train loss: 33.2215\n","AE Val loss: 479.6485\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6471, Train Accuracy: 0.6453\n","CLF Val loss: 0.5194, Validation Accuracy: 0.7570\n","Epoch 2/50\n","CLF Train loss: 0.4728, Train Accuracy: 0.8016\n","CLF Val loss: 0.5354, Validation Accuracy: 0.7196\n","Epoch 3/50\n","CLF Train loss: 0.3946, Train Accuracy: 0.8266\n","CLF Val loss: 0.5507, Validation Accuracy: 0.7290\n","Epoch 4/50\n","CLF Train loss: 0.3083, Train Accuracy: 0.8828\n","CLF Val loss: 0.6651, Validation Accuracy: 0.6355\n","Epoch 5/50\n","CLF Train loss: 0.3368, Train Accuracy: 0.8562\n","CLF Val loss: 0.6442, Validation Accuracy: 0.6495\n","Epoch 6/50\n","CLF Train loss: 0.2088, Train Accuracy: 0.9422\n","CLF Val loss: 0.4594, Validation Accuracy: 0.7804\n","Epoch 7/50\n","CLF Train loss: 0.1517, Train Accuracy: 0.9719\n","CLF Val loss: 0.5300, Validation Accuracy: 0.7570\n","Epoch 8/50\n","CLF Train loss: 0.1626, Train Accuracy: 0.9547\n","CLF Val loss: 0.6646, Validation Accuracy: 0.6776\n","Epoch 9/50\n","CLF Train loss: 0.1837, Train Accuracy: 0.9563\n","CLF Val loss: 0.5448, Validation Accuracy: 0.7383\n","Epoch 10/50\n","CLF Train loss: 0.1227, Train Accuracy: 0.9812\n","CLF Val loss: 0.5474, Validation Accuracy: 0.7196\n","Epoch 11/50\n","CLF Train loss: 0.1052, Train Accuracy: 0.9891\n","CLF Val loss: 0.4805, Validation Accuracy: 0.8037\n","Epoch 12/50\n","CLF Train loss: 0.1208, Train Accuracy: 0.9766\n","CLF Val loss: 0.5596, Validation Accuracy: 0.7103\n","Epoch 13/50\n","CLF Train loss: 0.1058, Train Accuracy: 0.9828\n","CLF Val loss: 0.5850, Validation Accuracy: 0.7196\n","Epoch 14/50\n","CLF Train loss: 0.1051, Train Accuracy: 0.9875\n","CLF Val loss: 0.5122, Validation Accuracy: 0.7243\n","Epoch 15/50\n","CLF Train loss: 0.0879, Train Accuracy: 0.9938\n","CLF Val loss: 0.5214, Validation Accuracy: 0.7383\n","Epoch 16/50\n","CLF Train loss: 0.0925, Train Accuracy: 0.9875\n","CLF Val loss: 0.5268, Validation Accuracy: 0.7523\n","Epoch 17/50\n","CLF Train loss: 0.0936, Train Accuracy: 0.9922\n","CLF Val loss: 0.4952, Validation Accuracy: 0.7477\n","Epoch 18/50\n","CLF Train loss: 0.0772, Train Accuracy: 0.9938\n","CLF Val loss: 0.4822, Validation Accuracy: 0.7523\n","Epoch 19/50\n","CLF Train loss: 0.0774, Train Accuracy: 0.9953\n","CLF Val loss: 0.6281, Validation Accuracy: 0.7196\n","Epoch 20/50\n","CLF Train loss: 0.0888, Train Accuracy: 0.9922\n","CLF Val loss: 0.4893, Validation Accuracy: 0.7664\n","Fold 6/10\n","{'accuracy': 0.7895, 'senstivity': 0.7143, 'specificity': 0.8491, 'loss': 0.4647}\n","--------------------------------------------\n","Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 772.8717\n","AE Val loss: 706.5956\n","Epoch 2/50\n","AE Train loss: 628.1357\n","AE Val loss: 646.5157\n","Epoch 3/50\n","AE Train loss: 554.9141\n","AE Val loss: 610.0867\n","Epoch 4/50\n","AE Train loss: 496.8113\n","AE Val loss: 589.6959\n","Epoch 5/50\n","AE Train loss: 453.2306\n","AE Val loss: 573.4763\n","Epoch 6/50\n","AE Train loss: 412.4868\n","AE Val loss: 560.9930\n","Epoch 7/50\n","AE Train loss: 376.3234\n","AE Val loss: 553.0426\n","Epoch 8/50\n","AE Train loss: 342.3035\n","AE Val loss: 538.7949\n","Epoch 9/50\n","AE Train loss: 310.9695\n","AE Val loss: 533.5322\n","Epoch 10/50\n","AE Train loss: 286.1821\n","AE Val loss: 527.4705\n","Epoch 11/50\n","AE Train loss: 262.3851\n","AE Val loss: 522.5098\n","Epoch 12/50\n","AE Train loss: 241.2852\n","AE Val loss: 515.6090\n","Epoch 13/50\n","AE Train loss: 222.8188\n","AE Val loss: 512.0062\n","Epoch 14/50\n","AE Train loss: 206.0807\n","AE Val loss: 513.8271\n","Epoch 15/50\n","AE Train loss: 191.1898\n","AE Val loss: 508.4995\n","Epoch 16/50\n","AE Train loss: 177.4698\n","AE Val loss: 502.7139\n","Epoch 17/50\n","AE Train loss: 166.0369\n","AE Val loss: 513.9866\n","Epoch 18/50\n","AE Train loss: 155.2722\n","AE Val loss: 499.5795\n","Epoch 19/50\n","AE Train loss: 143.8643\n","AE Val loss: 499.9093\n","Epoch 20/50\n","AE Train loss: 135.6969\n","AE Val loss: 496.2396\n","Epoch 21/50\n","AE Train loss: 127.1520\n","AE Val loss: 495.6482\n","Epoch 22/50\n","AE Train loss: 119.9897\n","AE Val loss: 493.0778\n","Epoch 23/50\n","AE Train loss: 112.7644\n","AE Val loss: 490.6594\n","Epoch 24/50\n","AE Train loss: 105.2918\n","AE Val loss: 490.5562\n","Epoch 25/50\n","AE Train loss: 98.5699\n","AE Val loss: 486.9732\n","Epoch 26/50\n","AE Train loss: 93.0418\n","AE Val loss: 486.0913\n","Epoch 27/50\n","AE Train loss: 87.4466\n","AE Val loss: 484.0536\n","Epoch 28/50\n","AE Train loss: 82.6730\n","AE Val loss: 489.4664\n","Epoch 29/50\n","AE Train loss: 78.4310\n","AE Val loss: 483.1863\n","Epoch 30/50\n","AE Train loss: 73.8613\n","AE Val loss: 483.8986\n","Epoch 31/50\n","AE Train loss: 70.6153\n","AE Val loss: 486.5009\n","Epoch 32/50\n","AE Train loss: 66.9039\n","AE Val loss: 482.4139\n","Epoch 33/50\n","AE Train loss: 63.4232\n","AE Val loss: 485.7877\n","Epoch 34/50\n","AE Train loss: 61.4515\n","AE Val loss: 484.9954\n","Epoch 35/50\n","AE Train loss: 59.3723\n","AE Val loss: 480.0571\n","Epoch 36/50\n","AE Train loss: 56.4355\n","AE Val loss: 481.5306\n","Epoch 37/50\n","AE Train loss: 53.3781\n","AE Val loss: 481.6675\n","Epoch 38/50\n","AE Train loss: 50.5614\n","AE Val loss: 477.6092\n","Epoch 39/50\n","AE Train loss: 48.7872\n","AE Val loss: 480.4767\n","Epoch 40/50\n","AE Train loss: 47.0087\n","AE Val loss: 477.8416\n","Epoch 41/50\n","AE Train loss: 45.8910\n","AE Val loss: 480.5699\n","Epoch 42/50\n","AE Train loss: 44.2157\n","AE Val loss: 477.7000\n","Epoch 43/50\n","AE Train loss: 42.0706\n","AE Val loss: 478.0952\n","Epoch 44/50\n","AE Train loss: 40.1067\n","AE Val loss: 479.2358\n","Epoch 45/50\n","AE Train loss: 38.3088\n","AE Val loss: 476.7444\n","Epoch 46/50\n","AE Train loss: 37.4562\n","AE Val loss: 476.9517\n","Epoch 47/50\n","AE Train loss: 36.7861\n","AE Val loss: 479.9414\n","Epoch 48/50\n","AE Train loss: 35.9492\n","AE Val loss: 477.2929\n","Epoch 49/50\n","AE Train loss: 34.8533\n","AE Val loss: 477.4424\n","Epoch 50/50\n","AE Train loss: 34.1152\n","AE Val loss: 478.3869\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6017, Train Accuracy: 0.6641\n","CLF Val loss: 0.5643, Validation Accuracy: 0.7290\n","Epoch 2/50\n","CLF Train loss: 0.4373, Train Accuracy: 0.8125\n","CLF Val loss: 0.6071, Validation Accuracy: 0.6963\n","Epoch 3/50\n","CLF Train loss: 0.3295, Train Accuracy: 0.8719\n","CLF Val loss: 0.5500, Validation Accuracy: 0.7056\n","Epoch 4/50\n","CLF Train loss: 0.2682, Train Accuracy: 0.9141\n","CLF Val loss: 0.7509, Validation Accuracy: 0.6822\n","Epoch 5/50\n","CLF Train loss: 0.2190, Train Accuracy: 0.9328\n","CLF Val loss: 0.5786, Validation Accuracy: 0.7150\n","Epoch 6/50\n","CLF Train loss: 0.2156, Train Accuracy: 0.9156\n","CLF Val loss: 0.6485, Validation Accuracy: 0.6869\n","Epoch 7/50\n","CLF Train loss: 0.2116, Train Accuracy: 0.9250\n","CLF Val loss: 0.6906, Validation Accuracy: 0.7243\n","Epoch 8/50\n","CLF Train loss: 0.1560, Train Accuracy: 0.9766\n","CLF Val loss: 0.5742, Validation Accuracy: 0.7430\n","Epoch 9/50\n","CLF Train loss: 0.1303, Train Accuracy: 0.9750\n","CLF Val loss: 0.6118, Validation Accuracy: 0.7523\n","Epoch 10/50\n","CLF Train loss: 0.1219, Train Accuracy: 0.9828\n","CLF Val loss: 0.7734, Validation Accuracy: 0.6963\n","Epoch 11/50\n","CLF Train loss: 0.1465, Train Accuracy: 0.9594\n","CLF Val loss: 0.5840, Validation Accuracy: 0.7103\n","Epoch 12/50\n","CLF Train loss: 0.0942, Train Accuracy: 0.9906\n","CLF Val loss: 0.5667, Validation Accuracy: 0.7196\n","Epoch 13/50\n","CLF Train loss: 0.0808, Train Accuracy: 0.9953\n","CLF Val loss: 0.5456, Validation Accuracy: 0.7664\n","Epoch 14/50\n","CLF Train loss: 0.0811, Train Accuracy: 0.9953\n","CLF Val loss: 0.6876, Validation Accuracy: 0.7103\n","Epoch 15/50\n","CLF Train loss: 0.1026, Train Accuracy: 0.9797\n","CLF Val loss: 0.6720, Validation Accuracy: 0.7383\n","Epoch 16/50\n","CLF Train loss: 0.0849, Train Accuracy: 0.9922\n","CLF Val loss: 0.5884, Validation Accuracy: 0.7383\n","Epoch 17/50\n","CLF Train loss: 0.0703, Train Accuracy: 0.9938\n","CLF Val loss: 0.6041, Validation Accuracy: 0.7430\n","Epoch 18/50\n","CLF Train loss: 0.0683, Train Accuracy: 0.9969\n","CLF Val loss: 0.5625, Validation Accuracy: 0.7383\n","Epoch 19/50\n","CLF Train loss: 0.0635, Train Accuracy: 0.9969\n","CLF Val loss: 0.5584, Validation Accuracy: 0.7383\n","Epoch 20/50\n","CLF Train loss: 0.0717, Train Accuracy: 0.9953\n","CLF Val loss: 0.6302, Validation Accuracy: 0.6916\n","Epoch 21/50\n","CLF Train loss: 0.0841, Train Accuracy: 0.9938\n","CLF Val loss: 0.6459, Validation Accuracy: 0.7196\n","Epoch 22/50\n","CLF Train loss: 0.0811, Train Accuracy: 0.9922\n","CLF Val loss: 0.5909, Validation Accuracy: 0.7477\n","Fold 7/10\n","{'accuracy': 0.7368, 'senstivity': 0.7381, 'specificity': 0.7358, 'loss': 0.6684}\n","--------------------------------------------\n","Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 779.7555\n","AE Val loss: 688.6442\n","Epoch 2/50\n","AE Train loss: 633.8707\n","AE Val loss: 632.9324\n","Epoch 3/50\n","AE Train loss: 559.5876\n","AE Val loss: 601.6826\n","Epoch 4/50\n","AE Train loss: 503.3896\n","AE Val loss: 580.0825\n","Epoch 5/50\n","AE Train loss: 457.4601\n","AE Val loss: 564.7907\n","Epoch 6/50\n","AE Train loss: 413.4355\n","AE Val loss: 549.5240\n","Epoch 7/50\n","AE Train loss: 376.0142\n","AE Val loss: 545.1766\n","Epoch 8/50\n","AE Train loss: 345.1131\n","AE Val loss: 538.5807\n","Epoch 9/50\n","AE Train loss: 315.6479\n","AE Val loss: 527.5685\n","Epoch 10/50\n","AE Train loss: 289.1676\n","AE Val loss: 520.7104\n","Epoch 11/50\n","AE Train loss: 266.8612\n","AE Val loss: 535.0148\n","Epoch 12/50\n","AE Train loss: 247.8310\n","AE Val loss: 511.8363\n","Epoch 13/50\n","AE Train loss: 226.9362\n","AE Val loss: 509.1979\n","Epoch 14/50\n","AE Train loss: 208.6776\n","AE Val loss: 511.7409\n","Epoch 15/50\n","AE Train loss: 195.7261\n","AE Val loss: 500.5596\n","Epoch 16/50\n","AE Train loss: 180.0502\n","AE Val loss: 498.1281\n","Epoch 17/50\n","AE Train loss: 166.8436\n","AE Val loss: 495.3891\n","Epoch 18/50\n","AE Train loss: 154.3160\n","AE Val loss: 499.1541\n","Epoch 19/50\n","AE Train loss: 143.5536\n","AE Val loss: 490.7020\n","Epoch 20/50\n","AE Train loss: 133.9989\n","AE Val loss: 491.8915\n","Epoch 21/50\n","AE Train loss: 127.1741\n","AE Val loss: 493.1620\n","Epoch 22/50\n","AE Train loss: 120.1587\n","AE Val loss: 491.3888\n","Epoch 23/50\n","AE Train loss: 112.1191\n","AE Val loss: 486.6748\n","Epoch 24/50\n","AE Train loss: 106.2562\n","AE Val loss: 483.9416\n","Epoch 25/50\n","AE Train loss: 102.9447\n","AE Val loss: 488.8517\n","Epoch 26/50\n","AE Train loss: 97.1877\n","AE Val loss: 486.8885\n","Epoch 27/50\n","AE Train loss: 91.5523\n","AE Val loss: 485.4550\n","Epoch 28/50\n","AE Train loss: 85.6258\n","AE Val loss: 486.4980\n","Epoch 29/50\n","AE Train loss: 80.5614\n","AE Val loss: 485.6814\n","Epoch 30/50\n","AE Train loss: 75.6845\n","AE Val loss: 480.5676\n","Epoch 31/50\n","AE Train loss: 71.2001\n","AE Val loss: 479.5635\n","Epoch 32/50\n","AE Train loss: 67.9153\n","AE Val loss: 480.4657\n","Epoch 33/50\n","AE Train loss: 64.8933\n","AE Val loss: 483.4576\n","Epoch 34/50\n","AE Train loss: 62.4460\n","AE Val loss: 476.2908\n","Epoch 35/50\n","AE Train loss: 59.6871\n","AE Val loss: 480.9684\n","Epoch 36/50\n","AE Train loss: 56.8061\n","AE Val loss: 480.0019\n","Epoch 37/50\n","AE Train loss: 55.2426\n","AE Val loss: 479.5729\n","Epoch 38/50\n","AE Train loss: 52.6697\n","AE Val loss: 479.5269\n","Epoch 39/50\n","AE Train loss: 50.5878\n","AE Val loss: 477.4004\n","Epoch 40/50\n","AE Train loss: 47.8113\n","AE Val loss: 475.6137\n","Epoch 41/50\n","AE Train loss: 45.1664\n","AE Val loss: 474.4192\n","Epoch 42/50\n","AE Train loss: 42.5630\n","AE Val loss: 473.5455\n","Epoch 43/50\n","AE Train loss: 40.7979\n","AE Val loss: 475.2786\n","Epoch 44/50\n","AE Train loss: 39.9806\n","AE Val loss: 475.3943\n","Epoch 45/50\n","AE Train loss: 38.2954\n","AE Val loss: 473.3744\n","Epoch 46/50\n","AE Train loss: 37.4669\n","AE Val loss: 473.5551\n","Epoch 47/50\n","AE Train loss: 37.1791\n","AE Val loss: 474.1242\n","Epoch 48/50\n","AE Train loss: 36.5971\n","AE Val loss: 473.2514\n","Epoch 49/50\n","AE Train loss: 35.4960\n","AE Val loss: 476.1185\n","Epoch 50/50\n","AE Train loss: 34.3135\n","AE Val loss: 477.4860\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6139, Train Accuracy: 0.6625\n","CLF Val loss: 0.5977, Validation Accuracy: 0.6916\n","Epoch 2/50\n","CLF Train loss: 0.4152, Train Accuracy: 0.8172\n","CLF Val loss: 0.5740, Validation Accuracy: 0.7290\n","Epoch 3/50\n","CLF Train loss: 0.3238, Train Accuracy: 0.8703\n","CLF Val loss: 0.6096, Validation Accuracy: 0.6963\n","Epoch 4/50\n","CLF Train loss: 0.2694, Train Accuracy: 0.9016\n","CLF Val loss: 0.6278, Validation Accuracy: 0.7056\n","Epoch 5/50\n","CLF Train loss: 0.2678, Train Accuracy: 0.9047\n","CLF Val loss: 0.6718, Validation Accuracy: 0.6776\n","Epoch 6/50\n","CLF Train loss: 0.2526, Train Accuracy: 0.9094\n","CLF Val loss: 0.5689, Validation Accuracy: 0.7290\n","Epoch 7/50\n","CLF Train loss: 0.1446, Train Accuracy: 0.9719\n","CLF Val loss: 0.6431, Validation Accuracy: 0.6869\n","Epoch 8/50\n","CLF Train loss: 0.1229, Train Accuracy: 0.9828\n","CLF Val loss: 0.6423, Validation Accuracy: 0.7150\n","Epoch 9/50\n","CLF Train loss: 0.1161, Train Accuracy: 0.9828\n","CLF Val loss: 0.6237, Validation Accuracy: 0.7056\n","Epoch 10/50\n","CLF Train loss: 0.1251, Train Accuracy: 0.9703\n","CLF Val loss: 0.7794, Validation Accuracy: 0.6682\n","Epoch 11/50\n","CLF Train loss: 0.2120, Train Accuracy: 0.9219\n","CLF Val loss: 0.6338, Validation Accuracy: 0.7243\n","Fold 8/10\n","{'accuracy': 0.8, 'senstivity': 0.881, 'specificity': 0.7358, 'loss': 0.4103}\n","--------------------------------------------\n","Number of train subjects :  640\n","Number of val subjects :  214\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 781.4421\n","AE Val loss: 696.0339\n","Epoch 2/50\n","AE Train loss: 635.1644\n","AE Val loss: 639.1997\n","Epoch 3/50\n","AE Train loss: 563.0459\n","AE Val loss: 606.3516\n","Epoch 4/50\n","AE Train loss: 506.1003\n","AE Val loss: 583.1157\n","Epoch 5/50\n","AE Train loss: 454.3708\n","AE Val loss: 566.7671\n","Epoch 6/50\n","AE Train loss: 413.1815\n","AE Val loss: 554.2839\n","Epoch 7/50\n","AE Train loss: 376.6056\n","AE Val loss: 543.9458\n","Epoch 8/50\n","AE Train loss: 346.7260\n","AE Val loss: 544.1251\n","Epoch 9/50\n","AE Train loss: 321.6219\n","AE Val loss: 536.4543\n","Epoch 10/50\n","AE Train loss: 290.4194\n","AE Val loss: 532.4111\n","Epoch 11/50\n","AE Train loss: 263.9522\n","AE Val loss: 517.5561\n","Epoch 12/50\n","AE Train loss: 242.1266\n","AE Val loss: 513.3448\n","Epoch 13/50\n","AE Train loss: 223.6102\n","AE Val loss: 508.1793\n","Epoch 14/50\n","AE Train loss: 207.1244\n","AE Val loss: 505.6188\n","Epoch 15/50\n","AE Train loss: 192.0448\n","AE Val loss: 503.9695\n","Epoch 16/50\n","AE Train loss: 179.4112\n","AE Val loss: 501.5985\n","Epoch 17/50\n","AE Train loss: 166.2206\n","AE Val loss: 499.1973\n","Epoch 18/50\n","AE Train loss: 155.3075\n","AE Val loss: 499.1980\n","Epoch 19/50\n","AE Train loss: 147.4451\n","AE Val loss: 499.2735\n","Epoch 20/50\n","AE Train loss: 138.6568\n","AE Val loss: 494.0220\n","Epoch 21/50\n","AE Train loss: 129.7854\n","AE Val loss: 500.7951\n","Epoch 22/50\n","AE Train loss: 121.1660\n","AE Val loss: 497.8201\n","Epoch 23/50\n","AE Train loss: 113.2071\n","AE Val loss: 490.6545\n","Epoch 24/50\n","AE Train loss: 106.2132\n","AE Val loss: 493.1490\n","Epoch 25/50\n","AE Train loss: 100.4037\n","AE Val loss: 488.0115\n","Epoch 26/50\n","AE Train loss: 95.1707\n","AE Val loss: 487.2778\n","Epoch 27/50\n","AE Train loss: 89.2566\n","AE Val loss: 485.0335\n","Epoch 28/50\n","AE Train loss: 83.0571\n","AE Val loss: 480.8601\n","Epoch 29/50\n","AE Train loss: 79.1913\n","AE Val loss: 487.0117\n","Epoch 30/50\n","AE Train loss: 75.3531\n","AE Val loss: 484.4522\n","Epoch 31/50\n","AE Train loss: 72.4352\n","AE Val loss: 481.3288\n","Epoch 32/50\n","AE Train loss: 68.9034\n","AE Val loss: 481.4469\n","Epoch 33/50\n","AE Train loss: 64.7080\n","AE Val loss: 480.1143\n","Epoch 34/50\n","AE Train loss: 61.8004\n","AE Val loss: 479.7358\n","Epoch 35/50\n","AE Train loss: 59.0429\n","AE Val loss: 479.0747\n","Epoch 36/50\n","AE Train loss: 56.7198\n","AE Val loss: 479.6423\n","Epoch 37/50\n","AE Train loss: 53.7910\n","AE Val loss: 476.1434\n","Epoch 38/50\n","AE Train loss: 50.2818\n","AE Val loss: 478.3875\n","Epoch 39/50\n","AE Train loss: 47.3850\n","AE Val loss: 477.8168\n","Epoch 40/50\n","AE Train loss: 45.3885\n","AE Val loss: 476.0642\n","Epoch 41/50\n","AE Train loss: 43.6792\n","AE Val loss: 477.0686\n","Epoch 42/50\n","AE Train loss: 42.4639\n","AE Val loss: 476.9573\n","Epoch 43/50\n","AE Train loss: 41.7503\n","AE Val loss: 475.1123\n","Epoch 44/50\n","AE Train loss: 41.3986\n","AE Val loss: 480.1543\n","Epoch 45/50\n","AE Train loss: 41.6842\n","AE Val loss: 477.8256\n","Epoch 46/50\n","AE Train loss: 41.0229\n","AE Val loss: 476.8182\n","Epoch 47/50\n","AE Train loss: 39.1261\n","AE Val loss: 477.3792\n","Epoch 48/50\n","AE Train loss: 37.9392\n","AE Val loss: 478.7662\n","Epoch 49/50\n","AE Train loss: 37.6504\n","AE Val loss: 476.4028\n","Epoch 50/50\n","AE Train loss: 37.1975\n","AE Val loss: 479.2728\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6401, Train Accuracy: 0.6188\n","CLF Val loss: 0.5947, Validation Accuracy: 0.6495\n","Epoch 2/50\n","CLF Train loss: 0.4358, Train Accuracy: 0.8313\n","CLF Val loss: 0.5404, Validation Accuracy: 0.7336\n","Epoch 3/50\n","CLF Train loss: 0.3453, Train Accuracy: 0.8609\n","CLF Val loss: 0.5459, Validation Accuracy: 0.7243\n","Epoch 4/50\n","CLF Train loss: 0.2688, Train Accuracy: 0.9156\n","CLF Val loss: 0.5343, Validation Accuracy: 0.7336\n","Epoch 5/50\n","CLF Train loss: 0.2285, Train Accuracy: 0.9203\n","CLF Val loss: 0.5850, Validation Accuracy: 0.7243\n","Epoch 6/50\n","CLF Train loss: 0.2046, Train Accuracy: 0.9266\n","CLF Val loss: 0.6274, Validation Accuracy: 0.6916\n","Epoch 7/50\n","CLF Train loss: 0.1619, Train Accuracy: 0.9563\n","CLF Val loss: 0.6598, Validation Accuracy: 0.7009\n","Epoch 8/50\n","CLF Train loss: 0.1263, Train Accuracy: 0.9781\n","CLF Val loss: 0.5343, Validation Accuracy: 0.7570\n","Epoch 9/50\n","CLF Train loss: 0.1397, Train Accuracy: 0.9672\n","CLF Val loss: 0.5496, Validation Accuracy: 0.7290\n","Epoch 10/50\n","CLF Train loss: 0.1120, Train Accuracy: 0.9797\n","CLF Val loss: 0.5403, Validation Accuracy: 0.7290\n","Epoch 11/50\n","CLF Train loss: 0.1083, Train Accuracy: 0.9844\n","CLF Val loss: 0.5255, Validation Accuracy: 0.7757\n","Epoch 12/50\n","CLF Train loss: 0.0896, Train Accuracy: 0.9953\n","CLF Val loss: 0.5661, Validation Accuracy: 0.7430\n","Epoch 13/50\n","CLF Train loss: 0.1178, Train Accuracy: 0.9781\n","CLF Val loss: 0.5509, Validation Accuracy: 0.7243\n","Epoch 14/50\n","CLF Train loss: 0.1206, Train Accuracy: 0.9719\n","CLF Val loss: 0.7282, Validation Accuracy: 0.7150\n","Epoch 15/50\n","CLF Train loss: 0.0899, Train Accuracy: 0.9891\n","CLF Val loss: 0.5507, Validation Accuracy: 0.7477\n","Epoch 16/50\n","CLF Train loss: 0.0792, Train Accuracy: 0.9938\n","CLF Val loss: 0.5368, Validation Accuracy: 0.7243\n","Epoch 17/50\n","CLF Train loss: 0.0723, Train Accuracy: 0.9938\n","CLF Val loss: 0.6312, Validation Accuracy: 0.7056\n","Epoch 18/50\n","CLF Train loss: 0.0778, Train Accuracy: 1.0000\n","CLF Val loss: 0.5784, Validation Accuracy: 0.7150\n","Epoch 19/50\n","CLF Train loss: 0.1134, Train Accuracy: 0.9781\n","CLF Val loss: 0.5482, Validation Accuracy: 0.7804\n","Epoch 20/50\n","CLF Train loss: 0.0921, Train Accuracy: 0.9875\n","CLF Val loss: 0.5915, Validation Accuracy: 0.7523\n","Epoch 21/50\n","CLF Train loss: 0.0646, Train Accuracy: 0.9984\n","CLF Val loss: 0.6523, Validation Accuracy: 0.6963\n","Epoch 22/50\n","CLF Train loss: 0.0616, Train Accuracy: 0.9984\n","CLF Val loss: 0.6616, Validation Accuracy: 0.7103\n","Epoch 23/50\n","CLF Train loss: 0.0767, Train Accuracy: 0.9875\n","CLF Val loss: 0.6088, Validation Accuracy: 0.7009\n","Epoch 24/50\n","CLF Train loss: 0.0660, Train Accuracy: 0.9953\n","CLF Val loss: 0.5954, Validation Accuracy: 0.7196\n","Epoch 25/50\n","CLF Train loss: 0.0728, Train Accuracy: 0.9938\n","CLF Val loss: 0.5903, Validation Accuracy: 0.7523\n","Epoch 26/50\n","CLF Train loss: 0.0639, Train Accuracy: 0.9953\n","CLF Val loss: 0.5811, Validation Accuracy: 0.7617\n","Epoch 27/50\n","CLF Train loss: 0.0550, Train Accuracy: 1.0000\n","CLF Val loss: 0.6131, Validation Accuracy: 0.7196\n","Epoch 28/50\n","CLF Train loss: 0.0580, Train Accuracy: 0.9953\n","CLF Val loss: 0.5672, Validation Accuracy: 0.7617\n","Fold 9/10\n","{'accuracy': 0.6737, 'senstivity': 0.5238, 'specificity': 0.7925, 'loss': 0.73}\n","--------------------------------------------\n","Number of train subjects :  641\n","Number of val subjects :  214\n","Number of test subjects :  94\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 775.6643\n","AE Val loss: 717.0140\n","Epoch 2/50\n","AE Train loss: 635.4883\n","AE Val loss: 666.2662\n","Epoch 3/50\n","AE Train loss: 563.3670\n","AE Val loss: 627.7562\n","Epoch 4/50\n","AE Train loss: 513.8870\n","AE Val loss: 606.8002\n","Epoch 5/50\n","AE Train loss: 468.2169\n","AE Val loss: 584.6143\n","Epoch 6/50\n","AE Train loss: 425.4265\n","AE Val loss: 576.1970\n","Epoch 7/50\n","AE Train loss: 392.7310\n","AE Val loss: 564.3950\n","Epoch 8/50\n","AE Train loss: 364.6579\n","AE Val loss: 559.1660\n","Epoch 9/50\n","AE Train loss: 341.7249\n","AE Val loss: 552.1234\n","Epoch 10/50\n","AE Train loss: 315.0479\n","AE Val loss: 551.8637\n","Epoch 11/50\n","AE Train loss: 290.6627\n","AE Val loss: 538.1690\n","Epoch 12/50\n","AE Train loss: 269.9821\n","AE Val loss: 534.9166\n","Epoch 13/50\n","AE Train loss: 254.2025\n","AE Val loss: 541.5781\n","Epoch 14/50\n","AE Train loss: 240.9941\n","AE Val loss: 526.2092\n","Epoch 15/50\n","AE Train loss: 222.9617\n","AE Val loss: 523.8256\n","Epoch 16/50\n","AE Train loss: 209.7441\n","AE Val loss: 521.2172\n","Epoch 17/50\n","AE Train loss: 203.5926\n","AE Val loss: 515.4574\n","Epoch 18/50\n","AE Train loss: 185.2506\n","AE Val loss: 512.0234\n","Epoch 19/50\n","AE Train loss: 173.3931\n","AE Val loss: 512.2862\n","Epoch 20/50\n","AE Train loss: 163.9762\n","AE Val loss: 511.4666\n","Epoch 21/50\n","AE Train loss: 162.3399\n","AE Val loss: 508.3520\n","Epoch 22/50\n","AE Train loss: 155.4869\n","AE Val loss: 514.0829\n","Epoch 23/50\n","AE Train loss: 144.9716\n","AE Val loss: 519.4611\n","Epoch 24/50\n","AE Train loss: 151.6668\n","AE Val loss: 523.5149\n","Epoch 25/50\n","AE Train loss: 140.2067\n","AE Val loss: 506.4177\n","Epoch 26/50\n","AE Train loss: 123.7902\n","AE Val loss: 505.6259\n","Epoch 27/50\n","AE Train loss: 112.4450\n","AE Val loss: 501.7129\n","Epoch 28/50\n","AE Train loss: 109.2942\n","AE Val loss: 498.4138\n","Epoch 29/50\n","AE Train loss: 104.7338\n","AE Val loss: 495.2413\n","Epoch 30/50\n","AE Train loss: 102.3812\n","AE Val loss: 494.6800\n","Epoch 31/50\n","AE Train loss: 95.9679\n","AE Val loss: 493.3234\n","Epoch 32/50\n","AE Train loss: 90.1984\n","AE Val loss: 510.5230\n","Epoch 33/50\n","AE Train loss: 88.6412\n","AE Val loss: 495.0408\n","Epoch 34/50\n","AE Train loss: 86.5401\n","AE Val loss: 503.8244\n","Epoch 35/50\n","AE Train loss: 81.9250\n","AE Val loss: 493.3409\n","Epoch 36/50\n","AE Train loss: 77.4308\n","AE Val loss: 490.9943\n","Epoch 37/50\n","AE Train loss: 73.0626\n","AE Val loss: 491.5993\n","Epoch 38/50\n","AE Train loss: 73.6738\n","AE Val loss: 491.0351\n","Epoch 39/50\n","AE Train loss: 71.3939\n","AE Val loss: 495.1003\n","Epoch 40/50\n","AE Train loss: 68.7861\n","AE Val loss: 491.2656\n","Epoch 41/50\n","AE Train loss: 65.1660\n","AE Val loss: 491.8122\n","Epoch 42/50\n","AE Train loss: 65.7782\n","AE Val loss: 494.6068\n","Epoch 43/50\n","AE Train loss: 63.8145\n","AE Val loss: 494.3647\n","Epoch 44/50\n","AE Train loss: 62.9392\n","AE Val loss: 491.0547\n","Epoch 45/50\n","AE Train loss: 58.5965\n","AE Val loss: 491.3083\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6250, Train Accuracy: 0.6459\n","CLF Val loss: 0.6068, Validation Accuracy: 0.6636\n","Epoch 2/50\n","CLF Train loss: 0.4838, Train Accuracy: 0.8112\n","CLF Val loss: 0.5463, Validation Accuracy: 0.7570\n","Epoch 3/50\n","CLF Train loss: 0.4376, Train Accuracy: 0.7785\n","CLF Val loss: 0.8000, Validation Accuracy: 0.5935\n","Epoch 4/50\n","CLF Train loss: 0.3745, Train Accuracy: 0.8346\n","CLF Val loss: 0.5561, Validation Accuracy: 0.7150\n","Epoch 5/50\n","CLF Train loss: 0.2849, Train Accuracy: 0.8939\n","CLF Val loss: 0.5030, Validation Accuracy: 0.7336\n","Epoch 6/50\n","CLF Train loss: 0.2493, Train Accuracy: 0.9048\n","CLF Val loss: 0.6706, Validation Accuracy: 0.6916\n","Epoch 7/50\n","CLF Train loss: 0.2391, Train Accuracy: 0.8970\n","CLF Val loss: 0.5923, Validation Accuracy: 0.7290\n","Epoch 8/50\n","CLF Train loss: 0.1975, Train Accuracy: 0.9360\n","CLF Val loss: 0.5443, Validation Accuracy: 0.7570\n","Epoch 9/50\n","CLF Train loss: 0.1422, Train Accuracy: 0.9704\n","CLF Val loss: 0.5817, Validation Accuracy: 0.7430\n","Epoch 10/50\n","CLF Train loss: 0.1438, Train Accuracy: 0.9626\n","CLF Val loss: 0.6164, Validation Accuracy: 0.7150\n","Epoch 11/50\n","CLF Train loss: 0.1195, Train Accuracy: 0.9860\n","CLF Val loss: 0.5524, Validation Accuracy: 0.7757\n","Epoch 12/50\n","CLF Train loss: 0.0922, Train Accuracy: 0.9938\n","CLF Val loss: 0.5935, Validation Accuracy: 0.7196\n","Epoch 13/50\n","CLF Train loss: 0.1181, Train Accuracy: 0.9860\n","CLF Val loss: 0.5792, Validation Accuracy: 0.7477\n","Epoch 14/50\n","CLF Train loss: 0.1837, Train Accuracy: 0.9454\n","CLF Val loss: 0.6718, Validation Accuracy: 0.6963\n","Epoch 15/50\n","CLF Train loss: 0.1150, Train Accuracy: 0.9766\n","CLF Val loss: 0.5525, Validation Accuracy: 0.7850\n","Epoch 16/50\n","CLF Train loss: 0.0714, Train Accuracy: 0.9984\n","CLF Val loss: 0.6523, Validation Accuracy: 0.7336\n","Epoch 17/50\n","CLF Train loss: 0.0700, Train Accuracy: 0.9969\n","CLF Val loss: 0.6346, Validation Accuracy: 0.7196\n","Epoch 18/50\n","CLF Train loss: 0.0905, Train Accuracy: 0.9906\n","CLF Val loss: 0.6562, Validation Accuracy: 0.7477\n","Epoch 19/50\n","CLF Train loss: 0.0884, Train Accuracy: 0.9922\n","CLF Val loss: 0.5568, Validation Accuracy: 0.7570\n","Epoch 20/50\n","CLF Train loss: 0.0811, Train Accuracy: 0.9938\n","CLF Val loss: 0.5546, Validation Accuracy: 0.7710\n","Epoch 21/50\n","CLF Train loss: 0.0652, Train Accuracy: 0.9922\n","CLF Val loss: 0.5251, Validation Accuracy: 0.7664\n","Epoch 22/50\n","CLF Train loss: 0.0632, Train Accuracy: 0.9953\n","CLF Val loss: 0.5493, Validation Accuracy: 0.7523\n","Epoch 23/50\n","CLF Train loss: 0.0637, Train Accuracy: 0.9969\n","CLF Val loss: 0.5832, Validation Accuracy: 0.7430\n","Epoch 24/50\n","CLF Train loss: 0.0604, Train Accuracy: 0.9984\n","CLF Val loss: 0.5458, Validation Accuracy: 0.7570\n","Fold 10/10\n","{'accuracy': 0.734, 'senstivity': 0.8049, 'specificity': 0.6792, 'loss': 0.6006}\n","--------------------------------------------\n","Average Value after 10 Folds\n","Accuracy: 0.7187, Senstivity: 0.6829, Specificity: 0.7472, Loss: 0.6498000025749207\n","Total time taken : 3994.336448431015\n"]}]},{"cell_type":"code","source":["crossval_acc, crossval_sen, crossval_spec, crossval_loss, attributions = [], [], [], [], [] \n","all_folds_splits = {}\n","kf = StratifiedKFold(n_splits = p_fold, random_state = 1, shuffle = True)\n","\n","start = time.time()\n","for fold,(train_index, test_index) in enumerate(kf.split(flist, labels)):\n","\n","    train_subjects, test_subjects = flist[train_index],flist[test_index]\n","    train_labels = labels[train_index]   \n","    train_subjects, val_subjects, train_labels, val_labels = train_test_split(train_subjects, train_labels, \n","                                                      test_size = 0.20, random_state = 42, stratify = train_labels)\n","    \n","    print('Number of train subjects : ', len(train_subjects))\n","    print('Number of val subjects : ', len(val_subjects))\n","    print('Number of test subjects : ', len(test_subjects))\n","\n","    fold_splits_dict = {} \n","    fold_splits_dict['train'] = train_subjects\n","    fold_splits_dict['val'] = val_subjects\n","    fold_splits_dict['test'] = test_subjects\n","\n","    all_folds_splits[fold] = fold_splits_dict\n","    verbose = (True if (fold == 0) else False)\n","   \n","    train_dataset = ASDDataset(all_corr, train_subjects)\n","    val_dataset = ASDDataset(all_corr, val_subjects)\n","    test_dataset = ASDDataset(all_corr, test_subjects)\n","    \n","    train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n","    val_dataloader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n","    test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)                           \n","\n","    model = Network(num_inputs = n_inputs, num_latent = n_latent)\n","    model = model.to(device)\n","\n","    criterion_ae = nn.MSELoss(reduction='sum')         \n","    optimizer = optim.Adam(model.parameters(), lr = lr_ae, weight_decay = weight_decay_ae)          \n","    best_ae_model, count = None, 1\n","    best_ae_loss = sys.float_info.max\n","    \n","    print(\"Auto Encoder training Started-----------\")\n","    for epoch in range(1, ae_epochs+1):\n","\n","        print(f'Epoch {epoch}/{ae_epochs}')\n","        ae_train_loss, _ = train(model, criterion_ae, train_dataloader, mode = 'ae')\n","        print(f'AE Train loss: {(ae_train_loss):.4f}')\n","\n","        ae_val_loss, _ = test(model, criterion_ae, val_dataloader, mode = 'ae')\n","        print(f'AE Val loss: {(ae_val_loss):.4f}')\n","\n","        if(ae_val_loss < best_ae_loss):     # Early Stopping \n","            best_ae_model = model\n","            best_ae_loss = ae_val_loss\n","            count = 1\n","        else:\n","            count += 1     \n","        if(count == 10):  # Criteria\n","            break\n","              \n","    best_clf_model, best_clf_acc, count = None, 0.0, 1\n","    model = best_ae_model\n","    criterion_clf = nn.BCELoss()      \n","    optimizer = optim.Adam(model.parameters(), lr = lr_clf, weight_decay = weight_decay_clf)\n","\n","    print(\"Classifier training Started-----------\")\n","    for epoch in range(1, clf_epochs+1):\n","\n","        print(f'Epoch {epoch}/{clf_epochs}')\n","        clf_train_loss, train_acc = train(model, criterion_clf, train_dataloader, mode='clf')\n","        print(f'CLF Train loss: {(clf_train_loss):.4f}, Train Accuracy: {(train_acc):.4f}')\n","\n","        val_metrics = test(model, criterion_clf, val_dataloader, mode='clf')\n","        print(f'CLF Val loss: {(val_metrics[\"loss\"]):.4f}, Validation Accuracy: {(val_metrics[\"accuracy\"]):.4f}')\n","\n","        if(val_metrics['accuracy'] > best_clf_acc):    # Early Stopping Criteria\n","            best_clf_model = model\n","            best_clf_acc = val_metrics['accuracy']\n","            count = 1\n","        else:\n","            count += 1\n","        if(count == 10):\n","            break        \n","\n","    metrics_dict = test(best_clf_model, criterion_clf, test_dataloader, mode = 'clf')\n","\n","    print(f'Fold {fold+1}/{p_fold}')\n","    print(f'{metrics_dict}')\n","    print(\"--------------------------------------------\")\n","    \n","    # torch.save(best_clf_model.state_dict(), f'./data/Weights/Fold_{kk+1}.pth').    # To save the weights\n","    # print(f'Fold {kk+1} weights are saved')\n","\n","    crossval_acc.append(metrics_dict['accuracy'])\n","    crossval_sen.append(metrics_dict['senstivity'])\n","    crossval_spec.append(metrics_dict['specificity'])\n","    crossval_loss.append(metrics_dict['loss'])\n","\n","print(f'Average Value after 10 Folds')\n","print(f'Accuracy: {np.round(np.mean(crossval_acc),4)}, Senstivity: {np.round(np.mean(crossval_sen),4)}, Specificity: {np.round(np.mean(crossval_spec),4)}, Loss: {np.round(np.mean(crossval_loss),4)}')\n","# pickle.dump(df, open('./data/AllFoldssubjects.pkl', 'wb'))\n","print(f'Total time taken : {time.time()-start}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wriHG8ySznLp","executionInfo":{"status":"ok","timestamp":1648211435346,"user_tz":-330,"elapsed":307,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"1d9e17f1-217b-40ae-c8e0-1835c65f10f8"},"execution_count":53,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 778.7787\n","AE Val loss: 690.0318\n","Epoch 2/50\n","AE Train loss: 631.7645\n","AE Val loss: 628.2238\n","Epoch 3/50\n","AE Train loss: 554.9092\n","AE Val loss: 594.4934\n","Epoch 4/50\n","AE Train loss: 500.8165\n","AE Val loss: 575.5294\n","Epoch 5/50\n","AE Train loss: 455.1542\n","AE Val loss: 564.6990\n","Epoch 6/50\n","AE Train loss: 415.4597\n","AE Val loss: 547.8933\n","Epoch 7/50\n","AE Train loss: 376.4567\n","AE Val loss: 545.7291\n","Epoch 8/50\n","AE Train loss: 343.7767\n","AE Val loss: 531.0880\n","Epoch 9/50\n","AE Train loss: 314.3024\n","AE Val loss: 520.2012\n","Epoch 10/50\n","AE Train loss: 287.2277\n","AE Val loss: 518.3170\n","Epoch 11/50\n","AE Train loss: 264.0032\n","AE Val loss: 509.0962\n","Epoch 12/50\n","AE Train loss: 245.9659\n","AE Val loss: 505.0529\n","Epoch 13/50\n","AE Train loss: 227.2921\n","AE Val loss: 502.5721\n","Epoch 14/50\n","AE Train loss: 210.4479\n","AE Val loss: 498.9919\n","Epoch 15/50\n","AE Train loss: 195.3605\n","AE Val loss: 496.9584\n","Epoch 16/50\n","AE Train loss: 184.5896\n","AE Val loss: 501.5562\n","Epoch 17/50\n","AE Train loss: 173.8265\n","AE Val loss: 505.1082\n","Epoch 18/50\n","AE Train loss: 163.5740\n","AE Val loss: 495.0189\n","Epoch 19/50\n","AE Train loss: 152.9411\n","AE Val loss: 489.3582\n","Epoch 20/50\n","AE Train loss: 142.8572\n","AE Val loss: 482.9362\n","Epoch 21/50\n","AE Train loss: 133.2428\n","AE Val loss: 486.1541\n","Epoch 22/50\n","AE Train loss: 125.9980\n","AE Val loss: 481.6222\n","Epoch 23/50\n","AE Train loss: 118.9176\n","AE Val loss: 482.1772\n","Epoch 24/50\n","AE Train loss: 112.5181\n","AE Val loss: 479.0384\n","Epoch 25/50\n","AE Train loss: 106.7185\n","AE Val loss: 478.2946\n","Epoch 26/50\n","AE Train loss: 101.1924\n","AE Val loss: 476.7000\n","Epoch 27/50\n","AE Train loss: 95.3427\n","AE Val loss: 473.9518\n","Epoch 28/50\n","AE Train loss: 90.0558\n","AE Val loss: 473.4052\n","Epoch 29/50\n","AE Train loss: 84.4873\n","AE Val loss: 473.2296\n","Epoch 30/50\n","AE Train loss: 80.4169\n","AE Val loss: 472.0022\n","Epoch 31/50\n","AE Train loss: 77.5144\n","AE Val loss: 470.5941\n","Epoch 32/50\n","AE Train loss: 74.0020\n","AE Val loss: 471.3748\n","Epoch 33/50\n","AE Train loss: 71.5630\n","AE Val loss: 473.3379\n","Epoch 34/50\n","AE Train loss: 69.0663\n","AE Val loss: 473.1790\n","Epoch 35/50\n","AE Train loss: 66.0440\n","AE Val loss: 470.4125\n","Epoch 36/50\n","AE Train loss: 63.4041\n","AE Val loss: 472.1496\n","Epoch 37/50\n","AE Train loss: 60.3574\n","AE Val loss: 472.3277\n","Epoch 38/50\n","AE Train loss: 58.5124\n","AE Val loss: 469.0551\n","Epoch 39/50\n","AE Train loss: 58.6340\n","AE Val loss: 471.2757\n","Epoch 40/50\n","AE Train loss: 56.9017\n","AE Val loss: 468.3476\n","Epoch 41/50\n","AE Train loss: 53.7692\n","AE Val loss: 469.4196\n","Epoch 42/50\n","AE Train loss: 51.4322\n","AE Val loss: 468.9619\n","Epoch 43/50\n","AE Train loss: 49.5877\n","AE Val loss: 467.3389\n","Epoch 44/50\n","AE Train loss: 48.2205\n","AE Val loss: 468.1498\n","Epoch 45/50\n","AE Train loss: 46.9583\n","AE Val loss: 466.9065\n","Epoch 46/50\n","AE Train loss: 45.6621\n","AE Val loss: 469.2413\n","Epoch 47/50\n","AE Train loss: 44.5705\n","AE Val loss: 467.0445\n","Epoch 48/50\n","AE Train loss: 42.8022\n","AE Val loss: 467.1328\n","Epoch 49/50\n","AE Train loss: 41.4226\n","AE Val loss: 469.7356\n","Epoch 50/50\n","AE Train loss: 40.1687\n","AE Val loss: 468.3882\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6547, Train Accuracy: 0.6413\n","CLF Val loss: 0.5492, Validation Accuracy: 0.7427\n","Epoch 2/50\n","CLF Train loss: 0.4521, Train Accuracy: 0.7789\n","CLF Val loss: 0.6209, Validation Accuracy: 0.6491\n","Epoch 3/50\n","CLF Train loss: 0.4204, Train Accuracy: 0.8155\n","CLF Val loss: 0.5188, Validation Accuracy: 0.7310\n","Epoch 4/50\n","CLF Train loss: 0.3167, Train Accuracy: 0.8770\n","CLF Val loss: 0.5174, Validation Accuracy: 0.7485\n","Epoch 5/50\n","CLF Train loss: 0.2440, Train Accuracy: 0.9092\n","CLF Val loss: 0.6185, Validation Accuracy: 0.6959\n","Epoch 6/50\n","CLF Train loss: 0.2013, Train Accuracy: 0.9400\n","CLF Val loss: 0.7163, Validation Accuracy: 0.6374\n","Epoch 7/50\n","CLF Train loss: 0.1633, Train Accuracy: 0.9546\n","CLF Val loss: 0.8383, Validation Accuracy: 0.5965\n","Epoch 8/50\n","CLF Train loss: 0.1463, Train Accuracy: 0.9722\n","CLF Val loss: 0.5444, Validation Accuracy: 0.7427\n","Epoch 9/50\n","CLF Train loss: 0.0995, Train Accuracy: 0.9898\n","CLF Val loss: 0.7186, Validation Accuracy: 0.6901\n","Epoch 10/50\n","CLF Train loss: 0.1216, Train Accuracy: 0.9780\n","CLF Val loss: 0.5875, Validation Accuracy: 0.7193\n","Epoch 11/50\n","CLF Train loss: 0.1223, Train Accuracy: 0.9722\n","CLF Val loss: 0.5945, Validation Accuracy: 0.7310\n","Epoch 12/50\n","CLF Train loss: 0.0951, Train Accuracy: 0.9956\n","CLF Val loss: 0.5478, Validation Accuracy: 0.7368\n","Epoch 13/50\n","CLF Train loss: 0.0819, Train Accuracy: 0.9927\n","CLF Val loss: 0.5461, Validation Accuracy: 0.7193\n","Fold 1/10\n","{'accuracy': 0.6842, 'senstivity': 0.7619, 'specificity': 0.6226, 'loss': 0.6332}\n","--------------------------------------------\n","Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 772.3492\n","AE Val loss: 703.3995\n","Epoch 2/50\n","AE Train loss: 629.3884\n","AE Val loss: 644.9489\n","Epoch 3/50\n","AE Train loss: 554.8857\n","AE Val loss: 608.5179\n","Epoch 4/50\n","AE Train loss: 498.5738\n","AE Val loss: 585.2060\n","Epoch 5/50\n","AE Train loss: 450.5154\n","AE Val loss: 567.2606\n","Epoch 6/50\n","AE Train loss: 408.7090\n","AE Val loss: 559.2751\n","Epoch 7/50\n","AE Train loss: 373.6502\n","AE Val loss: 551.2706\n","Epoch 8/50\n","AE Train loss: 344.5414\n","AE Val loss: 539.0063\n","Epoch 9/50\n","AE Train loss: 315.3726\n","AE Val loss: 530.8233\n","Epoch 10/50\n","AE Train loss: 288.8833\n","AE Val loss: 528.6002\n","Epoch 11/50\n","AE Train loss: 267.5933\n","AE Val loss: 521.6076\n","Epoch 12/50\n","AE Train loss: 248.0686\n","AE Val loss: 522.7621\n","Epoch 13/50\n","AE Train loss: 230.0596\n","AE Val loss: 510.7650\n","Epoch 14/50\n","AE Train loss: 213.6395\n","AE Val loss: 511.2221\n","Epoch 15/50\n","AE Train loss: 195.7920\n","AE Val loss: 502.3203\n","Epoch 16/50\n","AE Train loss: 181.0373\n","AE Val loss: 501.6819\n","Epoch 17/50\n","AE Train loss: 168.7282\n","AE Val loss: 504.8123\n","Epoch 18/50\n","AE Train loss: 158.6631\n","AE Val loss: 499.1101\n","Epoch 19/50\n","AE Train loss: 149.4780\n","AE Val loss: 495.6035\n","Epoch 20/50\n","AE Train loss: 141.0720\n","AE Val loss: 494.8942\n","Epoch 21/50\n","AE Train loss: 132.7307\n","AE Val loss: 493.7527\n","Epoch 22/50\n","AE Train loss: 124.9569\n","AE Val loss: 489.6166\n","Epoch 23/50\n","AE Train loss: 117.5087\n","AE Val loss: 488.2500\n","Epoch 24/50\n","AE Train loss: 111.4239\n","AE Val loss: 490.0506\n","Epoch 25/50\n","AE Train loss: 106.0654\n","AE Val loss: 492.0793\n","Epoch 26/50\n","AE Train loss: 100.2087\n","AE Val loss: 484.6190\n","Epoch 27/50\n","AE Train loss: 94.1424\n","AE Val loss: 484.5519\n","Epoch 28/50\n","AE Train loss: 88.9055\n","AE Val loss: 484.2495\n","Epoch 29/50\n","AE Train loss: 85.2859\n","AE Val loss: 483.6615\n","Epoch 30/50\n","AE Train loss: 81.0146\n","AE Val loss: 481.5366\n","Epoch 31/50\n","AE Train loss: 77.2480\n","AE Val loss: 481.2561\n","Epoch 32/50\n","AE Train loss: 74.0273\n","AE Val loss: 479.7780\n","Epoch 33/50\n","AE Train loss: 70.9489\n","AE Val loss: 487.1662\n","Epoch 34/50\n","AE Train loss: 68.5604\n","AE Val loss: 480.5284\n","Epoch 35/50\n","AE Train loss: 65.6632\n","AE Val loss: 478.0914\n","Epoch 36/50\n","AE Train loss: 62.4448\n","AE Val loss: 479.3895\n","Epoch 37/50\n","AE Train loss: 60.5564\n","AE Val loss: 479.6985\n","Epoch 38/50\n","AE Train loss: 58.9211\n","AE Val loss: 478.4782\n","Epoch 39/50\n","AE Train loss: 57.3913\n","AE Val loss: 476.1634\n","Epoch 40/50\n","AE Train loss: 55.8897\n","AE Val loss: 476.4529\n","Epoch 41/50\n","AE Train loss: 53.2787\n","AE Val loss: 478.4200\n","Epoch 42/50\n","AE Train loss: 51.0238\n","AE Val loss: 478.4455\n","Epoch 43/50\n","AE Train loss: 49.6218\n","AE Val loss: 478.3088\n","Epoch 44/50\n","AE Train loss: 47.7340\n","AE Val loss: 477.6944\n","Epoch 45/50\n","AE Train loss: 45.9678\n","AE Val loss: 478.4209\n","Epoch 46/50\n","AE Train loss: 44.6093\n","AE Val loss: 476.4048\n","Epoch 47/50\n","AE Train loss: 43.7601\n","AE Val loss: 475.4915\n","Epoch 48/50\n","AE Train loss: 42.3657\n","AE Val loss: 474.2356\n","Epoch 49/50\n","AE Train loss: 40.8376\n","AE Val loss: 474.8459\n","Epoch 50/50\n","AE Train loss: 39.4978\n","AE Val loss: 479.1155\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.5756, Train Accuracy: 0.6984\n","CLF Val loss: 0.5788, Validation Accuracy: 0.7193\n","Epoch 2/50\n","CLF Train loss: 0.4324, Train Accuracy: 0.8067\n","CLF Val loss: 0.5638, Validation Accuracy: 0.6725\n","Epoch 3/50\n","CLF Train loss: 0.2981, Train Accuracy: 0.8960\n","CLF Val loss: 0.5309, Validation Accuracy: 0.7193\n","Epoch 4/50\n","CLF Train loss: 0.2709, Train Accuracy: 0.9019\n","CLF Val loss: 0.6517, Validation Accuracy: 0.6725\n","Epoch 5/50\n","CLF Train loss: 0.2587, Train Accuracy: 0.8975\n","CLF Val loss: 0.7266, Validation Accuracy: 0.6959\n","Epoch 6/50\n","CLF Train loss: 0.1744, Train Accuracy: 0.9546\n","CLF Val loss: 0.5730, Validation Accuracy: 0.6842\n","Epoch 7/50\n","CLF Train loss: 0.1396, Train Accuracy: 0.9736\n","CLF Val loss: 0.5570, Validation Accuracy: 0.7018\n","Epoch 8/50\n","CLF Train loss: 0.1553, Train Accuracy: 0.9561\n","CLF Val loss: 0.5553, Validation Accuracy: 0.7193\n","Epoch 9/50\n","CLF Train loss: 0.1384, Train Accuracy: 0.9707\n","CLF Val loss: 0.6068, Validation Accuracy: 0.7368\n","Epoch 10/50\n","CLF Train loss: 0.1422, Train Accuracy: 0.9663\n","CLF Val loss: 0.5351, Validation Accuracy: 0.7135\n","Epoch 11/50\n","CLF Train loss: 0.1555, Train Accuracy: 0.9458\n","CLF Val loss: 0.6175, Validation Accuracy: 0.7018\n","Epoch 12/50\n","CLF Train loss: 0.1098, Train Accuracy: 0.9868\n","CLF Val loss: 0.5451, Validation Accuracy: 0.7135\n","Epoch 13/50\n","CLF Train loss: 0.0856, Train Accuracy: 0.9898\n","CLF Val loss: 0.7095, Validation Accuracy: 0.6491\n","Epoch 14/50\n","CLF Train loss: 0.0791, Train Accuracy: 0.9971\n","CLF Val loss: 0.6401, Validation Accuracy: 0.6959\n","Epoch 15/50\n","CLF Train loss: 0.0822, Train Accuracy: 0.9941\n","CLF Val loss: 0.6377, Validation Accuracy: 0.7076\n","Epoch 16/50\n","CLF Train loss: 0.0854, Train Accuracy: 0.9912\n","CLF Val loss: 0.6462, Validation Accuracy: 0.6491\n","Epoch 17/50\n","CLF Train loss: 0.0798, Train Accuracy: 0.9941\n","CLF Val loss: 0.6004, Validation Accuracy: 0.7135\n","Epoch 18/50\n","CLF Train loss: 0.1048, Train Accuracy: 0.9780\n","CLF Val loss: 0.6122, Validation Accuracy: 0.7135\n","Fold 2/10\n","{'accuracy': 0.6, 'senstivity': 0.4762, 'specificity': 0.6981, 'loss': 0.9059}\n","--------------------------------------------\n","Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 770.5760\n","AE Val loss: 695.9946\n","Epoch 2/50\n","AE Train loss: 629.3181\n","AE Val loss: 641.2267\n","Epoch 3/50\n","AE Train loss: 555.2002\n","AE Val loss: 610.3141\n","Epoch 4/50\n","AE Train loss: 496.7501\n","AE Val loss: 589.2356\n","Epoch 5/50\n","AE Train loss: 449.7123\n","AE Val loss: 569.3770\n","Epoch 6/50\n","AE Train loss: 412.2325\n","AE Val loss: 558.1418\n","Epoch 7/50\n","AE Train loss: 376.8867\n","AE Val loss: 547.5394\n","Epoch 8/50\n","AE Train loss: 343.3351\n","AE Val loss: 538.9229\n","Epoch 9/50\n","AE Train loss: 311.8981\n","AE Val loss: 528.8113\n","Epoch 10/50\n","AE Train loss: 285.1744\n","AE Val loss: 524.2876\n","Epoch 11/50\n","AE Train loss: 263.8531\n","AE Val loss: 522.6332\n","Epoch 12/50\n","AE Train loss: 244.4737\n","AE Val loss: 527.0535\n","Epoch 13/50\n","AE Train loss: 228.7773\n","AE Val loss: 511.7227\n","Epoch 14/50\n","AE Train loss: 209.6078\n","AE Val loss: 511.0029\n","Epoch 15/50\n","AE Train loss: 196.5692\n","AE Val loss: 509.1112\n","Epoch 16/50\n","AE Train loss: 185.2103\n","AE Val loss: 504.3351\n","Epoch 17/50\n","AE Train loss: 172.7819\n","AE Val loss: 498.8442\n","Epoch 18/50\n","AE Train loss: 160.8353\n","AE Val loss: 500.9606\n","Epoch 19/50\n","AE Train loss: 152.1006\n","AE Val loss: 496.7804\n","Epoch 20/50\n","AE Train loss: 141.3256\n","AE Val loss: 499.4869\n","Epoch 21/50\n","AE Train loss: 132.5387\n","AE Val loss: 495.0770\n","Epoch 22/50\n","AE Train loss: 125.3546\n","AE Val loss: 489.9146\n","Epoch 23/50\n","AE Train loss: 117.8108\n","AE Val loss: 490.8813\n","Epoch 24/50\n","AE Train loss: 111.0343\n","AE Val loss: 486.9772\n","Epoch 25/50\n","AE Train loss: 106.3206\n","AE Val loss: 486.7316\n","Epoch 26/50\n","AE Train loss: 100.6730\n","AE Val loss: 486.2172\n","Epoch 27/50\n","AE Train loss: 94.6593\n","AE Val loss: 483.4718\n","Epoch 28/50\n","AE Train loss: 88.7965\n","AE Val loss: 482.6204\n","Epoch 29/50\n","AE Train loss: 83.8866\n","AE Val loss: 481.7885\n","Epoch 30/50\n","AE Train loss: 80.3163\n","AE Val loss: 483.4750\n","Epoch 31/50\n","AE Train loss: 78.1281\n","AE Val loss: 481.3874\n","Epoch 32/50\n","AE Train loss: 75.5520\n","AE Val loss: 483.9279\n","Epoch 33/50\n","AE Train loss: 73.0129\n","AE Val loss: 487.1309\n","Epoch 34/50\n","AE Train loss: 70.6552\n","AE Val loss: 481.1905\n","Epoch 35/50\n","AE Train loss: 67.7561\n","AE Val loss: 485.1478\n","Epoch 36/50\n","AE Train loss: 65.1267\n","AE Val loss: 479.5498\n","Epoch 37/50\n","AE Train loss: 61.8135\n","AE Val loss: 479.7627\n","Epoch 38/50\n","AE Train loss: 59.3830\n","AE Val loss: 479.3510\n","Epoch 39/50\n","AE Train loss: 57.6229\n","AE Val loss: 477.8509\n","Epoch 40/50\n","AE Train loss: 54.8630\n","AE Val loss: 478.2845\n","Epoch 41/50\n","AE Train loss: 52.2269\n","AE Val loss: 478.3092\n","Epoch 42/50\n","AE Train loss: 51.1910\n","AE Val loss: 476.1562\n","Epoch 43/50\n","AE Train loss: 49.2688\n","AE Val loss: 478.2970\n","Epoch 44/50\n","AE Train loss: 47.4056\n","AE Val loss: 476.7128\n","Epoch 45/50\n","AE Train loss: 45.6008\n","AE Val loss: 474.5687\n","Epoch 46/50\n","AE Train loss: 44.7534\n","AE Val loss: 476.6162\n","Epoch 47/50\n","AE Train loss: 43.3975\n","AE Val loss: 475.4807\n","Epoch 48/50\n","AE Train loss: 42.7857\n","AE Val loss: 476.4310\n","Epoch 49/50\n","AE Train loss: 42.1853\n","AE Val loss: 477.4787\n","Epoch 50/50\n","AE Train loss: 41.6041\n","AE Val loss: 476.8360\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6298, Train Accuracy: 0.6603\n","CLF Val loss: 0.6134, Validation Accuracy: 0.6316\n","Epoch 2/50\n","CLF Train loss: 0.4165, Train Accuracy: 0.8228\n","CLF Val loss: 0.6881, Validation Accuracy: 0.6491\n","Epoch 3/50\n","CLF Train loss: 0.3461, Train Accuracy: 0.8565\n","CLF Val loss: 0.6623, Validation Accuracy: 0.6667\n","Epoch 4/50\n","CLF Train loss: 0.2598, Train Accuracy: 0.9180\n","CLF Val loss: 0.5894, Validation Accuracy: 0.6784\n","Epoch 5/50\n","CLF Train loss: 0.2161, Train Accuracy: 0.9414\n","CLF Val loss: 0.5406, Validation Accuracy: 0.7193\n","Epoch 6/50\n","CLF Train loss: 0.1885, Train Accuracy: 0.9502\n","CLF Val loss: 1.0237, Validation Accuracy: 0.6140\n","Epoch 7/50\n","CLF Train loss: 0.2919, Train Accuracy: 0.8682\n","CLF Val loss: 0.6120, Validation Accuracy: 0.6608\n","Epoch 8/50\n","CLF Train loss: 0.1711, Train Accuracy: 0.9590\n","CLF Val loss: 0.5430, Validation Accuracy: 0.7076\n","Epoch 9/50\n","CLF Train loss: 0.1342, Train Accuracy: 0.9751\n","CLF Val loss: 0.5974, Validation Accuracy: 0.6784\n","Epoch 10/50\n","CLF Train loss: 0.1179, Train Accuracy: 0.9839\n","CLF Val loss: 0.5937, Validation Accuracy: 0.6842\n","Epoch 11/50\n","CLF Train loss: 0.1077, Train Accuracy: 0.9854\n","CLF Val loss: 0.6349, Validation Accuracy: 0.6901\n","Epoch 12/50\n","CLF Train loss: 0.1158, Train Accuracy: 0.9795\n","CLF Val loss: 0.7690, Validation Accuracy: 0.6433\n","Epoch 13/50\n","CLF Train loss: 0.1386, Train Accuracy: 0.9619\n","CLF Val loss: 0.6469, Validation Accuracy: 0.6842\n","Epoch 14/50\n","CLF Train loss: 0.1108, Train Accuracy: 0.9780\n","CLF Val loss: 0.6219, Validation Accuracy: 0.6667\n","Fold 3/10\n","{'accuracy': 0.7158, 'senstivity': 0.4762, 'specificity': 0.9057, 'loss': 0.5676}\n","--------------------------------------------\n","Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 766.3069\n","AE Val loss: 684.8303\n","Epoch 2/50\n","AE Train loss: 625.8976\n","AE Val loss: 628.8398\n","Epoch 3/50\n","AE Train loss: 551.5178\n","AE Val loss: 594.3616\n","Epoch 4/50\n","AE Train loss: 496.0129\n","AE Val loss: 575.8403\n","Epoch 5/50\n","AE Train loss: 451.1488\n","AE Val loss: 560.2953\n","Epoch 6/50\n","AE Train loss: 411.1554\n","AE Val loss: 550.3632\n","Epoch 7/50\n","AE Train loss: 374.1249\n","AE Val loss: 537.9457\n","Epoch 8/50\n","AE Train loss: 341.9946\n","AE Val loss: 534.1977\n","Epoch 9/50\n","AE Train loss: 311.4868\n","AE Val loss: 523.4548\n","Epoch 10/50\n","AE Train loss: 286.4169\n","AE Val loss: 520.9350\n","Epoch 11/50\n","AE Train loss: 266.9207\n","AE Val loss: 510.3647\n","Epoch 12/50\n","AE Train loss: 244.5746\n","AE Val loss: 511.9769\n","Epoch 13/50\n","AE Train loss: 225.3324\n","AE Val loss: 501.7690\n","Epoch 14/50\n","AE Train loss: 209.7134\n","AE Val loss: 500.2971\n","Epoch 15/50\n","AE Train loss: 194.2498\n","AE Val loss: 495.4261\n","Epoch 16/50\n","AE Train loss: 181.8775\n","AE Val loss: 491.5223\n","Epoch 17/50\n","AE Train loss: 170.3392\n","AE Val loss: 489.3003\n","Epoch 18/50\n","AE Train loss: 159.2592\n","AE Val loss: 492.5754\n","Epoch 19/50\n","AE Train loss: 149.4323\n","AE Val loss: 485.7818\n","Epoch 20/50\n","AE Train loss: 140.7152\n","AE Val loss: 486.4825\n","Epoch 21/50\n","AE Train loss: 132.4928\n","AE Val loss: 484.5220\n","Epoch 22/50\n","AE Train loss: 126.0548\n","AE Val loss: 481.8275\n","Epoch 23/50\n","AE Train loss: 118.9194\n","AE Val loss: 480.5483\n","Epoch 24/50\n","AE Train loss: 111.9887\n","AE Val loss: 480.8965\n","Epoch 25/50\n","AE Train loss: 105.3730\n","AE Val loss: 477.1850\n","Epoch 26/50\n","AE Train loss: 98.8885\n","AE Val loss: 476.7706\n","Epoch 27/50\n","AE Train loss: 94.0609\n","AE Val loss: 478.5261\n","Epoch 28/50\n","AE Train loss: 89.3511\n","AE Val loss: 476.5962\n","Epoch 29/50\n","AE Train loss: 84.9636\n","AE Val loss: 476.8368\n","Epoch 30/50\n","AE Train loss: 81.1936\n","AE Val loss: 473.8889\n","Epoch 31/50\n","AE Train loss: 77.1723\n","AE Val loss: 476.2852\n","Epoch 32/50\n","AE Train loss: 74.8184\n","AE Val loss: 471.8162\n","Epoch 33/50\n","AE Train loss: 71.6530\n","AE Val loss: 474.5958\n","Epoch 34/50\n","AE Train loss: 69.8154\n","AE Val loss: 475.5942\n","Epoch 35/50\n","AE Train loss: 68.1980\n","AE Val loss: 476.3764\n","Epoch 36/50\n","AE Train loss: 65.4846\n","AE Val loss: 472.7852\n","Epoch 37/50\n","AE Train loss: 61.9395\n","AE Val loss: 468.8375\n","Epoch 38/50\n","AE Train loss: 59.4837\n","AE Val loss: 471.3785\n","Epoch 39/50\n","AE Train loss: 56.8731\n","AE Val loss: 468.2995\n","Epoch 40/50\n","AE Train loss: 54.3500\n","AE Val loss: 471.7018\n","Epoch 41/50\n","AE Train loss: 52.6783\n","AE Val loss: 470.0469\n","Epoch 42/50\n","AE Train loss: 50.5162\n","AE Val loss: 468.9929\n","Epoch 43/50\n","AE Train loss: 48.8135\n","AE Val loss: 468.5755\n","Epoch 44/50\n","AE Train loss: 46.7851\n","AE Val loss: 467.5667\n","Epoch 45/50\n","AE Train loss: 45.4637\n","AE Val loss: 465.3259\n","Epoch 46/50\n","AE Train loss: 43.7747\n","AE Val loss: 469.0422\n","Epoch 47/50\n","AE Train loss: 42.9953\n","AE Val loss: 466.0341\n","Epoch 48/50\n","AE Train loss: 43.0474\n","AE Val loss: 468.1888\n","Epoch 49/50\n","AE Train loss: 42.5656\n","AE Val loss: 467.4980\n","Epoch 50/50\n","AE Train loss: 42.5533\n","AE Val loss: 469.1004\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6671, Train Accuracy: 0.6530\n","CLF Val loss: 0.6494, Validation Accuracy: 0.6257\n","Epoch 2/50\n","CLF Train loss: 0.5088, Train Accuracy: 0.7423\n","CLF Val loss: 0.5786, Validation Accuracy: 0.6784\n","Epoch 3/50\n","CLF Train loss: 0.3877, Train Accuracy: 0.8375\n","CLF Val loss: 0.6083, Validation Accuracy: 0.6784\n","Epoch 4/50\n","CLF Train loss: 0.2618, Train Accuracy: 0.9224\n","CLF Val loss: 0.5797, Validation Accuracy: 0.6901\n","Epoch 5/50\n","CLF Train loss: 0.2543, Train Accuracy: 0.8917\n","CLF Val loss: 0.5578, Validation Accuracy: 0.7018\n","Epoch 6/50\n","CLF Train loss: 0.1976, Train Accuracy: 0.9370\n","CLF Val loss: 0.6347, Validation Accuracy: 0.6901\n","Epoch 7/50\n","CLF Train loss: 0.1818, Train Accuracy: 0.9590\n","CLF Val loss: 0.5931, Validation Accuracy: 0.6901\n","Epoch 8/50\n","CLF Train loss: 0.1464, Train Accuracy: 0.9693\n","CLF Val loss: 0.6520, Validation Accuracy: 0.6959\n","Epoch 9/50\n","CLF Train loss: 0.1265, Train Accuracy: 0.9810\n","CLF Val loss: 0.6058, Validation Accuracy: 0.7135\n","Epoch 10/50\n","CLF Train loss: 0.1258, Train Accuracy: 0.9736\n","CLF Val loss: 0.6450, Validation Accuracy: 0.7135\n","Epoch 11/50\n","CLF Train loss: 0.1078, Train Accuracy: 0.9868\n","CLF Val loss: 0.6268, Validation Accuracy: 0.7018\n","Epoch 12/50\n","CLF Train loss: 0.0903, Train Accuracy: 0.9956\n","CLF Val loss: 0.6713, Validation Accuracy: 0.6725\n","Epoch 13/50\n","CLF Train loss: 0.0912, Train Accuracy: 0.9912\n","CLF Val loss: 0.6842, Validation Accuracy: 0.7076\n","Epoch 14/50\n","CLF Train loss: 0.0860, Train Accuracy: 0.9941\n","CLF Val loss: 0.6720, Validation Accuracy: 0.7135\n","Epoch 15/50\n","CLF Train loss: 0.1091, Train Accuracy: 0.9780\n","CLF Val loss: 0.6378, Validation Accuracy: 0.7251\n","Epoch 16/50\n","CLF Train loss: 0.1128, Train Accuracy: 0.9810\n","CLF Val loss: 0.6784, Validation Accuracy: 0.6901\n","Epoch 17/50\n","CLF Train loss: 0.1154, Train Accuracy: 0.9736\n","CLF Val loss: 0.6182, Validation Accuracy: 0.7193\n","Epoch 18/50\n","CLF Train loss: 0.1240, Train Accuracy: 0.9736\n","CLF Val loss: 0.7107, Validation Accuracy: 0.7018\n","Epoch 19/50\n","CLF Train loss: 0.0654, Train Accuracy: 0.9956\n","CLF Val loss: 0.5944, Validation Accuracy: 0.7310\n","Epoch 20/50\n","CLF Train loss: 0.0585, Train Accuracy: 0.9985\n","CLF Val loss: 0.6909, Validation Accuracy: 0.6959\n","Epoch 21/50\n","CLF Train loss: 0.0728, Train Accuracy: 0.9985\n","CLF Val loss: 0.5964, Validation Accuracy: 0.7135\n","Epoch 22/50\n","CLF Train loss: 0.0820, Train Accuracy: 0.9927\n","CLF Val loss: 0.6672, Validation Accuracy: 0.7076\n","Epoch 23/50\n","CLF Train loss: 0.0722, Train Accuracy: 0.9912\n","CLF Val loss: 0.5928, Validation Accuracy: 0.7310\n","Epoch 24/50\n","CLF Train loss: 0.0628, Train Accuracy: 0.9956\n","CLF Val loss: 0.6232, Validation Accuracy: 0.7193\n","Epoch 25/50\n","CLF Train loss: 0.0579, Train Accuracy: 0.9956\n","CLF Val loss: 0.6788, Validation Accuracy: 0.6901\n","Epoch 26/50\n","CLF Train loss: 0.0700, Train Accuracy: 0.9912\n","CLF Val loss: 0.7036, Validation Accuracy: 0.7251\n","Epoch 27/50\n","CLF Train loss: 0.0797, Train Accuracy: 0.9941\n","CLF Val loss: 0.7017, Validation Accuracy: 0.6842\n","Epoch 28/50\n","CLF Train loss: 0.0701, Train Accuracy: 0.9927\n","CLF Val loss: 0.7103, Validation Accuracy: 0.6901\n","Fold 4/10\n","{'accuracy': 0.6842, 'senstivity': 0.7619, 'specificity': 0.6226, 'loss': 0.739}\n","--------------------------------------------\n","Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 771.1776\n","AE Val loss: 708.2865\n","Epoch 2/50\n","AE Train loss: 627.8608\n","AE Val loss: 645.8614\n","Epoch 3/50\n","AE Train loss: 554.0125\n","AE Val loss: 612.1946\n","Epoch 4/50\n","AE Train loss: 497.3948\n","AE Val loss: 589.9189\n","Epoch 5/50\n","AE Train loss: 449.3842\n","AE Val loss: 573.5865\n","Epoch 6/50\n","AE Train loss: 408.7391\n","AE Val loss: 562.4197\n","Epoch 7/50\n","AE Train loss: 374.9312\n","AE Val loss: 557.7156\n","Epoch 8/50\n","AE Train loss: 344.7392\n","AE Val loss: 547.2591\n","Epoch 9/50\n","AE Train loss: 316.2722\n","AE Val loss: 539.8977\n","Epoch 10/50\n","AE Train loss: 288.5284\n","AE Val loss: 533.3776\n","Epoch 11/50\n","AE Train loss: 265.0404\n","AE Val loss: 525.6814\n","Epoch 12/50\n","AE Train loss: 244.6936\n","AE Val loss: 520.1672\n","Epoch 13/50\n","AE Train loss: 225.7121\n","AE Val loss: 519.2058\n","Epoch 14/50\n","AE Train loss: 209.6588\n","AE Val loss: 513.3503\n","Epoch 15/50\n","AE Train loss: 194.9467\n","AE Val loss: 509.8027\n","Epoch 16/50\n","AE Train loss: 183.1600\n","AE Val loss: 506.8460\n","Epoch 17/50\n","AE Train loss: 171.7234\n","AE Val loss: 505.5148\n","Epoch 18/50\n","AE Train loss: 162.6980\n","AE Val loss: 505.6975\n","Epoch 19/50\n","AE Train loss: 151.1995\n","AE Val loss: 500.8511\n","Epoch 20/50\n","AE Train loss: 142.2002\n","AE Val loss: 499.4257\n","Epoch 21/50\n","AE Train loss: 133.5063\n","AE Val loss: 496.2357\n","Epoch 22/50\n","AE Train loss: 125.2478\n","AE Val loss: 496.7158\n","Epoch 23/50\n","AE Train loss: 117.7764\n","AE Val loss: 494.5632\n","Epoch 24/50\n","AE Train loss: 111.8578\n","AE Val loss: 495.0156\n","Epoch 25/50\n","AE Train loss: 106.6429\n","AE Val loss: 491.3499\n","Epoch 26/50\n","AE Train loss: 101.5474\n","AE Val loss: 490.3164\n","Epoch 27/50\n","AE Train loss: 97.7396\n","AE Val loss: 490.3619\n","Epoch 28/50\n","AE Train loss: 92.7516\n","AE Val loss: 488.9229\n","Epoch 29/50\n","AE Train loss: 88.0906\n","AE Val loss: 487.0619\n","Epoch 30/50\n","AE Train loss: 82.5942\n","AE Val loss: 487.2236\n","Epoch 31/50\n","AE Train loss: 78.7934\n","AE Val loss: 488.3488\n","Epoch 32/50\n","AE Train loss: 74.2991\n","AE Val loss: 484.6022\n","Epoch 33/50\n","AE Train loss: 69.6855\n","AE Val loss: 484.6690\n","Epoch 34/50\n","AE Train loss: 65.7553\n","AE Val loss: 483.4767\n","Epoch 35/50\n","AE Train loss: 62.9415\n","AE Val loss: 483.9549\n","Epoch 36/50\n","AE Train loss: 61.0430\n","AE Val loss: 482.7038\n","Epoch 37/50\n","AE Train loss: 59.9135\n","AE Val loss: 482.7392\n","Epoch 38/50\n","AE Train loss: 57.9016\n","AE Val loss: 482.8936\n","Epoch 39/50\n","AE Train loss: 56.2928\n","AE Val loss: 480.8540\n","Epoch 40/50\n","AE Train loss: 54.9268\n","AE Val loss: 480.5011\n","Epoch 41/50\n","AE Train loss: 53.1537\n","AE Val loss: 483.5412\n","Epoch 42/50\n","AE Train loss: 51.7930\n","AE Val loss: 482.9828\n","Epoch 43/50\n","AE Train loss: 50.6275\n","AE Val loss: 485.0274\n","Epoch 44/50\n","AE Train loss: 48.6101\n","AE Val loss: 480.6440\n","Epoch 45/50\n","AE Train loss: 46.4554\n","AE Val loss: 481.0281\n","Epoch 46/50\n","AE Train loss: 44.9565\n","AE Val loss: 484.9027\n","Epoch 47/50\n","AE Train loss: 43.7198\n","AE Val loss: 480.7773\n","Epoch 48/50\n","AE Train loss: 43.0376\n","AE Val loss: 481.1187\n","Epoch 49/50\n","AE Train loss: 41.9494\n","AE Val loss: 480.6656\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6642, Train Accuracy: 0.6237\n","CLF Val loss: 0.5593, Validation Accuracy: 0.7135\n","Epoch 2/50\n","CLF Train loss: 0.4978, Train Accuracy: 0.7482\n","CLF Val loss: 0.5641, Validation Accuracy: 0.6901\n","Epoch 3/50\n","CLF Train loss: 0.3886, Train Accuracy: 0.8258\n","CLF Val loss: 0.5261, Validation Accuracy: 0.7368\n","Epoch 4/50\n","CLF Train loss: 0.2738, Train Accuracy: 0.9180\n","CLF Val loss: 0.4987, Validation Accuracy: 0.7427\n","Epoch 5/50\n","CLF Train loss: 0.2466, Train Accuracy: 0.9078\n","CLF Val loss: 0.5981, Validation Accuracy: 0.7018\n","Epoch 6/50\n","CLF Train loss: 0.1928, Train Accuracy: 0.9400\n","CLF Val loss: 0.5641, Validation Accuracy: 0.7544\n","Epoch 7/50\n","CLF Train loss: 0.1810, Train Accuracy: 0.9400\n","CLF Val loss: 0.5642, Validation Accuracy: 0.7251\n","Epoch 8/50\n","CLF Train loss: 0.1504, Train Accuracy: 0.9678\n","CLF Val loss: 0.5576, Validation Accuracy: 0.7076\n","Epoch 9/50\n","CLF Train loss: 0.1770, Train Accuracy: 0.9400\n","CLF Val loss: 0.6611, Validation Accuracy: 0.6725\n","Epoch 10/50\n","CLF Train loss: 0.1241, Train Accuracy: 0.9736\n","CLF Val loss: 0.6214, Validation Accuracy: 0.7018\n","Epoch 11/50\n","CLF Train loss: 0.1024, Train Accuracy: 0.9883\n","CLF Val loss: 0.5513, Validation Accuracy: 0.7427\n","Epoch 12/50\n","CLF Train loss: 0.1035, Train Accuracy: 0.9898\n","CLF Val loss: 0.5739, Validation Accuracy: 0.7368\n","Epoch 13/50\n","CLF Train loss: 0.1054, Train Accuracy: 0.9883\n","CLF Val loss: 0.6027, Validation Accuracy: 0.7135\n","Epoch 14/50\n","CLF Train loss: 0.0836, Train Accuracy: 0.9941\n","CLF Val loss: 0.5238, Validation Accuracy: 0.7076\n","Epoch 15/50\n","CLF Train loss: 0.0780, Train Accuracy: 0.9941\n","CLF Val loss: 0.5141, Validation Accuracy: 0.7602\n","Epoch 16/50\n","CLF Train loss: 0.0974, Train Accuracy: 0.9912\n","CLF Val loss: 0.5268, Validation Accuracy: 0.7485\n","Epoch 17/50\n","CLF Train loss: 0.0779, Train Accuracy: 0.9985\n","CLF Val loss: 0.5549, Validation Accuracy: 0.7368\n","Epoch 18/50\n","CLF Train loss: 0.0776, Train Accuracy: 0.9941\n","CLF Val loss: 0.5151, Validation Accuracy: 0.7427\n","Epoch 19/50\n","CLF Train loss: 0.0650, Train Accuracy: 0.9985\n","CLF Val loss: 0.5170, Validation Accuracy: 0.7251\n","Epoch 20/50\n","CLF Train loss: 0.0704, Train Accuracy: 0.9956\n","CLF Val loss: 0.5409, Validation Accuracy: 0.7251\n","Epoch 21/50\n","CLF Train loss: 0.0785, Train Accuracy: 0.9927\n","CLF Val loss: 0.5368, Validation Accuracy: 0.7485\n","Epoch 22/50\n","CLF Train loss: 0.0773, Train Accuracy: 0.9941\n","CLF Val loss: 0.6096, Validation Accuracy: 0.7368\n","Epoch 23/50\n","CLF Train loss: 0.0799, Train Accuracy: 0.9898\n","CLF Val loss: 0.6335, Validation Accuracy: 0.6959\n","Epoch 24/50\n","CLF Train loss: 0.0639, Train Accuracy: 0.9956\n","CLF Val loss: 0.5480, Validation Accuracy: 0.7193\n","Fold 5/10\n","{'accuracy': 0.7684, 'senstivity': 0.6905, 'specificity': 0.8302, 'loss': 0.5349}\n","--------------------------------------------\n","Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 771.5391\n","AE Val loss: 702.5779\n","Epoch 2/50\n","AE Train loss: 627.4321\n","AE Val loss: 644.7223\n","Epoch 3/50\n","AE Train loss: 555.2717\n","AE Val loss: 610.5067\n","Epoch 4/50\n","AE Train loss: 500.1302\n","AE Val loss: 586.2117\n","Epoch 5/50\n","AE Train loss: 452.8299\n","AE Val loss: 570.9592\n","Epoch 6/50\n","AE Train loss: 411.9353\n","AE Val loss: 556.0810\n","Epoch 7/50\n","AE Train loss: 375.8499\n","AE Val loss: 551.1887\n","Epoch 8/50\n","AE Train loss: 342.7411\n","AE Val loss: 539.2255\n","Epoch 9/50\n","AE Train loss: 313.4734\n","AE Val loss: 530.0928\n","Epoch 10/50\n","AE Train loss: 288.8513\n","AE Val loss: 525.2463\n","Epoch 11/50\n","AE Train loss: 265.6014\n","AE Val loss: 522.4197\n","Epoch 12/50\n","AE Train loss: 246.1199\n","AE Val loss: 513.9391\n","Epoch 13/50\n","AE Train loss: 229.0275\n","AE Val loss: 513.8837\n","Epoch 14/50\n","AE Train loss: 213.1677\n","AE Val loss: 505.6818\n","Epoch 15/50\n","AE Train loss: 197.0638\n","AE Val loss: 507.7417\n","Epoch 16/50\n","AE Train loss: 183.8534\n","AE Val loss: 501.3298\n","Epoch 17/50\n","AE Train loss: 169.8937\n","AE Val loss: 495.2959\n","Epoch 18/50\n","AE Train loss: 157.7081\n","AE Val loss: 492.0391\n","Epoch 19/50\n","AE Train loss: 149.7021\n","AE Val loss: 491.2046\n","Epoch 20/50\n","AE Train loss: 141.0375\n","AE Val loss: 488.6470\n","Epoch 21/50\n","AE Train loss: 132.1275\n","AE Val loss: 489.5469\n","Epoch 22/50\n","AE Train loss: 125.5865\n","AE Val loss: 486.7173\n","Epoch 23/50\n","AE Train loss: 119.1046\n","AE Val loss: 488.0756\n","Epoch 24/50\n","AE Train loss: 113.2134\n","AE Val loss: 486.3941\n","Epoch 25/50\n","AE Train loss: 107.7309\n","AE Val loss: 488.4124\n","Epoch 26/50\n","AE Train loss: 102.5723\n","AE Val loss: 482.1281\n","Epoch 27/50\n","AE Train loss: 97.5822\n","AE Val loss: 484.5992\n","Epoch 28/50\n","AE Train loss: 91.5775\n","AE Val loss: 482.6215\n","Epoch 29/50\n","AE Train loss: 86.1536\n","AE Val loss: 479.3882\n","Epoch 30/50\n","AE Train loss: 81.2570\n","AE Val loss: 478.3026\n","Epoch 31/50\n","AE Train loss: 77.0137\n","AE Val loss: 475.7837\n","Epoch 32/50\n","AE Train loss: 73.7798\n","AE Val loss: 475.0065\n","Epoch 33/50\n","AE Train loss: 70.6370\n","AE Val loss: 475.4435\n","Epoch 34/50\n","AE Train loss: 67.4391\n","AE Val loss: 476.1241\n","Epoch 35/50\n","AE Train loss: 64.8314\n","AE Val loss: 476.8394\n","Epoch 36/50\n","AE Train loss: 62.2312\n","AE Val loss: 474.7833\n","Epoch 37/50\n","AE Train loss: 60.8621\n","AE Val loss: 481.8829\n","Epoch 38/50\n","AE Train loss: 59.1278\n","AE Val loss: 476.7131\n","Epoch 39/50\n","AE Train loss: 57.1001\n","AE Val loss: 475.0661\n","Epoch 40/50\n","AE Train loss: 54.9168\n","AE Val loss: 474.3552\n","Epoch 41/50\n","AE Train loss: 53.9328\n","AE Val loss: 476.4718\n","Epoch 42/50\n","AE Train loss: 51.8793\n","AE Val loss: 475.5078\n","Epoch 43/50\n","AE Train loss: 49.8632\n","AE Val loss: 472.6276\n","Epoch 44/50\n","AE Train loss: 48.0307\n","AE Val loss: 473.0064\n","Epoch 45/50\n","AE Train loss: 47.0461\n","AE Val loss: 473.0535\n","Epoch 46/50\n","AE Train loss: 46.0980\n","AE Val loss: 475.6431\n","Epoch 47/50\n","AE Train loss: 44.1069\n","AE Val loss: 472.2828\n","Epoch 48/50\n","AE Train loss: 42.9081\n","AE Val loss: 472.4800\n","Epoch 49/50\n","AE Train loss: 42.5053\n","AE Val loss: 472.8530\n","Epoch 50/50\n","AE Train loss: 42.9872\n","AE Val loss: 477.1996\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6432, Train Accuracy: 0.6281\n","CLF Val loss: 0.5097, Validation Accuracy: 0.7427\n","Epoch 2/50\n","CLF Train loss: 0.4516, Train Accuracy: 0.8053\n","CLF Val loss: 0.4825, Validation Accuracy: 0.7544\n","Epoch 3/50\n","CLF Train loss: 0.3767, Train Accuracy: 0.8507\n","CLF Val loss: 0.4632, Validation Accuracy: 0.7895\n","Epoch 4/50\n","CLF Train loss: 0.2801, Train Accuracy: 0.8990\n","CLF Val loss: 0.4873, Validation Accuracy: 0.7602\n","Epoch 5/50\n","CLF Train loss: 0.2258, Train Accuracy: 0.9297\n","CLF Val loss: 0.5028, Validation Accuracy: 0.7544\n","Epoch 6/50\n","CLF Train loss: 0.1891, Train Accuracy: 0.9429\n","CLF Val loss: 0.5126, Validation Accuracy: 0.7602\n","Epoch 7/50\n","CLF Train loss: 0.1846, Train Accuracy: 0.9502\n","CLF Val loss: 0.5333, Validation Accuracy: 0.7310\n","Epoch 8/50\n","CLF Train loss: 0.1463, Train Accuracy: 0.9722\n","CLF Val loss: 0.4494, Validation Accuracy: 0.8070\n","Epoch 9/50\n","CLF Train loss: 0.1167, Train Accuracy: 0.9868\n","CLF Val loss: 0.5801, Validation Accuracy: 0.7135\n","Epoch 10/50\n","CLF Train loss: 0.1284, Train Accuracy: 0.9722\n","CLF Val loss: 0.4893, Validation Accuracy: 0.7953\n","Epoch 11/50\n","CLF Train loss: 0.1238, Train Accuracy: 0.9780\n","CLF Val loss: 0.4544, Validation Accuracy: 0.7778\n","Epoch 12/50\n","CLF Train loss: 0.1103, Train Accuracy: 0.9868\n","CLF Val loss: 0.5701, Validation Accuracy: 0.7251\n","Epoch 13/50\n","CLF Train loss: 0.1295, Train Accuracy: 0.9707\n","CLF Val loss: 0.6165, Validation Accuracy: 0.7018\n","Epoch 14/50\n","CLF Train loss: 0.1149, Train Accuracy: 0.9795\n","CLF Val loss: 0.5121, Validation Accuracy: 0.7661\n","Epoch 15/50\n","CLF Train loss: 0.0896, Train Accuracy: 0.9883\n","CLF Val loss: 0.5110, Validation Accuracy: 0.7251\n","Epoch 16/50\n","CLF Train loss: 0.0776, Train Accuracy: 0.9956\n","CLF Val loss: 0.4677, Validation Accuracy: 0.7895\n","Epoch 17/50\n","CLF Train loss: 0.0849, Train Accuracy: 0.9912\n","CLF Val loss: 0.4837, Validation Accuracy: 0.7368\n","Fold 6/10\n","{'accuracy': 0.7895, 'senstivity': 0.8333, 'specificity': 0.7547, 'loss': 0.4769}\n","--------------------------------------------\n","Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 766.2407\n","AE Val loss: 700.6242\n","Epoch 2/50\n","AE Train loss: 623.4375\n","AE Val loss: 641.9822\n","Epoch 3/50\n","AE Train loss: 550.5538\n","AE Val loss: 607.1021\n","Epoch 4/50\n","AE Train loss: 492.9587\n","AE Val loss: 585.8801\n","Epoch 5/50\n","AE Train loss: 448.4565\n","AE Val loss: 572.7798\n","Epoch 6/50\n","AE Train loss: 410.3968\n","AE Val loss: 562.1384\n","Epoch 7/50\n","AE Train loss: 373.6959\n","AE Val loss: 544.9357\n","Epoch 8/50\n","AE Train loss: 337.3152\n","AE Val loss: 541.0152\n","Epoch 9/50\n","AE Train loss: 309.0275\n","AE Val loss: 528.3155\n","Epoch 10/50\n","AE Train loss: 283.3880\n","AE Val loss: 525.7827\n","Epoch 11/50\n","AE Train loss: 263.1969\n","AE Val loss: 524.8906\n","Epoch 12/50\n","AE Train loss: 244.7648\n","AE Val loss: 519.7066\n","Epoch 13/50\n","AE Train loss: 226.6611\n","AE Val loss: 516.6783\n","Epoch 14/50\n","AE Train loss: 211.4789\n","AE Val loss: 511.8464\n","Epoch 15/50\n","AE Train loss: 196.5146\n","AE Val loss: 507.7532\n","Epoch 16/50\n","AE Train loss: 182.2486\n","AE Val loss: 501.7054\n","Epoch 17/50\n","AE Train loss: 169.8677\n","AE Val loss: 500.3132\n","Epoch 18/50\n","AE Train loss: 159.5409\n","AE Val loss: 498.9637\n","Epoch 19/50\n","AE Train loss: 149.5965\n","AE Val loss: 494.4229\n","Epoch 20/50\n","AE Train loss: 140.2150\n","AE Val loss: 493.2815\n","Epoch 21/50\n","AE Train loss: 132.4569\n","AE Val loss: 492.0021\n","Epoch 22/50\n","AE Train loss: 124.5801\n","AE Val loss: 489.7469\n","Epoch 23/50\n","AE Train loss: 118.3214\n","AE Val loss: 492.3022\n","Epoch 24/50\n","AE Train loss: 111.2801\n","AE Val loss: 486.2427\n","Epoch 25/50\n","AE Train loss: 104.8542\n","AE Val loss: 486.7325\n","Epoch 26/50\n","AE Train loss: 99.7485\n","AE Val loss: 486.6581\n","Epoch 27/50\n","AE Train loss: 94.7384\n","AE Val loss: 483.2918\n","Epoch 28/50\n","AE Train loss: 90.4586\n","AE Val loss: 484.6763\n","Epoch 29/50\n","AE Train loss: 86.3767\n","AE Val loss: 483.9584\n","Epoch 30/50\n","AE Train loss: 81.9941\n","AE Val loss: 480.9078\n","Epoch 31/50\n","AE Train loss: 78.8364\n","AE Val loss: 489.7162\n","Epoch 32/50\n","AE Train loss: 75.1609\n","AE Val loss: 480.0300\n","Epoch 33/50\n","AE Train loss: 70.8843\n","AE Val loss: 485.8724\n","Epoch 34/50\n","AE Train loss: 67.5361\n","AE Val loss: 480.0144\n","Epoch 35/50\n","AE Train loss: 64.5187\n","AE Val loss: 479.6706\n","Epoch 36/50\n","AE Train loss: 62.3219\n","AE Val loss: 476.9685\n","Epoch 37/50\n","AE Train loss: 60.8555\n","AE Val loss: 479.2201\n","Epoch 38/50\n","AE Train loss: 58.9059\n","AE Val loss: 478.2713\n","Epoch 39/50\n","AE Train loss: 56.6726\n","AE Val loss: 480.8859\n","Epoch 40/50\n","AE Train loss: 54.4512\n","AE Val loss: 477.6165\n","Epoch 41/50\n","AE Train loss: 52.1799\n","AE Val loss: 477.3139\n","Epoch 42/50\n","AE Train loss: 51.0736\n","AE Val loss: 475.6562\n","Epoch 43/50\n","AE Train loss: 49.0324\n","AE Val loss: 481.3290\n","Epoch 44/50\n","AE Train loss: 47.2250\n","AE Val loss: 475.7154\n","Epoch 45/50\n","AE Train loss: 45.6769\n","AE Val loss: 476.8717\n","Epoch 46/50\n","AE Train loss: 44.4552\n","AE Val loss: 479.8650\n","Epoch 47/50\n","AE Train loss: 43.6662\n","AE Val loss: 479.8265\n","Epoch 48/50\n","AE Train loss: 42.4661\n","AE Val loss: 476.0158\n","Epoch 49/50\n","AE Train loss: 41.1313\n","AE Val loss: 475.4075\n","Epoch 50/50\n","AE Train loss: 40.0403\n","AE Val loss: 473.8901\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6036, Train Accuracy: 0.6647\n","CLF Val loss: 0.5407, Validation Accuracy: 0.6959\n","Epoch 2/50\n","CLF Train loss: 0.4245, Train Accuracy: 0.8170\n","CLF Val loss: 0.5438, Validation Accuracy: 0.7251\n","Epoch 3/50\n","CLF Train loss: 0.3488, Train Accuracy: 0.8551\n","CLF Val loss: 0.5681, Validation Accuracy: 0.7135\n","Epoch 4/50\n","CLF Train loss: 0.3571, Train Accuracy: 0.8316\n","CLF Val loss: 0.5585, Validation Accuracy: 0.7310\n","Epoch 5/50\n","CLF Train loss: 0.2458, Train Accuracy: 0.9165\n","CLF Val loss: 0.4830, Validation Accuracy: 0.7251\n","Epoch 6/50\n","CLF Train loss: 0.1905, Train Accuracy: 0.9488\n","CLF Val loss: 0.5843, Validation Accuracy: 0.7193\n","Epoch 7/50\n","CLF Train loss: 0.1480, Train Accuracy: 0.9693\n","CLF Val loss: 0.8051, Validation Accuracy: 0.6667\n","Epoch 8/50\n","CLF Train loss: 0.1691, Train Accuracy: 0.9502\n","CLF Val loss: 0.7914, Validation Accuracy: 0.6725\n","Epoch 9/50\n","CLF Train loss: 0.1609, Train Accuracy: 0.9649\n","CLF Val loss: 0.5928, Validation Accuracy: 0.6959\n","Epoch 10/50\n","CLF Train loss: 0.1108, Train Accuracy: 0.9854\n","CLF Val loss: 0.5248, Validation Accuracy: 0.7427\n","Epoch 11/50\n","CLF Train loss: 0.0908, Train Accuracy: 0.9956\n","CLF Val loss: 0.6023, Validation Accuracy: 0.7076\n","Epoch 12/50\n","CLF Train loss: 0.1040, Train Accuracy: 0.9868\n","CLF Val loss: 0.6168, Validation Accuracy: 0.7018\n","Epoch 13/50\n","CLF Train loss: 0.1182, Train Accuracy: 0.9751\n","CLF Val loss: 0.6073, Validation Accuracy: 0.7193\n","Epoch 14/50\n","CLF Train loss: 0.1267, Train Accuracy: 0.9663\n","CLF Val loss: 0.6194, Validation Accuracy: 0.7135\n","Epoch 15/50\n","CLF Train loss: 0.1121, Train Accuracy: 0.9795\n","CLF Val loss: 0.5617, Validation Accuracy: 0.7544\n","Epoch 16/50\n","CLF Train loss: 0.0763, Train Accuracy: 0.9927\n","CLF Val loss: 0.5625, Validation Accuracy: 0.7310\n","Epoch 17/50\n","CLF Train loss: 0.0684, Train Accuracy: 0.9985\n","CLF Val loss: 0.5394, Validation Accuracy: 0.7485\n","Epoch 18/50\n","CLF Train loss: 0.0784, Train Accuracy: 0.9927\n","CLF Val loss: 0.5852, Validation Accuracy: 0.7135\n","Epoch 19/50\n","CLF Train loss: 0.0682, Train Accuracy: 0.9956\n","CLF Val loss: 0.5756, Validation Accuracy: 0.7310\n","Epoch 20/50\n","CLF Train loss: 0.0764, Train Accuracy: 0.9941\n","CLF Val loss: 0.6147, Validation Accuracy: 0.7251\n","Epoch 21/50\n","CLF Train loss: 0.0920, Train Accuracy: 0.9839\n","CLF Val loss: 0.5401, Validation Accuracy: 0.7602\n","Epoch 22/50\n","CLF Train loss: 0.0653, Train Accuracy: 1.0000\n","CLF Val loss: 0.5956, Validation Accuracy: 0.7310\n","Epoch 23/50\n","CLF Train loss: 0.0702, Train Accuracy: 0.9956\n","CLF Val loss: 0.5787, Validation Accuracy: 0.7368\n","Epoch 24/50\n","CLF Train loss: 0.0587, Train Accuracy: 1.0000\n","CLF Val loss: 0.5915, Validation Accuracy: 0.7427\n","Epoch 25/50\n","CLF Train loss: 0.0554, Train Accuracy: 1.0000\n","CLF Val loss: 0.5697, Validation Accuracy: 0.7251\n","Epoch 26/50\n","CLF Train loss: 0.0658, Train Accuracy: 0.9956\n","CLF Val loss: 0.5334, Validation Accuracy: 0.7251\n","Epoch 27/50\n","CLF Train loss: 0.0598, Train Accuracy: 0.9971\n","CLF Val loss: 0.6075, Validation Accuracy: 0.7368\n","Epoch 28/50\n","CLF Train loss: 0.0559, Train Accuracy: 1.0000\n","CLF Val loss: 0.5606, Validation Accuracy: 0.7719\n","Epoch 29/50\n","CLF Train loss: 0.0481, Train Accuracy: 1.0000\n","CLF Val loss: 0.5442, Validation Accuracy: 0.7485\n","Epoch 30/50\n","CLF Train loss: 0.0509, Train Accuracy: 1.0000\n","CLF Val loss: 0.5514, Validation Accuracy: 0.7427\n","Epoch 31/50\n","CLF Train loss: 0.0507, Train Accuracy: 1.0000\n","CLF Val loss: 0.5831, Validation Accuracy: 0.7427\n","Epoch 32/50\n","CLF Train loss: 0.0621, Train Accuracy: 0.9971\n","CLF Val loss: 0.5875, Validation Accuracy: 0.7193\n","Epoch 33/50\n","CLF Train loss: 0.0659, Train Accuracy: 0.9941\n","CLF Val loss: 0.5713, Validation Accuracy: 0.7485\n","Epoch 34/50\n","CLF Train loss: 0.0704, Train Accuracy: 0.9912\n","CLF Val loss: 0.7104, Validation Accuracy: 0.7135\n","Epoch 35/50\n","CLF Train loss: 0.0769, Train Accuracy: 0.9868\n","CLF Val loss: 0.6017, Validation Accuracy: 0.7310\n","Epoch 36/50\n","CLF Train loss: 0.0592, Train Accuracy: 0.9956\n","CLF Val loss: 0.5612, Validation Accuracy: 0.7544\n","Epoch 37/50\n","CLF Train loss: 0.0555, Train Accuracy: 0.9941\n","CLF Val loss: 0.5849, Validation Accuracy: 0.7368\n","Fold 7/10\n","{'accuracy': 0.7263, 'senstivity': 0.7619, 'specificity': 0.6981, 'loss': 0.639}\n","--------------------------------------------\n","Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 775.3882\n","AE Val loss: 688.2222\n","Epoch 2/50\n","AE Train loss: 630.0345\n","AE Val loss: 631.6978\n","Epoch 3/50\n","AE Train loss: 556.2662\n","AE Val loss: 598.7283\n","Epoch 4/50\n","AE Train loss: 501.3228\n","AE Val loss: 577.7070\n","Epoch 5/50\n","AE Train loss: 451.9850\n","AE Val loss: 567.3286\n","Epoch 6/50\n","AE Train loss: 412.5766\n","AE Val loss: 550.0757\n","Epoch 7/50\n","AE Train loss: 375.5639\n","AE Val loss: 542.1912\n","Epoch 8/50\n","AE Train loss: 343.6792\n","AE Val loss: 529.6690\n","Epoch 9/50\n","AE Train loss: 315.4624\n","AE Val loss: 523.5880\n","Epoch 10/50\n","AE Train loss: 290.1591\n","AE Val loss: 517.6479\n","Epoch 11/50\n","AE Train loss: 266.6932\n","AE Val loss: 514.9678\n","Epoch 12/50\n","AE Train loss: 246.7881\n","AE Val loss: 512.1624\n","Epoch 13/50\n","AE Train loss: 227.7269\n","AE Val loss: 510.1329\n","Epoch 14/50\n","AE Train loss: 211.3179\n","AE Val loss: 504.4413\n","Epoch 15/50\n","AE Train loss: 197.3201\n","AE Val loss: 499.0243\n","Epoch 16/50\n","AE Train loss: 183.5428\n","AE Val loss: 496.8741\n","Epoch 17/50\n","AE Train loss: 171.5967\n","AE Val loss: 493.9196\n","Epoch 18/50\n","AE Train loss: 160.6325\n","AE Val loss: 490.5327\n","Epoch 19/50\n","AE Train loss: 151.2554\n","AE Val loss: 488.3887\n","Epoch 20/50\n","AE Train loss: 141.7464\n","AE Val loss: 485.9940\n","Epoch 21/50\n","AE Train loss: 132.8379\n","AE Val loss: 485.5354\n","Epoch 22/50\n","AE Train loss: 124.4630\n","AE Val loss: 484.7436\n","Epoch 23/50\n","AE Train loss: 117.9053\n","AE Val loss: 483.7550\n","Epoch 24/50\n","AE Train loss: 111.5552\n","AE Val loss: 489.0948\n","Epoch 25/50\n","AE Train loss: 105.6981\n","AE Val loss: 481.3300\n","Epoch 26/50\n","AE Train loss: 100.0922\n","AE Val loss: 481.6453\n","Epoch 27/50\n","AE Train loss: 94.3950\n","AE Val loss: 476.5465\n","Epoch 28/50\n","AE Train loss: 89.6777\n","AE Val loss: 479.9866\n","Epoch 29/50\n","AE Train loss: 86.6387\n","AE Val loss: 479.3254\n","Epoch 30/50\n","AE Train loss: 82.2239\n","AE Val loss: 478.2590\n","Epoch 31/50\n","AE Train loss: 78.6129\n","AE Val loss: 478.8479\n","Epoch 32/50\n","AE Train loss: 76.3257\n","AE Val loss: 478.6416\n","Epoch 33/50\n","AE Train loss: 73.0642\n","AE Val loss: 474.6057\n","Epoch 34/50\n","AE Train loss: 68.8810\n","AE Val loss: 475.5419\n","Epoch 35/50\n","AE Train loss: 66.1181\n","AE Val loss: 476.0316\n","Epoch 36/50\n","AE Train loss: 63.9538\n","AE Val loss: 473.7466\n","Epoch 37/50\n","AE Train loss: 60.8314\n","AE Val loss: 474.7148\n","Epoch 38/50\n","AE Train loss: 57.9875\n","AE Val loss: 474.5791\n","Epoch 39/50\n","AE Train loss: 56.1399\n","AE Val loss: 471.5623\n","Epoch 40/50\n","AE Train loss: 54.4122\n","AE Val loss: 475.1078\n","Epoch 41/50\n","AE Train loss: 53.3381\n","AE Val loss: 473.3530\n","Epoch 42/50\n","AE Train loss: 52.3507\n","AE Val loss: 471.8488\n","Epoch 43/50\n","AE Train loss: 50.6975\n","AE Val loss: 472.0170\n","Epoch 44/50\n","AE Train loss: 48.7166\n","AE Val loss: 472.8516\n","Epoch 45/50\n","AE Train loss: 46.7891\n","AE Val loss: 470.0125\n","Epoch 46/50\n","AE Train loss: 45.2639\n","AE Val loss: 472.5332\n","Epoch 47/50\n","AE Train loss: 44.3838\n","AE Val loss: 470.5608\n","Epoch 48/50\n","AE Train loss: 42.9169\n","AE Val loss: 472.3449\n","Epoch 49/50\n","AE Train loss: 41.6170\n","AE Val loss: 473.1128\n","Epoch 50/50\n","AE Train loss: 40.9611\n","AE Val loss: 469.5273\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6384, Train Accuracy: 0.6369\n","CLF Val loss: 0.5470, Validation Accuracy: 0.6842\n","Epoch 2/50\n","CLF Train loss: 0.4578, Train Accuracy: 0.7818\n","CLF Val loss: 0.5442, Validation Accuracy: 0.7076\n","Epoch 3/50\n","CLF Train loss: 0.3573, Train Accuracy: 0.8624\n","CLF Val loss: 0.6780, Validation Accuracy: 0.6667\n","Epoch 4/50\n","CLF Train loss: 0.3437, Train Accuracy: 0.8448\n","CLF Val loss: 0.5882, Validation Accuracy: 0.7193\n","Epoch 5/50\n","CLF Train loss: 0.2072, Train Accuracy: 0.9531\n","CLF Val loss: 0.7876, Validation Accuracy: 0.6374\n","Epoch 6/50\n","CLF Train loss: 0.3119, Train Accuracy: 0.8492\n","CLF Val loss: 0.5944, Validation Accuracy: 0.7135\n","Epoch 7/50\n","CLF Train loss: 0.2103, Train Accuracy: 0.9253\n","CLF Val loss: 0.6672, Validation Accuracy: 0.6959\n","Epoch 8/50\n","CLF Train loss: 0.1560, Train Accuracy: 0.9693\n","CLF Val loss: 0.6613, Validation Accuracy: 0.6784\n","Epoch 9/50\n","CLF Train loss: 0.1257, Train Accuracy: 0.9810\n","CLF Val loss: 0.6214, Validation Accuracy: 0.7135\n","Epoch 10/50\n","CLF Train loss: 0.1131, Train Accuracy: 0.9854\n","CLF Val loss: 0.6024, Validation Accuracy: 0.7135\n","Epoch 11/50\n","CLF Train loss: 0.1025, Train Accuracy: 0.9912\n","CLF Val loss: 0.6474, Validation Accuracy: 0.7076\n","Epoch 12/50\n","CLF Train loss: 0.1048, Train Accuracy: 0.9854\n","CLF Val loss: 0.6201, Validation Accuracy: 0.7193\n","Epoch 13/50\n","CLF Train loss: 0.1372, Train Accuracy: 0.9766\n","CLF Val loss: 0.6535, Validation Accuracy: 0.7193\n","Fold 8/10\n","{'accuracy': 0.8526, 'senstivity': 0.8095, 'specificity': 0.8868, 'loss': 0.3936}\n","--------------------------------------------\n","Number of train subjects :  683\n","Number of val subjects :  171\n","Number of test subjects :  95\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 775.0398\n","AE Val loss: 691.9044\n","Epoch 2/50\n","AE Train loss: 629.6696\n","AE Val loss: 633.9526\n","Epoch 3/50\n","AE Train loss: 554.5504\n","AE Val loss: 599.0566\n","Epoch 4/50\n","AE Train loss: 498.1125\n","AE Val loss: 578.3715\n","Epoch 5/50\n","AE Train loss: 449.6950\n","AE Val loss: 561.3886\n","Epoch 6/50\n","AE Train loss: 411.0326\n","AE Val loss: 550.0995\n","Epoch 7/50\n","AE Train loss: 375.5772\n","AE Val loss: 539.0626\n","Epoch 8/50\n","AE Train loss: 340.9244\n","AE Val loss: 529.0927\n","Epoch 9/50\n","AE Train loss: 310.6958\n","AE Val loss: 524.2821\n","Epoch 10/50\n","AE Train loss: 285.2520\n","AE Val loss: 517.7663\n","Epoch 11/50\n","AE Train loss: 263.3931\n","AE Val loss: 513.8932\n","Epoch 12/50\n","AE Train loss: 245.5047\n","AE Val loss: 508.2549\n","Epoch 13/50\n","AE Train loss: 228.2685\n","AE Val loss: 507.1944\n","Epoch 14/50\n","AE Train loss: 212.3516\n","AE Val loss: 504.3709\n","Epoch 15/50\n","AE Train loss: 198.0042\n","AE Val loss: 498.1146\n","Epoch 16/50\n","AE Train loss: 184.3854\n","AE Val loss: 496.3151\n","Epoch 17/50\n","AE Train loss: 171.0541\n","AE Val loss: 496.8640\n","Epoch 18/50\n","AE Train loss: 160.0319\n","AE Val loss: 492.5452\n","Epoch 19/50\n","AE Train loss: 150.5000\n","AE Val loss: 490.1738\n","Epoch 20/50\n","AE Train loss: 142.4240\n","AE Val loss: 494.4021\n","Epoch 21/50\n","AE Train loss: 132.8974\n","AE Val loss: 484.7096\n","Epoch 22/50\n","AE Train loss: 123.8810\n","AE Val loss: 485.4239\n","Epoch 23/50\n","AE Train loss: 117.6626\n","AE Val loss: 485.7597\n","Epoch 24/50\n","AE Train loss: 112.4704\n","AE Val loss: 483.5800\n","Epoch 25/50\n","AE Train loss: 105.9868\n","AE Val loss: 482.3614\n","Epoch 26/50\n","AE Train loss: 100.8752\n","AE Val loss: 480.6057\n","Epoch 27/50\n","AE Train loss: 95.9872\n","AE Val loss: 479.3889\n","Epoch 28/50\n","AE Train loss: 91.2108\n","AE Val loss: 478.3737\n","Epoch 29/50\n","AE Train loss: 87.0683\n","AE Val loss: 476.9518\n","Epoch 30/50\n","AE Train loss: 81.8312\n","AE Val loss: 480.3645\n","Epoch 31/50\n","AE Train loss: 77.8447\n","AE Val loss: 477.1490\n","Epoch 32/50\n","AE Train loss: 74.3089\n","AE Val loss: 476.5676\n","Epoch 33/50\n","AE Train loss: 70.3570\n","AE Val loss: 474.8315\n","Epoch 34/50\n","AE Train loss: 67.5792\n","AE Val loss: 474.9472\n","Epoch 35/50\n","AE Train loss: 64.5410\n","AE Val loss: 475.7385\n","Epoch 36/50\n","AE Train loss: 61.9007\n","AE Val loss: 472.6993\n","Epoch 37/50\n","AE Train loss: 60.0901\n","AE Val loss: 471.5674\n","Epoch 38/50\n","AE Train loss: 58.0575\n","AE Val loss: 472.9064\n","Epoch 39/50\n","AE Train loss: 56.7223\n","AE Val loss: 473.2139\n","Epoch 40/50\n","AE Train loss: 55.9033\n","AE Val loss: 471.2599\n","Epoch 41/50\n","AE Train loss: 54.0098\n","AE Val loss: 474.4492\n","Epoch 42/50\n","AE Train loss: 52.2768\n","AE Val loss: 472.8631\n","Epoch 43/50\n","AE Train loss: 50.2927\n","AE Val loss: 472.0039\n","Epoch 44/50\n","AE Train loss: 48.8875\n","AE Val loss: 470.7451\n","Epoch 45/50\n","AE Train loss: 47.2485\n","AE Val loss: 471.2953\n","Epoch 46/50\n","AE Train loss: 45.1217\n","AE Val loss: 472.1471\n","Epoch 47/50\n","AE Train loss: 43.2510\n","AE Val loss: 468.8134\n","Epoch 48/50\n","AE Train loss: 41.7008\n","AE Val loss: 472.4687\n","Epoch 49/50\n","AE Train loss: 40.7476\n","AE Val loss: 470.5069\n","Epoch 50/50\n","AE Train loss: 40.2385\n","AE Val loss: 470.0974\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6478, Train Accuracy: 0.6135\n","CLF Val loss: 0.7200, Validation Accuracy: 0.6023\n","Epoch 2/50\n","CLF Train loss: 0.5404, Train Accuracy: 0.7174\n","CLF Val loss: 0.6364, Validation Accuracy: 0.6257\n","Epoch 3/50\n","CLF Train loss: 0.4218, Train Accuracy: 0.8170\n","CLF Val loss: 0.5288, Validation Accuracy: 0.7602\n","Epoch 4/50\n","CLF Train loss: 0.3873, Train Accuracy: 0.8243\n","CLF Val loss: 0.5163, Validation Accuracy: 0.7485\n","Epoch 5/50\n","CLF Train loss: 0.2777, Train Accuracy: 0.8975\n","CLF Val loss: 0.5152, Validation Accuracy: 0.7602\n","Epoch 6/50\n","CLF Train loss: 0.2496, Train Accuracy: 0.9078\n","CLF Val loss: 0.5100, Validation Accuracy: 0.7719\n","Epoch 7/50\n","CLF Train loss: 0.1952, Train Accuracy: 0.9517\n","CLF Val loss: 0.5082, Validation Accuracy: 0.7544\n","Epoch 8/50\n","CLF Train loss: 0.1348, Train Accuracy: 0.9780\n","CLF Val loss: 0.5357, Validation Accuracy: 0.7544\n","Epoch 9/50\n","CLF Train loss: 0.1128, Train Accuracy: 0.9868\n","CLF Val loss: 0.5531, Validation Accuracy: 0.7193\n","Epoch 10/50\n","CLF Train loss: 0.1179, Train Accuracy: 0.9868\n","CLF Val loss: 0.5208, Validation Accuracy: 0.7602\n","Epoch 11/50\n","CLF Train loss: 0.1054, Train Accuracy: 0.9898\n","CLF Val loss: 0.5318, Validation Accuracy: 0.7719\n","Epoch 12/50\n","CLF Train loss: 0.1051, Train Accuracy: 0.9898\n","CLF Val loss: 0.5492, Validation Accuracy: 0.7368\n","Epoch 13/50\n","CLF Train loss: 0.1147, Train Accuracy: 0.9795\n","CLF Val loss: 0.5779, Validation Accuracy: 0.7485\n","Epoch 14/50\n","CLF Train loss: 0.1562, Train Accuracy: 0.9561\n","CLF Val loss: 0.5614, Validation Accuracy: 0.7602\n","Epoch 15/50\n","CLF Train loss: 0.0952, Train Accuracy: 0.9912\n","CLF Val loss: 0.5314, Validation Accuracy: 0.7602\n","Fold 9/10\n","{'accuracy': 0.7368, 'senstivity': 0.7143, 'specificity': 0.7547, 'loss': 0.6161}\n","--------------------------------------------\n","Number of train subjects :  684\n","Number of val subjects :  171\n","Number of test subjects :  94\n","Auto Encoder training Started-----------\n","Epoch 1/50\n","AE Train loss: 778.2292\n","AE Val loss: 707.7847\n","Epoch 2/50\n","AE Train loss: 629.7451\n","AE Val loss: 643.2241\n","Epoch 3/50\n","AE Train loss: 554.0173\n","AE Val loss: 608.8319\n","Epoch 4/50\n","AE Train loss: 499.4512\n","AE Val loss: 591.9478\n","Epoch 5/50\n","AE Train loss: 456.3841\n","AE Val loss: 577.7938\n","Epoch 6/50\n","AE Train loss: 413.3913\n","AE Val loss: 558.4680\n","Epoch 7/50\n","AE Train loss: 376.2641\n","AE Val loss: 548.4006\n","Epoch 8/50\n","AE Train loss: 341.7047\n","AE Val loss: 538.6797\n","Epoch 9/50\n","AE Train loss: 311.5438\n","AE Val loss: 531.8940\n","Epoch 10/50\n","AE Train loss: 287.8643\n","AE Val loss: 525.7332\n","Epoch 11/50\n","AE Train loss: 265.0837\n","AE Val loss: 521.3879\n","Epoch 12/50\n","AE Train loss: 244.5722\n","AE Val loss: 516.0462\n","Epoch 13/50\n","AE Train loss: 225.2719\n","AE Val loss: 512.0126\n","Epoch 14/50\n","AE Train loss: 209.7926\n","AE Val loss: 510.3917\n","Epoch 15/50\n","AE Train loss: 196.7030\n","AE Val loss: 508.8755\n","Epoch 16/50\n","AE Train loss: 184.5089\n","AE Val loss: 502.7023\n","Epoch 17/50\n","AE Train loss: 170.7543\n","AE Val loss: 499.3252\n","Epoch 18/50\n","AE Train loss: 160.1203\n","AE Val loss: 502.5664\n","Epoch 19/50\n","AE Train loss: 150.7214\n","AE Val loss: 500.8958\n","Epoch 20/50\n","AE Train loss: 141.5237\n","AE Val loss: 493.4706\n","Epoch 21/50\n","AE Train loss: 132.6399\n","AE Val loss: 492.2612\n","Epoch 22/50\n","AE Train loss: 124.9219\n","AE Val loss: 489.4193\n","Epoch 23/50\n","AE Train loss: 116.9096\n","AE Val loss: 489.1730\n","Epoch 24/50\n","AE Train loss: 110.4083\n","AE Val loss: 488.4219\n","Epoch 25/50\n","AE Train loss: 103.6917\n","AE Val loss: 486.0463\n","Epoch 26/50\n","AE Train loss: 98.2055\n","AE Val loss: 488.8165\n","Epoch 27/50\n","AE Train loss: 94.0848\n","AE Val loss: 487.5831\n","Epoch 28/50\n","AE Train loss: 89.5445\n","AE Val loss: 483.8231\n","Epoch 29/50\n","AE Train loss: 84.3739\n","AE Val loss: 481.4563\n","Epoch 30/50\n","AE Train loss: 80.4962\n","AE Val loss: 481.9010\n","Epoch 31/50\n","AE Train loss: 77.4928\n","AE Val loss: 481.6576\n","Epoch 32/50\n","AE Train loss: 74.2058\n","AE Val loss: 480.7938\n","Epoch 33/50\n","AE Train loss: 71.4242\n","AE Val loss: 481.6463\n","Epoch 34/50\n","AE Train loss: 69.0038\n","AE Val loss: 482.2550\n","Epoch 35/50\n","AE Train loss: 66.0363\n","AE Val loss: 479.7451\n","Epoch 36/50\n","AE Train loss: 63.0168\n","AE Val loss: 481.5482\n","Epoch 37/50\n","AE Train loss: 60.6686\n","AE Val loss: 476.6003\n","Epoch 38/50\n","AE Train loss: 59.3078\n","AE Val loss: 478.0510\n","Epoch 39/50\n","AE Train loss: 57.2709\n","AE Val loss: 478.7430\n","Epoch 40/50\n","AE Train loss: 54.6302\n","AE Val loss: 476.7850\n","Epoch 41/50\n","AE Train loss: 52.0637\n","AE Val loss: 477.6048\n","Epoch 42/50\n","AE Train loss: 50.1653\n","AE Val loss: 476.3877\n","Epoch 43/50\n","AE Train loss: 49.4205\n","AE Val loss: 477.1116\n","Epoch 44/50\n","AE Train loss: 48.0422\n","AE Val loss: 477.3824\n","Epoch 45/50\n","AE Train loss: 46.7014\n","AE Val loss: 478.0186\n","Epoch 46/50\n","AE Train loss: 44.7019\n","AE Val loss: 475.1392\n","Epoch 47/50\n","AE Train loss: 44.1613\n","AE Val loss: 477.7257\n","Epoch 48/50\n","AE Train loss: 44.0279\n","AE Val loss: 477.8980\n","Epoch 49/50\n","AE Train loss: 43.2575\n","AE Val loss: 478.5558\n","Epoch 50/50\n","AE Train loss: 42.4387\n","AE Val loss: 479.0874\n","Classifier training Started-----------\n","Epoch 1/50\n","CLF Train loss: 0.6340, Train Accuracy: 0.6418\n","CLF Val loss: 0.5471, Validation Accuracy: 0.6901\n","Epoch 2/50\n","CLF Train loss: 0.4589, Train Accuracy: 0.8143\n","CLF Val loss: 0.5479, Validation Accuracy: 0.7251\n","Epoch 3/50\n","CLF Train loss: 0.4230, Train Accuracy: 0.8114\n","CLF Val loss: 0.4847, Validation Accuracy: 0.7895\n","Epoch 4/50\n","CLF Train loss: 0.2872, Train Accuracy: 0.9094\n","CLF Val loss: 0.5294, Validation Accuracy: 0.7427\n","Epoch 5/50\n","CLF Train loss: 0.2278, Train Accuracy: 0.9240\n","CLF Val loss: 0.5218, Validation Accuracy: 0.7485\n","Epoch 6/50\n","CLF Train loss: 0.1975, Train Accuracy: 0.9386\n","CLF Val loss: 0.5851, Validation Accuracy: 0.7544\n","Epoch 7/50\n","CLF Train loss: 0.2002, Train Accuracy: 0.9327\n","CLF Val loss: 0.6502, Validation Accuracy: 0.7193\n","Epoch 8/50\n","CLF Train loss: 0.1779, Train Accuracy: 0.9518\n","CLF Val loss: 0.5621, Validation Accuracy: 0.6901\n","Epoch 9/50\n","CLF Train loss: 0.1367, Train Accuracy: 0.9751\n","CLF Val loss: 0.5431, Validation Accuracy: 0.7602\n","Epoch 10/50\n","CLF Train loss: 0.1114, Train Accuracy: 0.9839\n","CLF Val loss: 0.5046, Validation Accuracy: 0.7544\n","Epoch 11/50\n","CLF Train loss: 0.1179, Train Accuracy: 0.9795\n","CLF Val loss: 0.5646, Validation Accuracy: 0.7193\n","Epoch 12/50\n","CLF Train loss: 0.1183, Train Accuracy: 0.9810\n","CLF Val loss: 0.5780, Validation Accuracy: 0.7778\n","Fold 10/10\n","{'accuracy': 0.7128, 'senstivity': 0.5122, 'specificity': 0.8679, 'loss': 0.5798}\n","--------------------------------------------\n","Average Value after 10 Folds\n","Accuracy: 0.7271, Senstivity: 0.6798, Specificity: 0.7641, Loss: 0.6086000204086304\n","Total time taken : 4182.921565294266\n"]}]},{"cell_type":"markdown","source":["# Visualization"],"metadata":{"id":"laTjryBjYUVu"}},{"cell_type":"code","source":["def attribute_image_features(algorithm, inputs, target = 1):\n","    model.zero_grad()\n","    model.eval()\n","    tensor_attributions = algorithm.attribute(inputs = inputs, target = target, return_convergence_delta=True)  \n","    return tensor_attributions"],"metadata":{"id":"sSt5CcbIj5Tn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["attributions = []\n","all_folds = pickle.load(open('./data/AllFoldssubjects.pkl', 'rb'))\n","\n","for fold in range(10):\n","    fold_weights = torch.load(f'data/Weights/Fold_{fold+1}.pth', map_location=torch.device('cpu'))\n","    best_clf_model = MTAutoEncoder(tied = False, num_inputs = 19900, num_latent = 512, use_dropout = True) \n","    best_clf_model.load_state_dict(fold_weights)\n","    best_clf_model = best_clf_model.to('cpu')\n","\n","    test_subjects = all_folds[fold]['test']\n","    x_asd, y_asd = [], []\n","    for sample in test_subjects : \n","        if(all_corr[sample][1] == 1):\n","          x_asd.append(all_corr[sample][0])\n","          y_asd.append(all_corr[sample][1])\n","    print('Number of ASD subjects in test set : ', len(x_asd))\n","\n","    x_asd = torch.tensor(x_asd, dtype=torch.float)\n","    y_asd = np.array(y_asd)  \n","\n","    y_asd_pred = best_clf_model(x_asd)\n","    y_asd_pred = y_asd_pred.detach().cpu().numpy()\n","    y_asd_pred = np.round(y_asd_pred)\n","    y_asd_pred = np.squeeze(y_asd_pred, axis = 1)\n","\n","    right_indices = np.where(y_asd_pred == 1)\n","    x_asd_ig = x_asd[right_indices]\n","    print('Number of correctly predicted ASD subjects : ', len(x_asd_ig))\n","\n","    ig_asd = IntegratedGradients(best_clf_model)        \n","    grads_asd, delta_asd = attribute_image_features(ig_asd, inputs = x_asd_ig, target = 0)                     \n","    grads_asd = torch.mean(grads_asd, axis = 0)\n","    grads_asd = np.array(grads_asd)\n","    attributions.append(grads_asd)\n","                            \n","attributions = np.array(attributions)\n","# np.save('./data/IG_Attributions.npy', attributions)\n","print(\"Attributions shape : \", attributions.shape)"],"metadata":{"id":"QaFQKIopR6r0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643953948011,"user_tz":-330,"elapsed":212388,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"ce81709d-598f-4dc3-ae45-190b142d5e61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of ASD samples in test set :  42\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n"]},{"output_type":"stream","name":"stdout","text":["Number of correctly predicted ASD samples :  28\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  23\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  26\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  28\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  31\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  32\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  29\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  32\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  23\n","Number of ASD samples in test set :  41\n","Number of correctly predicted ASD samples :  19\n","Attributions shape :  (10, 19900)\n"]}]},{"cell_type":"code","source":["rois_count = {}    # {roi : number of times it is repeated in all 10 folds}\n","\n","for grads_asd in attributions :\n","  \n","    attr_vals_asd = grads_asd.copy()\n","    thresh = np.percentile(attr_vals_asd, 99)\n","    attr_vals_asd = np.where(attr_vals_asd > thresh,  1 , 0) # check1\n","    corr_matrix_asd = np.zeros((200,200))\n","    corr_matrix_asd[np.triu_indices(200, 1)] = attr_vals_asd\n","    print('Number of unique elements in corr_matrix : ', np.unique(corr_matrix_asd, return_counts = True))\n","\n","    max_sum_rows = np.sum(corr_matrix_asd, axis = 1)      # check 2\n","    top_indices = np.argsort(max_sum_rows)            # Max value indices\n","    top_values = max_sum_rows[top_indices]      # Max values\n","\n","    top20_indices  = top_indices[-20 : ]\n","    top20_values = top_values[-20 : ]\n","\n","    print('Most repeated ROIS in ASD (Not index values): ', top20_indices + 1)\n","    print('Number of times ROIS repeated in ASD : ', top20_values)\n","    \n","    for index, roi in enumerate(top_indices): \n","        if(roi in rois_count):\n","            rois_count[roi] += top_values[index]\n","        else : \n","          rois_count[roi] = top_values[index]        \n","\n","rois_count_sorted = dict(sorted(rois_count.items(), key = lambda x : x[1], reverse = True))\n","print(rois_count_sorted)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_4RVBh0qnr3","executionInfo":{"status":"ok","timestamp":1643356297318,"user_tz":-330,"elapsed":518,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"bd09a900-de0f-4909-94e5-b972fb81cf1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [154  30 107 105 106  65  31  10  63  28  71  21  32  59 117  57  64  49\n","  94  55]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 5. 5. 5. 6. 6. 6. 6. 6. 7. 8.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [107  21  33  28  90  93  45  71 154 130  49 106  59  46  32  55  30  17\n","  77  64]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 5. 5. 5. 5. 6. 6. 6. 6. 7.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [128  94 130  93  55   8  66  31  16  36  32  45  49  57  63  64  42  46\n","  30  59]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 6.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 42 106  73  65 117  87  35  49  55  17  15  45  71  46  53  32  94  30\n","  84  59]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 5.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 93  34  11  28  78  46 110  53  36  21  94  16  49  30  73  63  64  32\n","  55  59]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 6. 6. 6.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 28  45  35  11  77 119  42  47  63 106  94  17  64  32  87  46  49  30\n","  59   4]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 5. 5. 5. 5. 5. 5. 5. 6.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 63  35  46  13  57 117  17  21  84 106  90   8  94  49  64  30  55  59\n","  32  15]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 6. 6. 6. 7. 7. 8.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 30 126  71  89  33  21  55  59  36  65  46  49  17  90  28  32  94  53\n"," 117  64]\n","Number of times ROIS repeated in ASD :  [3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 6. 6. 6. 7. 9.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 73 107  90  93 129  28 106  32  16  33  44  47  49 117  42  21  94  53\n","  59  64]\n","Number of times ROIS repeated in ASD :  [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  4.  4.  4.  5.  5.  5.\n","  7. 10.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [129  36  71  99  63 170  33   3 117  74  46  21  47 106  59  28  30  55\n","  49  64]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 6. 7.]\n","{63: 61.0, 58: 56.0, 31: 49.0, 48: 48.0, 54: 46.0, 29: 44.0, 93: 40.0, 45: 37.0, 20: 37.0, 16: 35.0, 27: 35.0, 116: 34.0, 105: 33.0, 14: 29.0, 52: 28.0, 62: 28.0, 70: 26.0, 89: 25.0, 44: 25.0, 7: 24.0, 83: 24.0, 56: 24.0, 35: 23.0, 32: 22.0, 41: 22.0, 88: 22.0, 64: 22.0, 46: 21.0, 73: 21.0, 4: 21.0, 10: 21.0, 15: 20.0, 30: 20.0, 72: 19.0, 92: 19.0, 34: 19.0, 106: 19.0, 9: 19.0, 76: 18.0, 86: 17.0, 12: 17.0, 38: 17.0, 163: 17.0, 65: 17.0, 43: 17.0, 3: 16.0, 165: 16.0, 113: 16.0, 11: 16.0, 118: 16.0, 33: 16.0, 109: 16.0, 129: 16.0, 104: 16.0, 167: 15.0, 90: 15.0, 130: 15.0, 82: 15.0, 127: 15.0, 74: 15.0, 153: 15.0, 161: 14.0, 77: 13.0, 2: 13.0, 128: 12.0, 98: 11.0, 91: 11.0, 17: 11.0, 154: 11.0, 85: 10.0, 169: 10.0, 67: 10.0, 139: 10.0, 125: 10.0, 102: 10.0, 146: 10.0, 66: 9.0, 36: 9.0, 23: 9.0, 99: 9.0, 111: 8.0, 24: 8.0, 94: 8.0, 117: 7.0, 101: 7.0, 189: 7.0, 158: 7.0, 28: 7.0, 164: 7.0, 84: 7.0, 186: 6.0, 187: 6.0, 19: 6.0, 180: 6.0, 182: 6.0, 61: 6.0, 0: 5.0, 134: 5.0, 103: 5.0, 47: 5.0, 49: 5.0, 50: 5.0, 26: 5.0, 75: 5.0, 122: 5.0, 42: 5.0, 126: 4.0, 110: 4.0, 149: 4.0, 183: 4.0, 166: 4.0, 79: 4.0, 51: 4.0, 21: 4.0, 5: 4.0, 22: 4.0, 39: 4.0, 123: 3.0, 131: 3.0, 140: 3.0, 119: 3.0, 95: 3.0, 100: 3.0, 80: 3.0, 193: 3.0, 159: 3.0, 160: 3.0, 25: 3.0, 13: 3.0, 150: 3.0, 114: 3.0, 55: 3.0, 151: 3.0, 133: 2.0, 144: 2.0, 115: 2.0, 87: 2.0, 97: 2.0, 108: 2.0, 155: 2.0, 181: 2.0, 152: 2.0, 40: 2.0, 59: 2.0, 78: 2.0, 68: 2.0, 69: 2.0, 18: 2.0, 142: 2.0, 143: 2.0, 8: 2.0, 60: 2.0, 121: 2.0, 135: 1.0, 138: 1.0, 145: 1.0, 147: 1.0, 136: 1.0, 112: 1.0, 184: 1.0, 177: 1.0, 168: 1.0, 37: 1.0, 124: 0.0, 132: 0.0, 120: 0.0, 137: 0.0, 141: 0.0, 148: 0.0, 81: 0.0, 96: 0.0, 198: 0.0, 107: 0.0, 185: 0.0, 188: 0.0, 179: 0.0, 191: 0.0, 192: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 190: 0.0, 178: 0.0, 176: 0.0, 156: 0.0, 157: 0.0, 162: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 199: 0.0, 57: 0.0, 1: 0.0, 6: 0.0, 53: 0.0, 71: 0.0}\n"]}]},{"cell_type":"code","source":["print(rois_count_sorted)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvBf8b7rcvli","executionInfo":{"status":"ok","timestamp":1643356368961,"user_tz":-330,"elapsed":829,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"acd14f8f-2085-4709-da01-abbb817a2a69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{63: 61.0, 58: 56.0, 31: 49.0, 48: 48.0, 54: 46.0, 29: 44.0, 93: 40.0, 45: 37.0, 20: 37.0, 16: 35.0, 27: 35.0, 116: 34.0, 105: 33.0, 14: 29.0, 52: 28.0, 62: 28.0, 70: 26.0, 89: 25.0, 44: 25.0, 7: 24.0, 83: 24.0, 56: 24.0, 35: 23.0, 32: 22.0, 41: 22.0, 88: 22.0, 64: 22.0, 46: 21.0, 73: 21.0, 4: 21.0, 10: 21.0, 15: 20.0, 30: 20.0, 72: 19.0, 92: 19.0, 34: 19.0, 106: 19.0, 9: 19.0, 76: 18.0, 86: 17.0, 12: 17.0, 38: 17.0, 163: 17.0, 65: 17.0, 43: 17.0, 3: 16.0, 165: 16.0, 113: 16.0, 11: 16.0, 118: 16.0, 33: 16.0, 109: 16.0, 129: 16.0, 104: 16.0, 167: 15.0, 90: 15.0, 130: 15.0, 82: 15.0, 127: 15.0, 74: 15.0, 153: 15.0, 161: 14.0, 77: 13.0, 2: 13.0, 128: 12.0, 98: 11.0, 91: 11.0, 17: 11.0, 154: 11.0, 85: 10.0, 169: 10.0, 67: 10.0, 139: 10.0, 125: 10.0, 102: 10.0, 146: 10.0, 66: 9.0, 36: 9.0, 23: 9.0, 99: 9.0, 111: 8.0, 24: 8.0, 94: 8.0, 117: 7.0, 101: 7.0, 189: 7.0, 158: 7.0, 28: 7.0, 164: 7.0, 84: 7.0, 186: 6.0, 187: 6.0, 19: 6.0, 180: 6.0, 182: 6.0, 61: 6.0, 0: 5.0, 134: 5.0, 103: 5.0, 47: 5.0, 49: 5.0, 50: 5.0, 26: 5.0, 75: 5.0, 122: 5.0, 42: 5.0, 126: 4.0, 110: 4.0, 149: 4.0, 183: 4.0, 166: 4.0, 79: 4.0, 51: 4.0, 21: 4.0, 5: 4.0, 22: 4.0, 39: 4.0, 123: 3.0, 131: 3.0, 140: 3.0, 119: 3.0, 95: 3.0, 100: 3.0, 80: 3.0, 193: 3.0, 159: 3.0, 160: 3.0, 25: 3.0, 13: 3.0, 150: 3.0, 114: 3.0, 55: 3.0, 151: 3.0, 133: 2.0, 144: 2.0, 115: 2.0, 87: 2.0, 97: 2.0, 108: 2.0, 155: 2.0, 181: 2.0, 152: 2.0, 40: 2.0, 59: 2.0, 78: 2.0, 68: 2.0, 69: 2.0, 18: 2.0, 142: 2.0, 143: 2.0, 8: 2.0, 60: 2.0, 121: 2.0, 135: 1.0, 138: 1.0, 145: 1.0, 147: 1.0, 136: 1.0, 112: 1.0, 184: 1.0, 177: 1.0, 168: 1.0, 37: 1.0, 124: 0.0, 132: 0.0, 120: 0.0, 137: 0.0, 141: 0.0, 148: 0.0, 81: 0.0, 96: 0.0, 198: 0.0, 107: 0.0, 185: 0.0, 188: 0.0, 179: 0.0, 191: 0.0, 192: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 190: 0.0, 178: 0.0, 176: 0.0, 156: 0.0, 157: 0.0, 162: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 199: 0.0, 57: 0.0, 1: 0.0, 6: 0.0, 53: 0.0, 71: 0.0}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6rzw64tPTaU","outputId":"15192e22-595a-4ad4-c8ab-92154759ade1","executionInfo":{"status":"ok","timestamp":1643352982474,"user_tz":-330,"elapsed":3,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.width', None)\n","pd.set_option('display.max_colwidth', -1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n","  after removing the cwd from sys.path.\n"]}]},{"cell_type":"code","metadata":{"id":"XkE6jziUZBE1","colab":{"base_uri":"https://localhost:8080/","height":681},"outputId":"0efa5f8c-5a71-4ca9-edc4-04ec4bb681a9","executionInfo":{"status":"ok","timestamp":1643353087427,"user_tz":-330,"elapsed":586,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}}},"source":["cc200_labels = pd.read_csv('./data/CC200_ROI_labels.csv')\n","# cc200_labels.head(5)\n","print('ASD Associated Regions : ')\n","rois = [64, 59, 32, 49, 55, 30, 94, 46]\n","asd_rois = cc200_labels[cc200_labels['ROI number'].isin(rois)]\n","display(asd_rois)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ASD Associated Regions : \n"]},{"output_type":"display_data","data":{"text/html":["\n","  <div id=\"df-262d8b44-f999-4f7d-8eb2-0c33c17bf3ae\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ROI number</th>\n","      <th>volume</th>\n","      <th>center of mass</th>\n","      <th>Dosenbach</th>\n","      <th>AAL</th>\n","      <th>Eickhoff-Zilles</th>\n","      <th>Talairach-Tournoux</th>\n","      <th>Harvard-Oxford</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>29</th>\n","      <td>30</td>\n","      <td>194</td>\n","      <td>(2.9;-28.0;-36.0)</td>\n","      <td>[\"None\": 1.00]</td>\n","      <td>[\"None\": 1.00]</td>\n","      <td>[\"None\": 1.00]</td>\n","      <td>[\"None\": 1.00]</td>\n","      <td>[\"None\": 1.00]</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>32</td>\n","      <td>170</td>\n","      <td>(43.5;9.9;-36.2)</td>\n","      <td>[\"None\": 1.00]</td>\n","      <td>[\"Temporal_Pole_Mid_R\": 0.59][\"Temporal_Inf_R\": 0.35]</td>\n","      <td>[\"Right Medial Temporal Pole\": 0.61][\"Right Inferior Temporal Gyrus\": 0.26][\"None\": 0.12]</td>\n","      <td>[\"Right Middle Temporal Gyrus\": 0.44][\"None\": 0.31][\"Right Superior Temporal Gyrus\": 0.25]</td>\n","      <td>[\"Right Temporal Pole\": 0.96]</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>46</td>\n","      <td>227</td>\n","      <td>(1.9;-38.2;32.2)</td>\n","      <td>[\"None\": 0.84]</td>\n","      <td>[\"Cingulum_Mid_R\": 0.33][\"Cingulum_Post_L\": 0.23][\"Cingulum_Mid_L\": 0.18][\"Cingulum_Post_R\": 0.18]</td>\n","      <td>[\"Left Posterior Cingulate Cortex\": 0.26][\"Right Middle Cingulate Cortex\": 0.24][\"Right Posterior Cingulate Cortex\": 0.24][\"Left Middle Cingulate Cortex\": 0.14]</td>\n","      <td>[\"Right Cingulate Gyrus\": 0.44][\"Left Cingulate Gyrus\": 0.26][\"Right Posterior Cingulate\": 0.14][\"Left Posterior Cingulate\": 0.13]</td>\n","      <td>[\"Right Cingulate Gyrus; posterior division\": 0.74][\"Left Cingulate Gyrus; posterior division\": 0.25]</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>49</td>\n","      <td>222</td>\n","      <td>(61.9;-21.1;-15.6)</td>\n","      <td>[\"None\": 0.94]</td>\n","      <td>[\"Temporal_Mid_R\": 0.64][\"Temporal_Inf_R\": 0.34]</td>\n","      <td>[\"Right Inferior Temporal Gyrus\": 0.53][\"Right Middle Temporal Gyrus\": 0.47]</td>\n","      <td>[\"Right Inferior Temporal Gyrus\": 0.41][\"Right Middle Temporal Gyrus\": 0.41][\"Right Fusiform Gyrus\": 0.14]</td>\n","      <td>[\"Right Middle Temporal Gyrus; posterior division\": 0.75][\"Right Inferior Temporal Gyrus; posterior division\": 0.23]</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>55</td>\n","      <td>247</td>\n","      <td>(0.3;16.3;32.3)</td>\n","      <td>[\"None\": 0.83]</td>\n","      <td>[\"Cingulum_Mid_L\": 0.32][\"Cingulum_Mid_R\": 0.22][\"Cingulum_Ant_L\": 0.21][\"Cingulum_Ant_R\": 0.20]</td>\n","      <td>[\"Left Anterior Cingulate Cortex\": 0.32][\"Left Middle Cingulate Cortex\": 0.24][\"Right Middle Cingulate Cortex\": 0.22][\"Right Anterior Cingulate Cortex\": 0.20]</td>\n","      <td>[\"Left Cingulate Gyrus\": 0.44][\"Right Cingulate Gyrus\": 0.29][\"Right Anterior Cingulate\": 0.13][\"Left Anterior Cingulate\": 0.13]</td>\n","      <td>[\"Right Cingulate Gyrus; anterior division\": 0.52][\"Left Cingulate Gyrus; anterior division\": 0.27][\"Left Paracingulate Gyrus\": 0.13]</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>59</td>\n","      <td>240</td>\n","      <td>(36.7;17.2;3.6)</td>\n","      <td>[\"None\": 0.92]</td>\n","      <td>[\"Insula_R\": 0.61][\"Putamen_R\": 0.20][\"Frontal_Inf_Tri_R\": 0.11]</td>\n","      <td>[\"Right Insula Lobe\": 0.64][\"Right Putamen\": 0.15]</td>\n","      <td>[\"Right Insula\": 0.46][\"Right Inferior Frontal Gyrus\": 0.40][\"Right Claustrum\": 0.14]</td>\n","      <td>[\"Right Insular Cortex\": 0.46][\"Right Frontal Operculum Cortex\": 0.33]</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>64</td>\n","      <td>230</td>\n","      <td>(28.8;-0.3;56.8)</td>\n","      <td>[\"None\": 1.00]</td>\n","      <td>[\"Frontal_Sup_R\": 0.46][\"Frontal_Mid_R\": 0.35][\"Precentral_R\": 0.20]</td>\n","      <td>[\"Right Superior Frontal Gyrus\": 0.39][\"Right Middle Frontal Gyrus\": 0.37][\"RightPrecentral Gyrus\": 0.23]</td>\n","      <td>[\"Right Middle Frontal Gyrus\": 0.80][\"Right Superior Frontal Gyrus\": 0.12]</td>\n","      <td>[\"Right Superior Frontal Gyrus\": 0.38][\"Right Precentral Gyrus\": 0.30][\"Right Middle Frontal Gyrus\": 0.28]</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>94</td>\n","      <td>87</td>\n","      <td>(14.2;-0.5;17.5)</td>\n","      <td>[\"None\": 1.00]</td>\n","      <td>[\"Caudate_R\": 0.84][\"Thalamus_R\": 0.14]</td>\n","      <td>[\"Right Caudate Nucleus\": 0.77][\"Right Thalamus\": 0.16]</td>\n","      <td>[\"Right Caudate\": 0.68][\"Right Thalamus\": 0.23]</td>\n","      <td>[\"Right Caudate\": 0.71][\"Right Thalamus\": 0.26]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-262d8b44-f999-4f7d-8eb2-0c33c17bf3ae')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-262d8b44-f999-4f7d-8eb2-0c33c17bf3ae button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-262d8b44-f999-4f7d-8eb2-0c33c17bf3ae');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["    ROI number   volume       center of mass       Dosenbach  \\\n","29  30          194       (2.9;-28.0;-36.0)   [\"None\": 1.00]   \n","31  32          170       (43.5;9.9;-36.2)    [\"None\": 1.00]   \n","45  46          227       (1.9;-38.2;32.2)    [\"None\": 0.84]   \n","48  49          222       (61.9;-21.1;-15.6)  [\"None\": 0.94]   \n","54  55          247       (0.3;16.3;32.3)     [\"None\": 0.83]   \n","58  59          240       (36.7;17.2;3.6)     [\"None\": 0.92]   \n","63  64          230       (28.8;-0.3;56.8)    [\"None\": 1.00]   \n","93  94          87        (14.2;-0.5;17.5)    [\"None\": 1.00]   \n","\n","                                                                                                   AAL  \\\n","29  [\"None\": 1.00]                                                                                       \n","31  [\"Temporal_Pole_Mid_R\": 0.59][\"Temporal_Inf_R\": 0.35]                                                \n","45  [\"Cingulum_Mid_R\": 0.33][\"Cingulum_Post_L\": 0.23][\"Cingulum_Mid_L\": 0.18][\"Cingulum_Post_R\": 0.18]   \n","48  [\"Temporal_Mid_R\": 0.64][\"Temporal_Inf_R\": 0.34]                                                     \n","54  [\"Cingulum_Mid_L\": 0.32][\"Cingulum_Mid_R\": 0.22][\"Cingulum_Ant_L\": 0.21][\"Cingulum_Ant_R\": 0.20]     \n","58  [\"Insula_R\": 0.61][\"Putamen_R\": 0.20][\"Frontal_Inf_Tri_R\": 0.11]                                     \n","63  [\"Frontal_Sup_R\": 0.46][\"Frontal_Mid_R\": 0.35][\"Precentral_R\": 0.20]                                 \n","93  [\"Caudate_R\": 0.84][\"Thalamus_R\": 0.14]                                                              \n","\n","                                                                                                                                                     Eickhoff-Zilles  \\\n","29  [\"None\": 1.00]                                                                                                                                                     \n","31  [\"Right Medial Temporal Pole\": 0.61][\"Right Inferior Temporal Gyrus\": 0.26][\"None\": 0.12]                                                                          \n","45  [\"Left Posterior Cingulate Cortex\": 0.26][\"Right Middle Cingulate Cortex\": 0.24][\"Right Posterior Cingulate Cortex\": 0.24][\"Left Middle Cingulate Cortex\": 0.14]   \n","48  [\"Right Inferior Temporal Gyrus\": 0.53][\"Right Middle Temporal Gyrus\": 0.47]                                                                                       \n","54  [\"Left Anterior Cingulate Cortex\": 0.32][\"Left Middle Cingulate Cortex\": 0.24][\"Right Middle Cingulate Cortex\": 0.22][\"Right Anterior Cingulate Cortex\": 0.20]     \n","58  [\"Right Insula Lobe\": 0.64][\"Right Putamen\": 0.15]                                                                                                                 \n","63  [\"Right Superior Frontal Gyrus\": 0.39][\"Right Middle Frontal Gyrus\": 0.37][\"RightPrecentral Gyrus\": 0.23]                                                          \n","93  [\"Right Caudate Nucleus\": 0.77][\"Right Thalamus\": 0.16]                                                                                                            \n","\n","                                                                                                                    Talairach-Tournoux  \\\n","29  [\"None\": 1.00]                                                                                                                       \n","31  [\"Right Middle Temporal Gyrus\": 0.44][\"None\": 0.31][\"Right Superior Temporal Gyrus\": 0.25]                                           \n","45  [\"Right Cingulate Gyrus\": 0.44][\"Left Cingulate Gyrus\": 0.26][\"Right Posterior Cingulate\": 0.14][\"Left Posterior Cingulate\": 0.13]   \n","48  [\"Right Inferior Temporal Gyrus\": 0.41][\"Right Middle Temporal Gyrus\": 0.41][\"Right Fusiform Gyrus\": 0.14]                           \n","54  [\"Left Cingulate Gyrus\": 0.44][\"Right Cingulate Gyrus\": 0.29][\"Right Anterior Cingulate\": 0.13][\"Left Anterior Cingulate\": 0.13]     \n","58  [\"Right Insula\": 0.46][\"Right Inferior Frontal Gyrus\": 0.40][\"Right Claustrum\": 0.14]                                                \n","63  [\"Right Middle Frontal Gyrus\": 0.80][\"Right Superior Frontal Gyrus\": 0.12]                                                           \n","93  [\"Right Caudate\": 0.68][\"Right Thalamus\": 0.23]                                                                                      \n","\n","                                                                                                                           Harvard-Oxford  \n","29  [\"None\": 1.00]                                                                                                                         \n","31  [\"Right Temporal Pole\": 0.96]                                                                                                          \n","45  [\"Right Cingulate Gyrus; posterior division\": 0.74][\"Left Cingulate Gyrus; posterior division\": 0.25]                                  \n","48  [\"Right Middle Temporal Gyrus; posterior division\": 0.75][\"Right Inferior Temporal Gyrus; posterior division\": 0.23]                   \n","54  [\"Right Cingulate Gyrus; anterior division\": 0.52][\"Left Cingulate Gyrus; anterior division\": 0.27][\"Left Paracingulate Gyrus\": 0.13]  \n","58  [\"Right Insular Cortex\": 0.46][\"Right Frontal Operculum Cortex\": 0.33]                                                                 \n","63  [\"Right Superior Frontal Gyrus\": 0.38][\"Right Precentral Gyrus\": 0.30][\"Right Middle Frontal Gyrus\": 0.28]                             \n","93  [\"Right Caudate\": 0.71][\"Right Thalamus\": 0.26]                                                                                        "]},"metadata":{}}]},{"cell_type":"code","source":["# ROIS : \n","Right middle frontal gyrus(64), Right insula lobe(59), Right temporal pole(32), Right middle temporal gyrus(49), Right Caudate Nucleus(94) "],"metadata":{"id":"dMmBBUqy8E8f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Deep Lift"],"metadata":{"id":"Pb1l88_ih96V"}},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"ajWq4e5UT2_a"}},{"cell_type":"code","metadata":{"id":"NK5mJmVdCV5c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643356585704,"user_tz":-330,"elapsed":127519,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"5009f152-d57c-45bc-fd05-fa6b878bcfcb"},"source":["dl_attributions = []\n","all_folds = pickle.load(open('./data/AllFoldssubjects.pkl', 'rb'))\n","for fold in range(10):\n","    fold_weights = torch.load(f'data/Weights/Fold_{fold+1}.pth', map_location=torch.device('cpu'))\n","    best_clf_model = MTAutoEncoder(tied = False, num_inputs = 19900, num_latent = 512, use_dropout = True) \n","    best_clf_model.load_state_dict(fold_weights)\n","    best_clf_model = best_clf_model.to('cpu')\n","\n","    test_subjects = all_folds[fold]['test']\n","    x_asd, y_asd = [], []\n","    for sample in test_subjects : \n","        if(all_corr[sample][1] == 1):\n","          x_asd.append(all_corr[sample][0])\n","          y_asd.append(all_corr[sample][1])\n","    print('Number of ASD subjects in test set : ', len(x_asd))\n","\n","    x_asd = torch.tensor(x_asd, dtype=torch.float)\n","    y_asd = np.array(y_asd)  \n","\n","    y_asd_pred = best_clf_model(x_asd)\n","    y_asd_pred = y_asd_pred.detach().cpu().numpy()\n","    y_asd_pred = np.round(y_asd_pred)\n","    y_asd_pred = np.squeeze(y_asd_pred, axis = 1)\n","\n","    right_indices = np.where(y_asd_pred == 1)\n","    x_asd_dl = x_asd[right_indices]\n","    print('Number of correctly predicted ASD subjects : ', len(x_asd_dl))\n","\n","    dl_asd = DeepLift(best_clf_model)        \n","    grads_asd, delta_asd = attribute_image_features(dl_asd, inputs = x_asd_dl, target = 0)                     \n","    grads_asd = torch.mean(grads_asd, axis = 0)\n","    grads_asd = grads_asd.detach().cpu().numpy()\n","    dl_attributions.append(grads_asd)\n","                            \n","dl_attributions = np.array(dl_attributions)\n","# np.save('./data/IG_Attributions.npy', attributions)\n","print(\"Attributions shape : \", dl_attributions.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  28\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/captum/_utils/gradient.py:58: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n","  \"required_grads has been set automatically.\" % index\n","/usr/local/lib/python3.7/dist-packages/captum/attr/_core/deep_lift.py:323: UserWarning: Setting forward, backward hooks and attributes on non-linear\n","               activations. The hooks and attributes will be removed\n","            after the attribution is finished\n","  after the attribution is finished\"\"\"\n"]},{"output_type":"stream","name":"stdout","text":["Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  22\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  25\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  26\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  31\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  32\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  30\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  32\n","Number of ASD samples in test set :  42\n","Number of correctly predicted ASD samples :  23\n","Number of ASD samples in test set :  41\n","Number of correctly predicted ASD samples :  20\n","Attributions shape :  (10, 19900)\n"]}]},{"cell_type":"code","source":["rois_count = {}    # {roi : number of times it is repeated in all 10 folds}\n","\n","for grads_asd in dl_attributions :\n","  \n","    attr_vals_asd = grads_asd.copy()\n","    thresh = np.percentile(attr_vals_asd, 99)\n","    attr_vals_asd = np.where(attr_vals_asd > thresh,  1 , 0) # check1\n","    corr_matrix_asd = np.zeros((200,200))\n","    corr_matrix_asd[np.triu_indices(200, 1)] = attr_vals_asd\n","    print('Number of unique elements in corr_matrix : ', np.unique(corr_matrix_asd, return_counts = True))\n","\n","    max_sum_rows = np.sum(corr_matrix_asd, axis = 1)      # check 2\n","    top_indices = np.argsort(max_sum_rows)            # Max value indices\n","    top_values = max_sum_rows[top_indices]      # Max values\n","\n","    top20_indices  = top_indices[-20 : ]\n","    top20_values = top_values[-20 : ]\n","\n","    print('Most repeated ROIS in ASD (Not index values): ', top20_indices + 1)\n","    print('Number of times ROIS repeated in ASD : ', top20_values)\n","    \n","    for index, roi in enumerate(top_indices): \n","        if(roi in rois_count):\n","            rois_count[roi] += top_values[index]\n","        else : \n","          rois_count[roi] = top_values[index]        \n","\n","rois_count_sorted = dict(sorted(rois_count.items(), key = lambda x : x[1], reverse = True))\n","print(rois_count_sorted)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cZKUFYkOmrEt","executionInfo":{"status":"ok","timestamp":1643356618312,"user_tz":-330,"elapsed":849,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"c5ffcd75-dc4b-45b2-e44f-32264849192c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 89 106 154 130  31  30  43  28  65  21  10  71  32  57  49  59  64 117\n","  94  55]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 6. 6. 6. 6. 7. 8.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 78  93  84  33  94  28  71 130  46  49 154  77 106  32  21  59  55  17\n","  30  64]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 6. 6. 6. 7.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 66  28 128  15  31  93  94  39  42 105  63  36  17  57  32  49  64  30\n","  46  59]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 5. 5. 6.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 64 106  21 117  35  31  28  55  45  15  17  84  49  46  59  32  71  53\n","  94  30]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 6. 6. 6.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [106  93  28  31  34  36  46 110  94  53  73  21  16  49  63  30  32  59\n","  55  64]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 6. 6. 6. 7.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 63 117  55  53  35  77  42  45  47  17  94 106  64  59  30  32  87  49\n","   4  46]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 5. 5. 5. 5. 5. 5. 6. 6.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 87  28  63  13 117  57   8  17  21  84  90  94 106  49  30  55  64  32\n","  59  15]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 5. 6. 6. 7. 7. 7. 8.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [140  30  71  55  59  65  36  33  21  17  46  89  90  28  49  32  94 117\n","  53  64]\n","Number of times ROIS repeated in ASD :  [3. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 5. 5. 5. 5. 6. 6. 7. 7. 9.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 74 119  90 129  66  77  93   5  32  47  53  13  16 117  12  21  94  49\n","  59  64]\n","Number of times ROIS repeated in ASD :  [ 3.  3.  3.  3.  3.  3.  3.  3.  3.  4.  4.  4.  4.  4.  4.  5.  5.  6.\n","  7. 10.]\n","Number of unique elements in corr_matrix :  (array([0., 1.]), array([39801,   199]))\n","Most repeated ROIS in ASD (Not index values):  [ 31  36 114  71  12  74   3  47  49  21 117  46  30 106  32  28  33  55\n","  64  59]\n","Number of times ROIS repeated in ASD :  [3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 5. 5. 6. 7. 8.]\n","{63: 65.0, 58: 59.0, 31: 50.0, 48: 48.0, 29: 47.0, 54: 46.0, 93: 42.0, 20: 39.0, 45: 37.0, 16: 36.0, 27: 35.0, 116: 34.0, 105: 33.0, 52: 31.0, 14: 30.0, 70: 26.0, 89: 25.0, 62: 24.0, 56: 24.0, 35: 23.0, 88: 23.0, 32: 22.0, 15: 22.0, 92: 22.0, 7: 22.0, 44: 22.0, 83: 22.0, 30: 22.0, 64: 22.0, 46: 21.0, 73: 21.0, 4: 21.0, 76: 20.0, 9: 20.0, 41: 19.0, 10: 19.0, 86: 18.0, 113: 18.0, 65: 18.0, 163: 18.0, 106: 18.0, 34: 17.0, 12: 17.0, 38: 17.0, 11: 17.0, 72: 16.0, 3: 16.0, 165: 16.0, 130: 16.0, 43: 16.0, 104: 16.0, 129: 16.0, 118: 15.0, 74: 15.0, 33: 15.0, 109: 15.0, 153: 15.0, 167: 14.0, 2: 14.0, 90: 14.0, 127: 14.0, 82: 13.0, 128: 13.0, 161: 12.0, 77: 11.0, 139: 11.0, 98: 11.0, 67: 11.0, 146: 11.0, 91: 11.0, 154: 11.0, 85: 10.0, 99: 10.0, 17: 10.0, 24: 10.0, 169: 9.0, 66: 9.0, 84: 9.0, 125: 9.0, 102: 9.0, 111: 8.0, 23: 8.0, 36: 8.0, 164: 8.0, 94: 8.0, 101: 7.0, 189: 7.0, 158: 7.0, 42: 7.0, 186: 6.0, 187: 6.0, 28: 6.0, 19: 6.0, 182: 6.0, 180: 6.0, 117: 5.0, 183: 5.0, 50: 5.0, 47: 5.0, 21: 5.0, 75: 5.0, 122: 5.0, 0: 4.0, 131: 4.0, 140: 4.0, 119: 4.0, 87: 4.0, 103: 4.0, 110: 4.0, 61: 4.0, 26: 4.0, 5: 4.0, 39: 4.0, 123: 3.0, 126: 3.0, 134: 3.0, 95: 3.0, 97: 3.0, 108: 3.0, 100: 3.0, 193: 3.0, 159: 3.0, 160: 3.0, 166: 3.0, 79: 3.0, 49: 3.0, 51: 3.0, 13: 3.0, 142: 3.0, 150: 3.0, 114: 3.0, 55: 3.0, 151: 3.0, 143: 3.0, 133: 2.0, 144: 2.0, 115: 2.0, 149: 2.0, 152: 2.0, 181: 2.0, 80: 2.0, 22: 2.0, 25: 2.0, 59: 2.0, 40: 2.0, 78: 2.0, 18: 2.0, 69: 2.0, 8: 2.0, 37: 2.0, 60: 2.0, 132: 1.0, 135: 1.0, 136: 1.0, 137: 1.0, 145: 1.0, 147: 1.0, 96: 1.0, 112: 1.0, 155: 1.0, 184: 1.0, 177: 1.0, 68: 1.0, 6: 1.0, 138: 1.0, 121: 1.0, 124: 0.0, 141: 0.0, 120: 0.0, 81: 0.0, 148: 0.0, 198: 0.0, 107: 0.0, 185: 0.0, 188: 0.0, 179: 0.0, 191: 0.0, 192: 0.0, 194: 0.0, 195: 0.0, 196: 0.0, 197: 0.0, 190: 0.0, 178: 0.0, 176: 0.0, 156: 0.0, 157: 0.0, 162: 0.0, 170: 0.0, 171: 0.0, 172: 0.0, 173: 0.0, 174: 0.0, 175: 0.0, 168: 0.0, 199: 0.0, 57: 0.0, 53: 0.0, 71: 0.0, 1: 0.0}\n"]}]},{"cell_type":"code","source":["delta_asd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q4UCdcN0mrHn","executionInfo":{"status":"ok","timestamp":1643356978336,"user_tz":-330,"elapsed":537,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"4ec0ffb6-7985-41d6-afc3-5c2e9c030443"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0.0448, -0.0280, -0.0142,  0.0200, -0.0104, -0.0270,  0.0045, -0.0501,\n","         0.0089, -0.0137, -0.0063,  0.0045, -0.0020, -0.0252,  0.0453,  0.0029,\n","        -0.0170,  0.0187,  0.0781,  0.0047])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["rois = [64, 59, 49, 32, 30, 55, 94, 46]\n","asd_rois = cc200_labels[cc200_labels['ROI number'].isin(rois)]\n","display(asd_rois)"],"metadata":{"id":"DTrhaJETh9MY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"l8aDLCwYmrKb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"KO2vGBnKmrNQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(rois_count_sorted).  # Without thresholding and taking the sum. "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p_3TRYyBTVUK","executionInfo":{"status":"ok","timestamp":1643954135820,"user_tz":-330,"elapsed":457,"user":{"displayName":"Pindi Krishna Chandra Prasad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhZxlbz0Z19akuHSNWxFzQ5NotgVLgbP1Z3pWeACA=s64","userId":"09882944775694485051"}},"outputId":"09d135fd-5205-468a-fc96-cbff19b56d2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{63: 0.28833801775652723, 34: 0.16755825132131255, 14: 0.15259633067985268, 70: 0.13047253297211048, 58: 0.12235610972428701, 41: 0.12204838184740958, 54: 0.11999169962167079, 29: 0.119460891259341, 48: 0.11912324991494355, 52: 0.11543538350486209, 127: 0.11251435212226324, 128: 0.10693960790720322, 88: 0.10345871149475779, 130: 0.10229100258155885, 129: 0.10204925380761753, 90: 0.09465215779146104, 20: 0.09419945080018129, 30: 0.08784245042409317, 83: 0.08576062744973681, 16: 0.08506434713670755, 72: 0.08309108378294525, 105: 0.07935774375355967, 89: 0.07755795605543256, 91: 0.07673209027984447, 82: 0.07601929354820683, 46: 0.07480984718746976, 109: 0.07152370382524624, 19: 0.06990669182987254, 45: 0.06989307003257972, 111: 0.06933357619506557, 118: 0.06875127717805271, 93: 0.06501561961407462, 65: 0.06432255460224846, 163: 0.060248144174904025, 66: 0.05892478769611261, 161: 0.05559441087351655, 110: 0.05502748499986784, 43: 0.05473448984499586, 117: 0.05314646348940971, 116: 0.05312470839891768, 125: 0.05284157795518295, 36: 0.05280198439482876, 62: 0.05253744655295338, 102: 0.05217222268775805, 108: 0.04987130275852759, 12: 0.048180330246799935, 165: 0.04734821067750166, 164: 0.04576009029960367, 56: 0.044393032996774155, 86: 0.04414353211314185, 38: 0.04393565042226278, 167: 0.043244937271131344, 57: 0.0425479574901058, 87: 0.04133974441512181, 10: 0.039711781094926756, 160: 0.036995111825119796, 47: 0.03689615936037732, 73: 0.03678561526957457, 169: 0.0358547544291699, 32: 0.03505050423381929, 24: 0.03332709884011677, 92: 0.03331232813963242, 106: 0.031193757639413143, 119: 0.030776633121194056, 126: 0.03009882553085503, 44: 0.03003014165241319, 182: 0.028435942999592075, 104: 0.028370631873877093, 84: 0.028063066113458122, 37: 0.027610485715147744, 4: 0.02746613645395753, 3: 0.026847160228006265, 153: 0.02599247364963674, 74: 0.024953806900251643, 98: 0.0248016621679322, 77: 0.023465530816658732, 50: 0.021898820555622034, 103: 0.02139667423467417, 166: 0.020258146850149324, 35: 0.01979826489681938, 76: 0.019555206204667133, 180: 0.017950420453975106, 139: 0.017497540041811657, 31: 0.01711847272572431, 85: 0.01673648875559459, 59: 0.016217787148675642, 33: 0.015977738447776675, 121: 0.014824901733032646, 131: 0.013260996897157153, 184: 0.011595208891585766, 162: 0.011336585101130038, 7: 0.0104168687123582, 154: 0.009855634280137008, 155: 0.009696737849780066, 158: 0.008678100668898814, 186: 0.008210723153331316, 170: 0.007712592427359191, 181: 0.006704557635403506, 101: 0.006207785196337427, 193: 0.005809162419216174, 183: 0.003934595468469482, 64: 0.003506429211504095, 51: 0.0034010491216618617, 192: 0.003274373618109859, 123: 0.0025657193646154105, 188: 0.0020769493429090824, 179: 0.0010216755165629145, 197: 0.0010188271099936684, 189: 0.0006010396994345813, 187: 0.00029409029313882365, 198: 0.00011403467930008336, 199: 0.0, 67: -0.0005161204381473816, 168: -0.0007164271919293302, 190: -0.0009075100557962654, 69: -0.0011473241652920087, 191: -0.0014118644331187857, 81: -0.0018185340302159332, 196: -0.002082706100564369, 185: -0.0028507422876018155, 149: -0.0035588767201282703, 9: -0.0036194223557549678, 157: -0.004488929875340442, 147: -0.004504915085442056, 134: -0.004708709841967555, 152: -0.004865027153294857, 113: -0.005265094969027212, 159: -0.0072594550881072495, 175: -0.0073440423532429655, 137: -0.007408262265374484, 114: -0.008590646307391788, 195: -0.008621245468034318, 112: -0.009502537424413312, 176: -0.0095745203846658, 27: -0.009628633378999624, 194: -0.009856572931624858, 138: -0.01035789225772693, 140: -0.010577638424533234, 151: -0.010874523902963108, 49: -0.011080862413560254, 23: -0.011983281111465679, 135: -0.012499623127393673, 95: -0.012606954399308305, 143: -0.012925881041405457, 171: -0.01305516297055968, 174: -0.013564383296299389, 122: -0.013618452887865512, 15: -0.014158575432843955, 124: -0.015971631303984834, 18: -0.016513288026496677, 68: -0.016564382491076873, 156: -0.018300347493060636, 94: -0.018601278842743266, 142: -0.019704705750509192, 146: -0.022807221722715994, 26: -0.023754320893547887, 61: -0.026189837271718627, 141: -0.02669331914206767, 133: -0.026787362209640703, 150: -0.027947915664309184, 0: -0.028255568283089408, 148: -0.029690205482707833, 120: -0.02989318181549701, 42: -0.030321729236891175, 178: -0.030658602758112455, 132: -0.030896143799309266, 177: -0.03320532477000267, 1: -0.03353668922491521, 96: -0.033643440744969375, 25: -0.03467627157431293, 80: -0.03594225509743467, 17: -0.03689347508041806, 75: -0.03706368343500563, 22: -0.03972160150037358, 97: -0.03976110669160757, 39: -0.040803977623187604, 172: -0.04146451328141268, 145: -0.04531807735509963, 60: -0.046315939670921694, 99: -0.04951986584628362, 136: -0.05095239124783012, 78: -0.05238037449772391, 100: -0.05418445561133041, 21: -0.05422739395378849, 107: -0.054563136766289856, 144: -0.06103823817392644, 115: -0.06169289756263292, 2: -0.06394825813993839, 173: -0.06586370730143272, 71: -0.0676460781827429, 40: -0.06826972638829006, 13: -0.0702247871723783, 11: -0.08075375152994747, 5: -0.08529137168418507, 53: -0.08699736148784445, 79: -0.08704765469687507, 28: -0.10789988354056877, 6: -0.11484748726741031, 8: -0.12857395497898264, 55: -0.15731916532881404}\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"QOFPu18_h9O_"},"execution_count":null,"outputs":[]}]}